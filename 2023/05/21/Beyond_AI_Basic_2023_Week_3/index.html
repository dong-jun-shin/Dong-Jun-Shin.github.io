<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>코칭스터디 Beyond AI Basic 2023 - 3주차 학습</title>
  <meta
    name="description"
    content="딥러닝 기초딥러닝 기본 용어 설명딥러닝을 활용하는 데이터 사이언티스트가 갖춰야 할 역량  프로그래밍 역량(Implementation Skills)          텐서플로우, 파이토치        수학 및 통계 역량(Math Skills)          선형 대수학(Linear ..."
  />
  <!-- Twitter Cards -->
<meta name="twitter:title" content="코칭스터디 Beyond AI Basic 2023 - 3주차 학습">
<meta name="twitter:description" content="딥러닝 기초

딥러닝 기본 용어 설명

딥러닝을 활용하는 데이터 사이언티스트가 갖춰야 할 역량


  프로그래밍 역량(Implementation Skills)
    
      텐서플로우, 파이토치
    
  
  수학 및 통계 역량(Math Skills)
    
      선형 대수학(Linear Algebra)
      확률(Probability)
    
  
  관련 도메인 지식(Knowing Papers)
    
      많은 양의 최신 자료
    
  




딥러닝의 정의


  Artificial Intelligence &gt; Machine Learning &gt; Deep Learning




딥러닝의 핵심 요소


  모델이 학습 가능한 데이터
    
      문제에 의존성을 가짐
      데이터의 종류
        
          정의 문제(Classification)
          특징 분류 문제(Semantic Segmentation)
          탐색 문제(Detection)
          자세 판단 문제(Pose Estimation)
          시각적 질의응답 문제(Visual QnA)
        
      
    
  
  데이터를 원하는 것으로 변환해주는 모델
    
      input(x)로 output(y)를 도출하기 위한 파라미터들(w, b)을 찾기 위한 것
      2012 ~ 2020까지 대표적인 모델 예시
        
          AlexNet - 2012, 첫 딥러닝 모델
          DQN - 2013, 딥 마인드에서 게임을 학습하는데 사용한 모델
          Encoder/Decoder - 2014, 번역 등에 사용한 모델
          AdamOptimizer - 2014, 수많은 하이퍼 파라미터의 최적화에 높은 성능을 보이는 모델
          GAN - 2015, 이미지 생성 모델
          ResNet(Residual Networks) - 2015, NN의 층을 깊게 쌓아 성능을 높인 모델
          Transformer - 2017, 기존 방법론들을 대체한 중요한 모델
          BERT - 2018, 소수의 데이터를 fine-tuning 하는 개념이 적용된 모델
          BIG language Models - 2019, GPT 같은 가장 진보된 NLP 모델
          Self Supervised Learning - 2020, SimCLR 같은 라벨되지 않은 데이터를 학습에 함께 활용하는 방법
        
      
      그 외 모델
        
          GoogLeNet
          DenseNet
          LSTM
          Deep AutoEncoders
        
      
    
  
  정해진 모델과 데이터로 어떻게 학습할 지에 대한 손실 함수(Loss function)
    
      손실률(실제와 예측의 차이)을 근사치로 표현한 함수
      클수록 오답이고, 작을수록 정답
      종류
        
          회귀 문제(Regression Task)
            
              평균 제곱 오차 (MSE, Mean-Squared Error)
                
                  학습값과 예측값의 오차 제곱을 계산한 값
                  연속적 분포의 특성을 갖는 선형 회귀에서 주로 사용
                
              
            
          
          분류 문제(Classification)
            
              크로스 엔트로피 (CE, Cross-Entropy)
                
                  확률 분포와 예측 분포 사이의 차이를 측정
                  이산적 분포의 특성을 갖는 다항 분류에 주로 사용
                
              
            
          
          확률 문제(Probability)
            
              최대 가능도 추정 (MLE, Maximum Likelihood Estimation)
                
                  각 샘플에 있는 특징을 기여도로 계산해서 다 곱한 값
                  데이터의 밀도를 추정하는 방법으로 값에 대한 평균과 분산으로 모델링할 때 주로 사용
                
              
            
          
        
      
    
  
  손실률을 최소화하는 최적화 목적의 알고리즘
    
      한정된 데이터로 모델과 손실 함수를 바꿔가며 높은 성능을 내도록 함
      Dropout
      Early stopping
      k-fold validation
      Weight decay
      Batch normalization
      MixUp
      Ensemble
      Bayesian Optimization
    
  




뉴럴 네트워크 - MLP

Neural Networks


  포유류의 신경망을 기반으로 분류, 생성, 변환 등 함수를 모방한 개념




Linear Neural Networks


  학습된 데이터가 선형의 모습으로 이루어진 가장 간단한 NN의 개념
  n차원 값에서 m차원 값을 찾고 싶은 경우, 행렬을 곱함
    
      2개의 벡터 공간 사이의 선형성을 찾는 것
    
  
  Data: x, y로 구성된 1차원 값 N개로 구성
  Model: x를 w라는 스칼로 곱하고, b라는 바이어스를 더함
    
      모델은 x에서 y를 도출하기 위한 w, b를 찾는 것이 목적
    
  
  Loss: MSE를 사용




Beyond Linear Neural Networks


  선형 결합의 반복을 통해 네트워크를 여러개 쌓는 방법
  Non-linear transform(p)을 선형 결합들 사이에 추가해서 반복 결합
    
      단순한 선형 결합은 행렬이 대칭하지 않기 때문에 하나인 네트워크와 같음
    
  
  Activation functions
    
      Non-linear transform을 위한 함수
      종류
        
          Rectified Linear Unit(ReLU)
            
              0보다 큰 값은 그대로 쓰고, 작은 값은 0으로 두는 방법
            
          
          Sigmoid
            
              출력값을 0 ~ 1로 제한하는 것
            
          
          Hyperbolic Tangent
            
              출력값을 +, -로 제한하는 것
            
          
        
      
    
  




Multi-Layer Perceptron


  input layer(x), hidden layer(h), output layer(y) 등으로 구성됨
  linear 또는 transformation 등 변환하는 작업을 하는 hidden layer가 있음




최적화

최적화의 주요 용어 이해하기

Introduction


  최적화는 빠르고 정확한 학습을 위한 개념
  Gradient Descent
    
      1차 미분값을 사용하여 계속 최적화를 반복해서 loss function을 최소화시키는 것
    
  




최적화에 있어 중요한 컨셉(Important Concepts in Optimization)


  Generalization
    
      Input data가 달라져도 Output에 대한 성능차이가 나지 않는 현상
      학습 데이터와 테스트 데이터 사이의 차이
        
          좋다 =&gt; 차이가 적어서 학습한만큼 나온다
        
      
      학습 데이터 자체가 안 좋을 경우, Generalization이 좋더라도 안 좋을 수 있음
    
  
  Underfitting vs. Overfitting
    
      과소적합, 과적합은 해석하기에 따라 달라질 수 있기 때문에 이론에 가까운 개념임
    
  
  Cross-validation
    
      학습데이터를 k개로 나누어 fold를 구성하고, 각 fold로 model을 생성하고 검증하는 K-fold cross-validation이 있음
      이 때 절대 테스트 데이터는 사용하면 안됨
    
  
  Bias and Variance
    
      두가지는 반비례함
      Bias: 평균적으로 봤을 때, 일관된 출력을 보이는 정도 (낮을수록 일관됨)
      Variance: 입력에 대해 일관된 출력을 보이는 정도 (낮을수록 일관됨)
    
  
  Bias and Variance Tradeoff
    
      cost를 줄이기 위해서, Bias와 Variance, noise를 두고 고민해야 함
    
  
  Bootstrapping
    
      데이터 중 랜덤하게 일부를 뽑아 샘플링하고 각각의 모델을 생성하는 방법
      모델들의 예측값이 일치하는 정도를 보고, 전체적인 모델의 예측을 보고자 할 때 사용
    
  
  Bagging vs. Boosting
    
      Bagging(Bootstrapping aggregating): 동일 모델을 여러개 만들어 각각 학습(병렬 학습)
      Boosting: 순차적으로 학습(직렬 학습)
    
  




Gradient Descent Methods

Practical Gradient Descent Methods


  Stochastic gradient descent
    
      전체 데이터 중 하나의 샘플을 이용해서 하나의 Gradient를 구하는 것을 반복하는 것
    
  
  Mini-batch gradient descent
    
      전체 데이터 중 일부를 이용해서 하나의 Gradient를 구하는 것을 반복하는 것
      보통 제일 많이 사용하는 방법
    
  
  Batch gradient descent
    
      전체 데이터 모두를 이용해서 하나의 Gradient를 구하는 것을 반복하는 것
    
  




Batch-size 문제


  Testing Function의 Minimum을 찾는 것이 중요
  Minimum의 개념
    
      제일 잘 예측하는 지점
      Flat Minimum
        
          Testing Function과 편차가 크지 않아, 학습 데이터에서 나온 성능만큼 보여주는 것
          Generalization가 높음
        
      
      Sharp Minimum
        
          Testing Function과 편차가 커서, 학습 데이터에서 나온 성능과 차이가 큼
          Generalization가 낮음
        
      
    
  




종류


  공식의 용어
    
      W:  NN의 Weight를 뜻함
      에타(η): Learning rate
      g: Gradient
      t: Step size
      베타(β): momentum
      엡실론(ε): 분모가 0이 되는 것을 방지하기 위한 값(분모값의 안정성을 위한 값)
      G: 파라미터가 변화한 정도를 누적한 값(gradient 제곱합)
    
  
  Stochastic Gradient Descent
    
      데이터 그대로 학습하는 방법
      Learning rate와 Gradient를 곱한 값을 Weight에서 뺌
      적절한 Learning rate와 Step size를 찾기 어려움
    
  
  Momentum(관성)
    
      momentum을 하이퍼 파라미터로 곱해서 다음 단계에 값이 반영되도록 한 방법
      일정 구간동안 학습 데이터가 반영될 수 있음
    
  
  Nesterov Accelerated Gradient
    
      실제 계산되는 지점에 momentum을 가로질러서 도달하는 방법
      Lookahead gradient를 계산
      momentum보다 빠르게 도달할 수 있음
    
  
  Adagrad
    
      NN의 파라미터가 변화한 정도를 조정하는 방법
      많이 변화했으면 둔하게 만들고, 적게 변화했으면 민감해지도록 함
      G가 계속 커지게 되면 점점 학습이 둔화하는 문제가 있음
    
  
  Adadelta
    
      G를 단계별로 고려해서 시간에 따른 변화를 보는 방법
      Adagrad에서 G가 계속 커지는 현상을 막기위해 나왔으나, 많이 사용되지는 않음
      단계별로 이전 단계들의 파라미터를 가지고 있어서 속도에 문제가 있음
    
  
  RMSprop
    
      Adagrad처럼 NN의 파라미터 변화한 정도와 단계별 사이즈를 고려하는 방법
    
  
  Adam
    
      RMSprop과 Momentum의 개념을 합친 방법
      G의 변화 정도, 단계별 사이즈, 이전 단계에서 사용된 값을 고려
      일반적으로 많이 사용됨
    
  




Regularization

정의


  Generalization(오차)를 줄이고 싶은 목적으로 방해되는 요소를 규제하는 방법




종류


  Early Stopping
    
      validation error가 커지는 시점을 기준으로 멈추는 방법
    
  
  Parameter Norm Penalty
    
      NN 파라미터가 너무 커지지 않도록 패널티를 부여하는 방법
    
  
  Data Augmentation
    
      데이터를 여러가지 방식으로 데이터를 늘려서 Input으로 사용하는 방법
      사진을 예시로 하면, 회전, 반전, 사이즈 수정 등이 있음
    
  
  Noise Robustness
    
      데이터에 불규칙한 노이즈를 추가해서 Input이나 weights로 사용하는 방법
      글자를 예시로 하면, 해상도를 낮추는 방법이 있음
    
  
  Lebel Smoothing
    
      학습데이터 2개를 뽑아서 섞어서 Input으로 사용하는 방법
      분류에 대한 기준을 찾기 위해 사용, 학습한 데이터 양에 비해 높은 성능을 보임
      사진을 예시로 하면, 강아지, 고양이에 대해 이미지와 분류 비율을 섞어서 사용함
    
  
  Dropout
    
      설정한 파라미터 값만큼 NN의 Weight을 바꿔서, 일부 neuron을 0으로 바꾸는 방법
    
  
  Batch Normalization
    
      평균을 빼고 분산을 나눠서(표준 편차를 줄이는) 방법
      각 층의 값들을 100이라 하면 0으로 줄임
      층이 많이 쌓일수록 높은 성능을 보여주지만, 논란이 많은 방법임
    
  




Reference


  제대로 된 인공지능 스터디를 찾고 있다면? AI 심화 스터디
  [코칭스터디 10기] Beyond AI Basic 2023 스터디 전용강좌

">



<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://dong-jun-shin.github.io/images/CS_AI_ML/logo.png">


<!-- Open Graph -->
<meta property="og:locale" content="">
<meta property="og:type" content="article">
<meta property="og:title" content="코칭스터디 Beyond AI Basic 2023 - 3주차 학습">

<meta property="og:image" content="https://dong-jun-shin.github.io/images/CS_AI_ML/logo.png">


<meta property="og:description" content="딥러닝 기초

딥러닝 기본 용어 설명

딥러닝을 활용하는 데이터 사이언티스트가 갖춰야 할 역량


  프로그래밍 역량(Implementation Skills)
    
      텐서플로우, 파이토치
    
  
  수학 및 통계 역량(Math Skills)
    
      선형 대수학(Linear Algebra)
      확률(Probability)
    
  
  관련 도메인 지식(Knowing Papers)
    
      많은 양의 최신 자료
    
  




딥러닝의 정의


  Artificial Intelligence &gt; Machine Learning &gt; Deep Learning




딥러닝의 핵심 요소


  모델이 학습 가능한 데이터
    
      문제에 의존성을 가짐
      데이터의 종류
        
          정의 문제(Classification)
          특징 분류 문제(Semantic Segmentation)
          탐색 문제(Detection)
          자세 판단 문제(Pose Estimation)
          시각적 질의응답 문제(Visual QnA)
        
      
    
  
  데이터를 원하는 것으로 변환해주는 모델
    
      input(x)로 output(y)를 도출하기 위한 파라미터들(w, b)을 찾기 위한 것
      2012 ~ 2020까지 대표적인 모델 예시
        
          AlexNet - 2012, 첫 딥러닝 모델
          DQN - 2013, 딥 마인드에서 게임을 학습하는데 사용한 모델
          Encoder/Decoder - 2014, 번역 등에 사용한 모델
          AdamOptimizer - 2014, 수많은 하이퍼 파라미터의 최적화에 높은 성능을 보이는 모델
          GAN - 2015, 이미지 생성 모델
          ResNet(Residual Networks) - 2015, NN의 층을 깊게 쌓아 성능을 높인 모델
          Transformer - 2017, 기존 방법론들을 대체한 중요한 모델
          BERT - 2018, 소수의 데이터를 fine-tuning 하는 개념이 적용된 모델
          BIG language Models - 2019, GPT 같은 가장 진보된 NLP 모델
          Self Supervised Learning - 2020, SimCLR 같은 라벨되지 않은 데이터를 학습에 함께 활용하는 방법
        
      
      그 외 모델
        
          GoogLeNet
          DenseNet
          LSTM
          Deep AutoEncoders
        
      
    
  
  정해진 모델과 데이터로 어떻게 학습할 지에 대한 손실 함수(Loss function)
    
      손실률(실제와 예측의 차이)을 근사치로 표현한 함수
      클수록 오답이고, 작을수록 정답
      종류
        
          회귀 문제(Regression Task)
            
              평균 제곱 오차 (MSE, Mean-Squared Error)
                
                  학습값과 예측값의 오차 제곱을 계산한 값
                  연속적 분포의 특성을 갖는 선형 회귀에서 주로 사용
                
              
            
          
          분류 문제(Classification)
            
              크로스 엔트로피 (CE, Cross-Entropy)
                
                  확률 분포와 예측 분포 사이의 차이를 측정
                  이산적 분포의 특성을 갖는 다항 분류에 주로 사용
                
              
            
          
          확률 문제(Probability)
            
              최대 가능도 추정 (MLE, Maximum Likelihood Estimation)
                
                  각 샘플에 있는 특징을 기여도로 계산해서 다 곱한 값
                  데이터의 밀도를 추정하는 방법으로 값에 대한 평균과 분산으로 모델링할 때 주로 사용
                
              
            
          
        
      
    
  
  손실률을 최소화하는 최적화 목적의 알고리즘
    
      한정된 데이터로 모델과 손실 함수를 바꿔가며 높은 성능을 내도록 함
      Dropout
      Early stopping
      k-fold validation
      Weight decay
      Batch normalization
      MixUp
      Ensemble
      Bayesian Optimization
    
  




뉴럴 네트워크 - MLP

Neural Networks


  포유류의 신경망을 기반으로 분류, 생성, 변환 등 함수를 모방한 개념




Linear Neural Networks


  학습된 데이터가 선형의 모습으로 이루어진 가장 간단한 NN의 개념
  n차원 값에서 m차원 값을 찾고 싶은 경우, 행렬을 곱함
    
      2개의 벡터 공간 사이의 선형성을 찾는 것
    
  
  Data: x, y로 구성된 1차원 값 N개로 구성
  Model: x를 w라는 스칼로 곱하고, b라는 바이어스를 더함
    
      모델은 x에서 y를 도출하기 위한 w, b를 찾는 것이 목적
    
  
  Loss: MSE를 사용




Beyond Linear Neural Networks


  선형 결합의 반복을 통해 네트워크를 여러개 쌓는 방법
  Non-linear transform(p)을 선형 결합들 사이에 추가해서 반복 결합
    
      단순한 선형 결합은 행렬이 대칭하지 않기 때문에 하나인 네트워크와 같음
    
  
  Activation functions
    
      Non-linear transform을 위한 함수
      종류
        
          Rectified Linear Unit(ReLU)
            
              0보다 큰 값은 그대로 쓰고, 작은 값은 0으로 두는 방법
            
          
          Sigmoid
            
              출력값을 0 ~ 1로 제한하는 것
            
          
          Hyperbolic Tangent
            
              출력값을 +, -로 제한하는 것
            
          
        
      
    
  




Multi-Layer Perceptron


  input layer(x), hidden layer(h), output layer(y) 등으로 구성됨
  linear 또는 transformation 등 변환하는 작업을 하는 hidden layer가 있음




최적화

최적화의 주요 용어 이해하기

Introduction


  최적화는 빠르고 정확한 학습을 위한 개념
  Gradient Descent
    
      1차 미분값을 사용하여 계속 최적화를 반복해서 loss function을 최소화시키는 것
    
  




최적화에 있어 중요한 컨셉(Important Concepts in Optimization)


  Generalization
    
      Input data가 달라져도 Output에 대한 성능차이가 나지 않는 현상
      학습 데이터와 테스트 데이터 사이의 차이
        
          좋다 =&gt; 차이가 적어서 학습한만큼 나온다
        
      
      학습 데이터 자체가 안 좋을 경우, Generalization이 좋더라도 안 좋을 수 있음
    
  
  Underfitting vs. Overfitting
    
      과소적합, 과적합은 해석하기에 따라 달라질 수 있기 때문에 이론에 가까운 개념임
    
  
  Cross-validation
    
      학습데이터를 k개로 나누어 fold를 구성하고, 각 fold로 model을 생성하고 검증하는 K-fold cross-validation이 있음
      이 때 절대 테스트 데이터는 사용하면 안됨
    
  
  Bias and Variance
    
      두가지는 반비례함
      Bias: 평균적으로 봤을 때, 일관된 출력을 보이는 정도 (낮을수록 일관됨)
      Variance: 입력에 대해 일관된 출력을 보이는 정도 (낮을수록 일관됨)
    
  
  Bias and Variance Tradeoff
    
      cost를 줄이기 위해서, Bias와 Variance, noise를 두고 고민해야 함
    
  
  Bootstrapping
    
      데이터 중 랜덤하게 일부를 뽑아 샘플링하고 각각의 모델을 생성하는 방법
      모델들의 예측값이 일치하는 정도를 보고, 전체적인 모델의 예측을 보고자 할 때 사용
    
  
  Bagging vs. Boosting
    
      Bagging(Bootstrapping aggregating): 동일 모델을 여러개 만들어 각각 학습(병렬 학습)
      Boosting: 순차적으로 학습(직렬 학습)
    
  




Gradient Descent Methods

Practical Gradient Descent Methods


  Stochastic gradient descent
    
      전체 데이터 중 하나의 샘플을 이용해서 하나의 Gradient를 구하는 것을 반복하는 것
    
  
  Mini-batch gradient descent
    
      전체 데이터 중 일부를 이용해서 하나의 Gradient를 구하는 것을 반복하는 것
      보통 제일 많이 사용하는 방법
    
  
  Batch gradient descent
    
      전체 데이터 모두를 이용해서 하나의 Gradient를 구하는 것을 반복하는 것
    
  




Batch-size 문제


  Testing Function의 Minimum을 찾는 것이 중요
  Minimum의 개념
    
      제일 잘 예측하는 지점
      Flat Minimum
        
          Testing Function과 편차가 크지 않아, 학습 데이터에서 나온 성능만큼 보여주는 것
          Generalization가 높음
        
      
      Sharp Minimum
        
          Testing Function과 편차가 커서, 학습 데이터에서 나온 성능과 차이가 큼
          Generalization가 낮음
        
      
    
  




종류


  공식의 용어
    
      W:  NN의 Weight를 뜻함
      에타(η): Learning rate
      g: Gradient
      t: Step size
      베타(β): momentum
      엡실론(ε): 분모가 0이 되는 것을 방지하기 위한 값(분모값의 안정성을 위한 값)
      G: 파라미터가 변화한 정도를 누적한 값(gradient 제곱합)
    
  
  Stochastic Gradient Descent
    
      데이터 그대로 학습하는 방법
      Learning rate와 Gradient를 곱한 값을 Weight에서 뺌
      적절한 Learning rate와 Step size를 찾기 어려움
    
  
  Momentum(관성)
    
      momentum을 하이퍼 파라미터로 곱해서 다음 단계에 값이 반영되도록 한 방법
      일정 구간동안 학습 데이터가 반영될 수 있음
    
  
  Nesterov Accelerated Gradient
    
      실제 계산되는 지점에 momentum을 가로질러서 도달하는 방법
      Lookahead gradient를 계산
      momentum보다 빠르게 도달할 수 있음
    
  
  Adagrad
    
      NN의 파라미터가 변화한 정도를 조정하는 방법
      많이 변화했으면 둔하게 만들고, 적게 변화했으면 민감해지도록 함
      G가 계속 커지게 되면 점점 학습이 둔화하는 문제가 있음
    
  
  Adadelta
    
      G를 단계별로 고려해서 시간에 따른 변화를 보는 방법
      Adagrad에서 G가 계속 커지는 현상을 막기위해 나왔으나, 많이 사용되지는 않음
      단계별로 이전 단계들의 파라미터를 가지고 있어서 속도에 문제가 있음
    
  
  RMSprop
    
      Adagrad처럼 NN의 파라미터 변화한 정도와 단계별 사이즈를 고려하는 방법
    
  
  Adam
    
      RMSprop과 Momentum의 개념을 합친 방법
      G의 변화 정도, 단계별 사이즈, 이전 단계에서 사용된 값을 고려
      일반적으로 많이 사용됨
    
  




Regularization

정의


  Generalization(오차)를 줄이고 싶은 목적으로 방해되는 요소를 규제하는 방법




종류


  Early Stopping
    
      validation error가 커지는 시점을 기준으로 멈추는 방법
    
  
  Parameter Norm Penalty
    
      NN 파라미터가 너무 커지지 않도록 패널티를 부여하는 방법
    
  
  Data Augmentation
    
      데이터를 여러가지 방식으로 데이터를 늘려서 Input으로 사용하는 방법
      사진을 예시로 하면, 회전, 반전, 사이즈 수정 등이 있음
    
  
  Noise Robustness
    
      데이터에 불규칙한 노이즈를 추가해서 Input이나 weights로 사용하는 방법
      글자를 예시로 하면, 해상도를 낮추는 방법이 있음
    
  
  Lebel Smoothing
    
      학습데이터 2개를 뽑아서 섞어서 Input으로 사용하는 방법
      분류에 대한 기준을 찾기 위해 사용, 학습한 데이터 양에 비해 높은 성능을 보임
      사진을 예시로 하면, 강아지, 고양이에 대해 이미지와 분류 비율을 섞어서 사용함
    
  
  Dropout
    
      설정한 파라미터 값만큼 NN의 Weight을 바꿔서, 일부 neuron을 0으로 바꾸는 방법
    
  
  Batch Normalization
    
      평균을 빼고 분산을 나눠서(표준 편차를 줄이는) 방법
      각 층의 값들을 100이라 하면 0으로 줄임
      층이 많이 쌓일수록 높은 성능을 보여주지만, 논란이 많은 방법임
    
  




Reference


  제대로 된 인공지능 스터디를 찾고 있다면? AI 심화 스터디
  [코칭스터디 10기] Beyond AI Basic 2023 스터디 전용강좌

">
<meta property="og:url" content="https://dong-jun-shin.github.io/2023/05/21/Beyond_AI_Basic_2023_Week_3/">
<meta property="og:site_name" content="Jun's Dev_Blog">
  <link rel="canonical" href="https://dong-jun-shin.github.io/2023/05/21/Beyond_AI_Basic_2023_Week_3/" />
  <link
    rel="alternate"
    type="application/rss+xml"
    title="Jun's Dev_Blog"
    href="https://dong-jun-shin.github.io/feed.xml"
  />
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css?family=Volkhov:400,700" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@200;300;400;500;700;900&display=swap" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css2?family=Courier+Prime:wght@700&display=swap" rel="stylesheet" />
  <!-- Common -->
  <style>
    
    /*! normalize.css v7.0.0 | MIT License | github.com/necolas/normalize.css */html,body{scroll-behavior:smooth}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{font-weight:normal;letter-spacing:0;margin:0}article,aside,footer,header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}figcaption,figure,main{display:block}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:rgba(0,0,0,0);-webkit-text-decoration-skip:objects}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}dfn{font-style:italic}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}img{border-style:none}svg:not(:root){overflow:hidden}button,input,optgroup,select,textarea{font-family:"Noto Sans KR",sans-serif;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,html [type=button],[type=reset],[type=submit]{-webkit-appearance:button}button::-moz-focus-inner,[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{display:inline-block;vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details,menu{display:block}summary{display:list-item}canvas{display:inline-block}template{display:none}[hidden]{display:none}body,h1,h2,h3,h4,h5,h6,p,blockquote,pre,dl,dd,ol,ul,fieldset,legend,figure,hr{margin:0;padding:0}li>ul,li>ol{margin-bottom:0}table{border:.14em solid #000;border-collapse:collapse;border-spacing:0;word-break:initial;width:100%}table tr:nth-child(even){background-color:#f2fafd}thead{background-color:#a0d0ee}table th{text-align:center;padding:6px 13px;border:.1em solid #757575}table td{padding:6px 13px;border:.1em solid #757575}table tr{padding:6px 13px;border:.1em solid #757575}@-webkit-keyframes spin{100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes spin{100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.icon{position:relative;display:inline-block;width:25px;height:25px;overflow:hidden;fill:currentColor}.icon__cnt{width:100%;height:100%;background:inherit;fill:inherit;pointer-events:none;transform:translateX(0);-ms-transform:translate(0.5px, -0.3px)}.icon--m{width:50px;height:50px}.icon--l{width:100px;height:100px}.icon--xl{width:150px;height:150px}.icon--xxl{width:200px;height:200px}.icon__spinner{position:absolute;top:0;left:0;width:100%;height:100%}.icon--ei-spinner .icon__spinner,.icon--ei-spinner-2 .icon__spinner{-webkit-animation:spin 1s steps(12) infinite;animation:spin 1s steps(12) infinite}.icon--ei-spinner-3 .icon__spinner{-webkit-animation:spin 1.5s linear infinite;animation:spin 1.5s linear infinite}.icon--ei-sc-facebook{fill:#3b5998}.icon--ei-sc-github{fill:#333}.icon--ei-sc-google-plus{fill:#dd4b39}.icon--ei-sc-instagram{fill:#3f729b}.icon--ei-sc-linkedin{fill:#0976b4}.icon--ei-sc-odnoklassniki{fill:#ed812b}.icon--ei-sc-skype{fill:#00aff0}.icon--ei-sc-soundcloud{fill:#f80}.icon--ei-sc-tumblr{fill:#35465c}.icon--ei-sc-twitter{fill:#55acee}.icon--ei-sc-vimeo{fill:#1ab7ea}.icon--ei-sc-vk{fill:#45668e}.icon--ei-sc-youtube{fill:#e52d27}.icon--ei-sc-pinterest{fill:#bd081c}.icon--ei-sc-telegram{fill:#08c}*,*::after,*::before{box-sizing:border-box}h1,h2,h3,h4,h5,h6,ul,ol,dl,blockquote,p,address,hr,table,fieldset,figure,pre{margin-bottom:20px}ul,ol,dd{margin-left:20px}.highlight{background:#f7f7f7}.highlighter-rouge .highlight{background:#0d1117;color:#e6edf3;border-radius:10px}.highlight .c{color:#7ca668;font-style:italic}.highlight .ch{color:#7ca668;font-style:italic}.highlight .cm{color:#7ca668;font-style:italic}.highlight .cp{color:#7ca668;font-style:italic;font-weight:normal}.highlight .cpf{color:#7ca668;font-style:italic}.highlight .c1{color:#7ca668;font-style:italic}.highlight .cs{color:#7ca668;font-style:italic}.highlight .err{color:#f85149}.highlight .esc{color:#e6edf3}.highlight .g{color:#e6edf3}.highlight .k{color:#c586c0}.highlight .l{color:#a5d6ff}.highlight .n{color:#e6edf3}.highlight .o{color:#d4d4d4}.highlight .x{color:#e6edf3}.highlight .p{color:#d4d4d4}.highlight .gd{color:#ffa198;background-color:#490202}.highlight .ge{color:#e6edf3;font-style:italic}.highlight .ges{color:#e6edf3;font-weight:bold;font-style:italic}.highlight .gr{color:#ffa198}.highlight .gh{color:#79c0ff;font-weight:bold}.highlight .gi{color:#56d364;background-color:#0f5323}.highlight .go{color:#8b949e}.highlight .gp{color:#8b949e}.highlight .gs{color:#e6edf3;font-weight:bold}.highlight .gu{color:#79c0ff}.highlight .gt{color:#ff7b72}.highlight .g-Underline{color:#e6edf3;text-decoration:underline}.highlight .kc{color:#79c0ff}.highlight .kd{color:#569cd6}.highlight .kn{color:#ff7b72}.highlight .kp{color:#79c0ff}.highlight .kr{color:#4ec9b0}.highlight .kt{color:#4ec9b0}.highlight .ld{color:#ce9178}.highlight .sd{color:#a5d6ff}.highlight .na{color:#e6edf3}.highlight .nb{color:#4ec9b0}.highlight .nc{color:#4ec9b0;font-weight:bold}.highlight .no{color:#79c0ff;font-weight:bold}.highlight .nd{color:#d2a8ff;font-weight:bold}.highlight .ni{color:#ffa657}.highlight .ne{color:#f0883e;font-weight:bold}.highlight .nf{color:#dcdcaa;font-weight:bold}.highlight .nl{color:#4ec9b0;font-weight:bold}.highlight .nn{color:#ff7b72}.highlight .nx{color:#9cdcfe}.highlight .py{color:#79c0ff}.highlight .nt{color:#4ec9b0}.highlight .nv{color:#79c0ff}.highlight .ow{color:#ff7b72;font-weight:bold}.highlight .pm{color:#e6edf3}.highlight .w{color:#6e7681}.highlight .mb{color:#a5d6ff}.highlight .mf{color:#b5cea8}.highlight .mh{color:#a5d6ff}.highlight .mi{color:#b5cea8}.highlight .mo{color:#a5d6ff}.highlight .sa{color:#79c0ff}.highlight .sb{color:#a5d6ff}.highlight .sc{color:#a5d6ff}.highlight .dl{color:#ce9178}.highlight .sd{color:#a5d6ff}.highlight .s{color:#ce9178}.highlight .s1{color:#ce9178}.highlight .s2{color:#ce9178}.highlight .se{color:#79c0ff}.highlight .sh{color:#79c0ff}.highlight .si{color:#a5d6ff}.highlight .sx{color:#a5d6ff}.highlight .sr{color:#79c0ff}.highlight .ss{color:#a5d6ff}.highlight .bp{color:#e6edf3}.highlight .fm{color:#d2a8ff;font-weight:bold}.highlight .vc{color:#79c0ff}.highlight .vg{color:#79c0ff}.highlight .vi{color:#79c0ff}.highlight .vm{color:#79c0ff}.highlight .il{color:#a5d6ff}body{font-family:"Open Sans",Helvetica Neue,Helvetica,"Noto Sans KR",Arial,sans-serif;font-size:16px;line-height:28px;color:#404040;background-color:#fbfbfb;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}*::selection{color:#fff;background-color:#3af}.toc-container{margin-bottom:20px;display:flex;justify-content:center}.toc{background-color:#fff;border:1px solid #edeeee;border-radius:8px;padding:20px;box-shadow:0 2px 4px rgba(0,0,0,.1);width:100%;font-family:"Noto Sans KR",sans-serif;text-align:left}.toc-title{font-family:"Noto Sans KR",sans-serif;font-size:32px;font-weight:700;color:#05b;margin-bottom:20px;text-align:left;background-color:rgba(204,238,255,.5);padding:15px;border-radius:5px;border:1px solid #ccc}.toc ul{list-style-type:disc;padding-left:15px}.toc a{font-family:"Noto Sans KR",sans-serif;font-size:16px;color:hsl(205,100%,45%);text-decoration:none;display:block;transition:color .3s ease,background-color .3s ease}.toc a:hover{background-color:#eee;color:rgb(0,89.25,153);text-decoration:underline}.toc a:active{color:#05b}.toc .list-group-item.active{background-color:rgba(34,34,34,.8);color:#fff;font-weight:bold;border-radius:5px}.toc .list-group-item.disabled{color:#6c757d;background-color:rgba(0,0,0,0)}.toc .list-group-item+.list-group-item{margin-top:8px}h1,h2,h3,h4,h5,h6{font-family:"Noto Sans KR",serif;font-weight:700;line-height:initial}h1{font-weight:700;font-size:36px;line-height:110%;margin-top:1.6em;margin-bottom:.8em}h2{font-weight:700;font-size:32px;margin-top:1.6em;margin-bottom:.8em}h3{font-weight:700;font-size:28px;margin-top:1.8em;margin-bottom:.9em}h4{font-weight:700;font-size:24px;margin-top:2em;margin-bottom:1em}h5{font-weight:700;font-size:22px;margin-top:2em;margin-bottom:1em;color:#333}h6{font-weight:700;font-size:20px;margin-top:2em;margin-bottom:1em;color:#444}img{max-width:100%;height:auto;vertical-align:middle}img+strong:before{display:inline-block;content:"▲";padding-right:5px;font-size:14px}img+strong{display:block;font-size:14px}p:has(>img):has(>strong){max-width:90%;margin:50px auto;text-align:center}a{text-decoration:none;color:hsl(205,100%,45%);transition:.35s}a:hover{color:rgb(0,89.25,153)}blockquote{padding-left:20px;border-left:4px solid #3af;font-family:"Noto Sans KR",serif;font-style:normal;font-size:14px;background-color:rgb(237.58,248.3,252.32)}blockquote p{padding:10px}hr{height:4px;margin:20px 0;border:0;background-color:#6b6b6b}pre{overflow:auto;padding:14px;font-size:14px;white-space:pre-wrap;word-wrap:break-word;word-break:break-all;font-family:Courier,"Noto Sans KR",monospace}pre.highlight{padding:15px 20px}code{border-radius:10px;overflow:auto;white-space:pre-wrap;word-wrap:break-word;word-break:break-all;font-family:Menlo,Monaco,"Courier New",monospace;font-weight:bold;font-size:14px;vertical-align:middle}p code,li code{color:#eb5757;background-color:#edeeee;margin:0 2px;padding:5px 6px}pre code{font-size:14px;color:#ddd;background-color:rgba(0,0,0,0)}.language-plaintext code{color:#ddd}.o-wrapper{max-width:1440px;position:relative}.o-opacity{animation-duration:.7s;animation-delay:.2s;animation-fill-mode:both;animation-name:opacity}@keyframes opacity{from{opacity:0}to{opacity:1}}.c-btn{display:inline-block;white-space:nowrap;vertical-align:middle;font-family:"Noto Sans KR",serif;font-size:14px;text-align:center;padding:5px 15px;cursor:pointer;transition:.35s}.c-btn--primary{color:#fff;background-color:#3af;background:linear-gradient(135deg, #33aaff 0%, #62d5ff 100%)}.c-btn--secondary{color:#fff;background-color:#cfcfdd;background:linear-gradient(135deg, #a2a2bd 0%, #cfcfdd 100%)}.c-btn--bar{color:#fff;background-color:#444;background:#525252;font-size:14px;width:76%;height:40px}.c-btn--round{border-radius:30px}.c-btn--shadow{box-shadow:8px 10px 20px 0 rgba(46,61,73,.15)}.c-btn--shadow:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,.2)}.c-btn--middle{display:block;width:300px;max-width:100%}.c-btn--big{display:block;width:100%}.c-btn:hover{color:#fff;transition:.35s}.c-btn:active{transform:translateY(2px)}.c-sidebar{display:flex;flex-direction:column;justify-content:space-between;position:fixed;top:0;left:0;bottom:0;width:360px;padding:40px 20px 20px;text-align:center;box-shadow:1px 1px 0 rgba(31,35,46,.15);background-color:#fff}.c-sidebar-author{display:flex;flex-direction:column}.c-sidebar-author .c-author__cover{width:100px;height:100px;margin:0 auto 10px;border-radius:50%;overflow:hidden;background-color:#cfcfdd}.c-sidebar-author .c-author__cover img{width:100%;height:100%;border-radius:50%;transition:.35s}.c-sidebar-author .c-author__cover img:hover{transform:scale3d(0.9, 0.9, 1)}.c-sidebar-author .c-contact-menu .c-btn{min-width:110px}.c-sidebar-author .c-contact-menu .c-btn .icon{vertical-align:text-bottom;fill:#fff}.c-sidebar-author .c-author__info{font-family:"Noto Sans KR",serif}.c-sidebar-author .c-author__name{font-size:18px;font-weight:700;line-height:21px}.c-sidebar-author .c-author__job{font-size:12px;color:#a0a0a0;margin:5px 0 0}.c-sidebar-author .c-contact-menu{justify-items:center;margin:30px 0px 10px 0px}.c-sidebar-author .c-contact-menu .c-btn{width:130px}.c-sidebar-author .c-contact-menu-bar{justify-items:center;margin:0px 0px 25px 0px}.c-sidebar-author .c-contact-menu-bar .c-btn{font-size:14px;width:260px}.c-sidebar-author .c-author__about{max-width:400px;margin:0 auto 15px;font-size:13px}.c-sidebar-footer .c-social__title{position:relative;font-family:"Noto Sans KR",serif;font-size:16px;font-weight:700;color:#444}.c-sidebar-footer .c-social__title::before{content:"";display:block;height:2px;width:calc(50% - 40px);transform:translateY(-50%);position:absolute;top:50%;left:0;background-color:#444}.c-sidebar-footer .c-social__title::after{content:"";display:block;height:2px;width:calc(50% - 40px);transform:translateY(-50%);position:absolute;top:50%;right:0;background-color:#444}.c-sidebar-footer .c-social__list{list-style-type:none;padding:0;margin:15px 0}.c-sidebar-footer .c-social__list .c-social__item{display:inline-block;width:27px;height:27px}.c-sidebar-footer .c-social__list .icon{width:27px;height:27px;fill:#444;vertical-align:middle;transition:.35s}.c-sidebar-footer .c-social__list .icon:hover{fill:#3af;transform:scale(1.2);transition:.35s}.c-sidebar-footer .c-copyright p{font-size:13px;margin:0}@media only screen and (max-width: 900px){.c-sidebar{position:relative;width:100%;padding:20px}.c-sidebar .c-contact-menu{margin:20px 0}.c-sidebar-footer .c-social .c-social__title{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}.c-sidebar-footer .c-social__list{margin:0}.c-sidebar-footer .c-copyright{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}}@media only screen and (max-width: 480px){.c-sidebar-author{display:flex;flex-direction:column}.c-sidebar-author .c-author__cover{width:80px;height:80px}.c-sidebar-author .c-author__cover img{width:100%;height:100%}.c-sidebar-author .c-contact-menu{justify-items:center;margin:15px 0px 0px 0px;min-width:245px}.c-sidebar-author .c-contact-menu .c-btn{min-width:80px;font-size:12px;width:120px;height:36px;margin-bottom:10px}.c-sidebar-author .c-contact-menu-bar{justify-items:center;margin:0px 0px 25px 0px}.c-sidebar-author .c-contact-menu-bar .c-btn{min-width:80px;font-size:12px;width:244px;height:36px;padding:4px 15px}.c-sidebar-footer .c-social .c-social__title{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}.c-sidebar-footer .c-social__list{margin:0}.c-sidebar-footer .c-social__list .icon{width:25px;height:25px}.c-sidebar-footer .c-copyright{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}}.c-content{position:relative;display:flex;flex-direction:row;flex-wrap:wrap;align-items:stretch;padding:0 20px 0;margin-left:360px}@media only screen and (max-width: 900px){.c-content{position:static;padding:0 15px 0;margin-left:0}}.c-posts{width:100%;display:flex;flex-direction:row;flex-wrap:wrap}.c-post{width:100%;max-width:100%;margin-bottom:20px;display:flex;flex-direction:row;align-items:stretch;min-height:180px;border-radius:10px;overflow:hidden;transition:.35s;background-color:#fff;box-shadow:0 1px 1px 0 rgba(31,35,46,.15)}.c-post:hover{transform:translate(0px, -2px);box-shadow:0 15px 45px -10px rgba(10,16,34,.2)}.c-post .c-post-thumbnail{display:block;width:30%;max-width:100%;min-height:180px;border-radius:10px 0 0 10px;background-color:rgba(220,235,245,.2);background-size:cover;background-position:50% 50%}.c-post .c-post-content{padding:15px;width:70%}.c-post .c-post-content .c-post-title{font-size:30px;font-weight:400;margin:0 0 15px}.c-post .c-post-content .c-post-title a{text-decoration:none;color:#263959}.c-post .c-post-content .c-post-tags{padding:3px 5px;border-radius:3px;background-color:rgba(135,131,120,.2);color:#eb5757;font-size:85%;font-family:"Courier Prime","Noto Sans KR"}.c-post .c-post-content .c-post-date,.c-post .c-post-content .c-post-words{font-size:12px}.c-load-more{padding:20px;margin:20px auto 40px;font-size:13px;color:#fff;border:none;background-color:#3af;outline:none}.c-load-more:hover{background-color:hsl(205,100%,45%)}@media only screen and (max-width: 1200px){.c-post{width:48%;max-width:100%;margin:0 1% 20px;flex-direction:column}.c-post .c-post-thumbnail{width:100%;border-radius:10px 10px 0 0}.c-post .c-post-content{width:100%}.c-post .c-post-content .c-post-title{font-size:21px;margin:15px 0}}@media only screen and (max-width: 480px){.c-post{width:100%;max-width:100%;margin:0 0 20px}.c-post .c-post-content{width:100%}.c-post .c-post-content .c-post-title{font-size:21px;margin:15px 0}}.c-article{width:100%;margin:20px 0}.c-wrap-content{padding:7%;background-color:#fff}.c-article__image{position:relative;background-color:rgba(220,235,245,.2);background-position:center;background-size:cover;background-repeat:no-repeat}.c-article__image:after{content:"";display:block;padding-top:56%}.c-article__header{margin-bottom:60px;padding-bottom:10px;text-align:center;border-bottom:1px solid #6b6b6b}.c-article__header .c-article__title{margin-bottom:10px}.c-article__date span{font-size:13px;text-transform:uppercase;color:#a0a0a0}.c-article__footer{margin:60px 0 0;padding-top:20px;padding-bottom:10px;text-align:center;border-top:1px solid #6b6b6b}.c-article__footer .c-article__share{transition:.35s}.c-article__footer .c-article__share a .icon{vertical-align:middle;transition:.35s}.c-article__footer .c-article__share a .icon:hover{opacity:.7;transition:.35s}.c-article__footer .c-article__tag{margin-bottom:5px}.c-article__footer .c-article__tag a{display:inline-block;vertical-align:middle;padding:5px 10px;font-family:"Noto Sans KR",serif;font-size:10px;line-height:10px;text-transform:uppercase;background-color:rgba(115,138,160,.6);color:#fff}.c-article__footer .c-article__tag a:hover{background-color:rgba(80.2446808511,99.6723404255,118.2553191489,.6)}.c-article__footer .c-article__tag a:last-child{margin-right:0}.c-recent-post{padding:30px 0}.c-recent-post .c-recent__title{font-size:14px;text-align:center;text-transform:uppercase;margin-bottom:30px}.c-recent-post .c-recent__box{display:flex;flex-direction:row;flex-wrap:wrap}.c-recent-post .c-recent__item{max-width:23%;flex-basis:23%;margin:0 1% 20px;border-radius:10px;overflow:hidden;text-align:center;background-color:#fff;box-shadow:0 1px 1px 0 rgba(31,35,46,.15);transition:.35s}.c-recent-post .c-recent__item h4{margin-bottom:5px;font-size:12px;text-transform:uppercase}.c-recent-post .c-recent__item h4 a{color:#444}.c-recent-post .c-recent__item:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,.2)}.c-recent-post .c-recent__footer{padding:15px}.c-recent-post .c-recent__image{display:block;width:100%;min-height:180px;background-color:rgba(220,235,245,.2);background-size:cover;background-position:center;background-repeat:no-repeat}.c-recent-post .c-recent__date{color:#a0a0a0;font-size:12px}@media only screen and (max-width: 1200px){.c-recent-post .c-recent__item{max-width:48%;flex-basis:48%}}@media only screen and (max-width: 900px){.c-article{margin:15px 0}}@media only screen and (max-width: 480px){.c-wrap-content{padding:15px}.c-article__header{margin-bottom:5px}.c-article__header .c-article__title{font-size:24px;margin-bottom:5px}.c-recent-post .c-recent__item{max-width:100%;flex-basis:100%;margin:0 0 20px}}.c-blog-tags{width:100%;padding:20px;margin:20px 0 40px;background-color:#fff}.c-blog-tags h1{text-align:center;margin-bottom:0}.c-blog-tags h2{font-size:18px;text-transform:uppercase;margin:30px 0;color:#757575}.c-tag__list{list-style:none;padding:0 0 40px;margin:40px 0 0;border-bottom:1px solid #6b6b6b}.c-tag__list li{display:inline-block;margin-right:15px}.c-tag__list li a{color:#404040;text-transform:uppercase;font-size:12px}.c-tag__list li a:hover{color:hsl(0,0%,-4.9019607843%)}.c-tag__item{margin-bottom:15px}.c-tag__image{width:50px;height:50px;border-radius:50%;margin-right:5px}@media only screen and (max-width: 480px){.c-blog-tags{padding:15px}.c-blog-tags h1{font-size:27px}.c-blog-tags h2{font-size:16px;margin:15px 0}.c-tag__list{padding:0 0 30px;margin:30px 0 0}.c-tag__item{margin-bottom:5px}.c-tag__image{display:none}}.c-header{position:relative;width:100%;margin:20px 0}.c-header__box{position:relative;display:flex;flex-direction:row;justify-content:space-between;align-items:center}.c-header__box .icon--ei-search{position:absolute;top:7px;left:15px;fill:#ccc}.c-search{width:80%}.c-search .c-search__box{display:flex;align-items:center}.c-search .c-search__text{position:relative;width:100%;padding:10px 10px 10px 40px;border:1px solid #f2fafd;border-radius:30px;outline:none;color:#a0a0a0}.c-search .c-search__text::placeholder{color:#ccc}.c-search .c-search__text:hover{box-shadow:0 1px 0px rgba(132,135,138,.1);transition:.35s}.c-search .c-search-results-list{position:absolute;width:100%;margin:10px 0 0;list-style-type:none;background-color:#fff;z-index:1}.c-search .c-search-results-list li{display:flex;flex-wrap:wrap;align-items:center;margin:0;padding:20px 25px 0;background-color:#fff;line-height:1.4;border-left:solid 1px #edeeee;border-right:solid 1px #edeeee}.c-search .c-search-results-list li:first-child{border-top-left-radius:5px;border-top-right-radius:5px;border-top:solid 1px #edeeee}.c-search .c-search-results-list li:last-child{border-bottom-left-radius:5px;border-bottom-right-radius:5px;padding-bottom:25px;border-bottom:solid 1px #edeeee}.c-search .c-search-results-list li a{font-size:16px}.c-nav{flex-grow:1;padding-left:20px}.c-nav .c-nav__list{display:flex;justify-content:flex-end}.c-nav .c-nav__list .c-nav__item{display:flex;align-items:center;float:left;padding:4px 10px;font-size:10px;text-transform:uppercase;white-space:nowrap;border:1px solid #f2fafd;box-shadow:0 1px 0px rgba(132,135,138,.4);will-change:transform;transform:translateY(0px);cursor:pointer}.c-nav .c-nav__list .c-nav__item:hover{color:#222;background-color:#fff}.c-nav .c-nav__list .c-nav__item.is-active{box-shadow:0 0 0 rgba(132,135,138,.5);transform:translateY(1px);color:#cfcfdd}.c-nav .c-nav__list .c-nav__item.is-active:hover{background-color:#fbfbfb}.c-nav .c-nav__list .c-nav__item:first-child{border-radius:10px 0 0 10px}.c-nav .c-nav__list .c-nav__item:last-child{border-radius:0 10px 10px 0}.c-nav .c-nav__list .c-nav__item .icon{width:18px;height:18px;margin-right:3px}@media only screen and (max-width: 900px){.c-header{margin:15px 0}}@media only screen and (max-width: 480px){.c-header .c-header__box{flex-direction:column}.c-header .c-search{width:100%}.c-header .c-search .c-search__text{padding:8px 8px 8px 40px}.c-header .c-nav{margin-top:15px}.c-header .c-nav .c-nav__list{justify-content:center}.c-header .c-nav .c-nav__item{padding:4px 8px}}.c-categories{width:100%}.c-categories__list{width:100%;display:flex;flex-direction:row;flex-wrap:wrap}.c-categories__item{max-width:25%;flex-basis:25%;padding:0 10px 20px}.c-categories__link{height:100%;display:flex;flex-direction:column;align-items:center;padding:20px 10px;border-radius:5px;box-shadow:5px 5px 25px rgba(46,61,73,.15);background-color:#fff;transition:.35s}.c-categories__link:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,.2)}.c-categories__link:hover .c-categories__img .c-categories__more{opacity:1;transition:.35s}.c-categories__link .c-categories__container{width:100%;word-wrap:break-word}.c-categories__link .c-categories__container.c-empty-figure{display:flex;flex-direction:column;justify-content:center;flex-grow:1}.c-categories__img{position:relative;max-width:100%}.c-categories__img figure{position:relative;width:200px;max-width:100%;margin-bottom:20px;overflow:hidden;background-size:cover;background-repeat:no-repeat;background-position:center;border-radius:50%;box-shadow:inset 0 1px 3px rgba(141,165,185,.3)}.c-categories__img figure:after{content:"";display:block;padding-top:100%}.c-categories__img figure:before{content:"";position:absolute;top:0;bottom:0;left:0;right:0;background-color:rgba(0,0,0,.15)}.c-categories__img .c-categories__more{display:inline-block;position:absolute;top:50%;left:50%;transform:translate(-50%, -50%);font-weight:700;color:#fff;text-transform:uppercase;text-shadow:0 1px 0 rgba(104,172,191,.3);opacity:0;transition:.35s}.c-categories__container{text-align:center}.c-categories__container .c-categories__header{font-size:13px;margin-bottom:10px;font-weight:normal;text-transform:uppercase;color:#404040}.c-categories__container .c-categories__count{font-family:"Noto Sans KR",serif;font-size:12px;color:#404040;margin-bottom:0}.c-categories__container .c-categories__count span{display:inline-block;width:20px;height:20px;line-height:20px;vertical-align:baseline;margin-right:5px;border-radius:50%;color:#fff;background-color:#ee6c6c}@media only screen and (max-width: 1200px){.c-categories .c-categories__item{max-width:33.333%;flex-basis:33.333%}}@media only screen and (max-width: 1050px){.c-categories .c-categories__item{max-width:50%;flex-basis:50%}}@media only screen and (max-width: 480px){.c-categories .c-categories__item{max-width:100%;flex-basis:100%;padding:0 0 20px}}.c-form-box{position:absolute;top:0;width:calc(100% - 40px);min-height:100vh;padding:0 20px;background-color:#fff;z-index:1}.c-form-bnt__close{position:absolute;top:0px;left:0;width:30px;height:30px;cursor:pointer;transition:.35s}.c-form-bnt__close:hover{transform:scale(0.8);opacity:.8}.c-form{position:relative;width:750px;max-width:100%;margin:40px auto}.c-form .c-form__title{margin:0 0 40px;min-width:0;border:0;padding:0;font-family:"Noto Sans KR",serif;text-transform:uppercase;text-align:center}.c-form a{color:#404040}.c-form__group{margin-bottom:20px}.c-form__group label{display:block;text-transform:uppercase;font-size:10px}.c-form__group input,.c-form__group textarea{width:100%;padding:10px 15px;color:#404040;border:1px solid #f2fafd;outline:none;transition:.35s}.c-form__group input:focus,.c-form__group textarea:focus{box-shadow:0 4px 25px rgba(132,135,138,.1)}.c-form__group button{padding:20px;text-transform:uppercase;outline:none;border:none}.c-thank-you p{position:relative;padding:20px 40px;width:750px;max-width:100%;text-transform:uppercase;font-size:12px;line-height:18px;font-weight:700;margin:40px auto 0;text-align:center;color:#fff;background:linear-gradient(135deg, #55b5ad 0%, #5ec9c5 100%)}.c-thank-you p .c-form-bnt__close{width:25px;height:25px;background:rgba(0,0,0,0)}.c-thank-you p a{color:#fff}@media only screen and (max-width: 900px){.c-form-box{width:100%;left:0;right:0}}@media only screen and (max-width: 480px){.c-form-bnt__close{width:25px;height:25px}}.c-newsletter{padding:30px 0 60px;margin:0 auto;border-bottom:1px solid #6b6b6b}.c-newsletter__header{text-align:center}.c-newsletter__header .c-newsletter__title{font-size:14px;text-transform:uppercase;text-align:center}.c-newsletter__header .c-newsletter__subtitle{margin-bottom:15px}.c-newsletter-form{width:100%;max-width:750px;margin:0 auto}.c-newsletter-form .c-newsletter-form__group{display:flex}.c-newsletter__email{width:70%;height:40px;padding:10px 15px;border:1px solid #ddd;border-right-color:rgba(0,0,0,0);outline:none;transition:.35s}.c-newsletter__email:focus{box-shadow:0 4px 25px rgba(132,135,138,.1)}.c-newsletter__button{width:30%;height:40px;color:#fff;background-color:#3af;transition:.35s;border:none;outline:none;cursor:pointer}.c-newsletter__button:hover{background-color:hsl(205,100%,45%)}@media only screen and (max-width: 480px){.c-newsletter__button{font-size:13px}}.c-comments{padding:30px 0;border-top:1px solid #6b6b6b}.c-top{position:fixed;width:40px;height:40px;bottom:20px;color:#05b;background-color:#cef;border-radius:50%;cursor:pointer;transition:.35s;right:-100px;z-index:10;opacity:.5}.c-top--active{right:15px}.c-top:hover{color:#757575;opacity:1}.u-text-left{text-align:left}.u-text-right{text-align:right}.u-text-center{text-align:center}.u-text-justify{text-align:justify}.u-block{display:block}.u-inline-block{display:inline-block}.u-inline{display:inline}.u-full-width{display:block;width:100%}.u-vertical-center{display:flex;align-items:center;justify-content:center}.u-responsive-image{max-width:100%;height:auto;vertical-align:middle}.u-show{display:block !important}.u-hide{display:none !important}.u-invisible{visibility:hidden}.u-float-left{float:left}.u-float-right{float:right}.u-no-padding-top{padding-top:0}.u-no-padding-bottom{padding-bottom:0}.u-no-padding-left{padding-left:0}.u-no-padding-right{padding-right:0}.u-no-padding{padding:0}.u-no-margin-top{margin-top:0}.u-no-margin-bottom{margin-bottom:0}.u-no-margin-left{margin-left:0}.u-no-margin-right{margin-right:0}.u-no-margin{margin:0}.u-lists-reset{list-style-type:none;margin:0;padding:0}.u-clearfix::before,.u-clearfix::after{content:"";display:table;clear:both}.u-screen-reader-text{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}
  </style>
  <!-- KaTeX 관련 파일 -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" />
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
          { left: "\\(", right: "\\)", display: false },
          { left: "\\[", right: "\\]", display: true },
        ],
      });
    });
  </script>
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-VNMTFT1R2R"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "G-VNMTFT1R2R");
  </script>
</head>


<body>
  
    <script>
  (function (i, s, o, g, r, a, m) {
  i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
    (i[r].q = i[r].q || []).push(arguments)
}, i[r].l = 1 * new Date(); a = s.createElement(o),
    m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

  ga('create', 'G-VNMTFT1R2R', 'auto');
  ga('send', 'pageview');

</script> <!-- /google analytics -->
  
  <div class="o-wrapper">
    <aside class="c-sidebar">
  <div class="c-sidebar-author">
    <div class="c-author__cover">
      <a href="/">
        <img src="/images/Profile/profile.png" alt="Dong-Jun Shin">
      </a>
    </div>
    <div class="c-author__info">
      <div class="c-author__name">Dong-Jun Shin</div>
      <span class="c-author__job">Web Developer</span>
    </div>
    <div class="c-contact-menu">
      <div style="width: 100%">
        <a href="/about/profile" class="c-contact-btn c-btn c-btn--secondary c-btn--round c-btn--shadow">
          <div style="
            display: flex;
            flex-direction: row;
            align-items: center;">
            <span data-icon='ei-tag' data-size='s'></span>
            <span>About me</span>
          </div>
        </a>
        
        <a target="_blank" href="https://github.com/Dong-Jun-Shin" class="c-btn c-btn--primary c-btn--round c-btn--shadow">
          <div style="
            display: flex;
            flex-direction: row;
            align-items: center;">
            <span data-icon='ei-sc-github' data-size='s'></span>
            <span>Visit Github</span>
          </div>  
        </a>
      </div>
      
    </div>
    <div class="c-contact-menu-bar">
      <div style="width: 100%">
        <a href="/" class="c-contact-btn c-btn c-btn--bar c-btn--round c-btn--shadow">All Posts</a>
      </div>
    </div>
    <p class="c-author__about">개발자로 성장하며 배운 것을 정리한 블로그</p>
  </div>

  <div class="c-sidebar-footer">
    <div class="c-social">
      <div class="c-social__title">Social</div>
      <ul class="c-social__list u-lists-reset">
        
        <li class="c-social__item"><a href="https://www.linkedin.com/in/kr-jun-shin" target="_blank"><div data-icon='ei-sc-linkedin' data-size='s'></div></a></li>
        
        
        
        
        
        
        
        
        
        
          <li class="c-social__item"><a href="https://youtube.com/channel/UCIHM7drY2vvvFhrhXtpbbzw" target="_blank"><div data-icon='ei-sc-youtube' data-size='s'></div></a></li>
        
        
        
      </ul>
    </div>
    <div class="c-copyright">
      <p>2025 &copy; Dong-Jun Shin</p>
      <!-- <a target="_blank" href="https://analytics.google.com/"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fdong-jun-shin.github.io&count_bg=%23FFD540&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=true"/></a> -->
      <a target="_blank" href="https://analytics.google.com/"><img src="https://img.shields.io/badge/Info-Analytics-infomation?style=flat-square&color=yellow"/></a>
      <a target="_blank" href="https://search.google.com/search-console"><img src="https://img.shields.io/badge/Info-Search-informational?style=flat-square"/></a>
    </div>
  </div>
</aside> <!-- /.c-sidebar -->

<main class="c-content">
  <article class="c-article">
  <div class="c-article__content">
    <header class="c-header u-hide u-no-margin-top">
      <div class="c-header__box">
        <div class="c-search u-full-width">
          <div class="c-search__box">
            <label for="js-search-input" class="u-screen-reader-text">Search for Blog</label>
            <input type="text" id="js-search-input" class="c-search__text" autocomplete="off" placeholder="Type to search...">
            <div data-icon='ei-search' data-size='s'></div>
          </div>
          <ul id="js-results-container" class="c-search-results-list"></ul>
        </div>
      </div>
    </header>
    
    <div class="c-article__image o-opacity" style="background-image: url( /images/CS_AI_ML/logo.png )"></div>
    
    <div class="c-wrap-content">
      <header class="c-article__header">
        <h1 class="c-article__title">코칭스터디 Beyond AI Basic 2023 - 3주차 학습</h1>
        <div class="c-article__date">
          <span>2023, May 21</span>
        </div>
      </header>
      
      <div class="toc-container">
        <div class="toc">
          <div class="toc-title">Index</div>
          <ul><li><a href="#딥러닝-기초">딥러닝 기초</a></li><li><a href="#딥러닝-기본-용어-설명">딥러닝 기본 용어 설명</a><ul><li><a href="#딥러닝을-활용하는-데이터-사이언티스트가-갖춰야-할-역량">딥러닝을 활용하는 데이터 사이언티스트가 갖춰야 할 역량</a></li><li><a href="#딥러닝의-정의">딥러닝의 정의</a></li><li><a href="#딥러닝의-핵심-요소">딥러닝의 핵심 요소</a></li></ul></li><li><a href="#뉴럴-네트워크---mlp">뉴럴 네트워크 - MLP</a><ul><li><a href="#neural-networks">Neural Networks</a></li><li><a href="#linear-neural-networks">Linear Neural Networks</a></li><li><a href="#beyond-linear-neural-networks">Beyond Linear Neural Networks</a></li><li><a href="#multi-layer-perceptron">Multi-Layer Perceptron</a></li></ul></li><li><a href="#최적화">최적화</a></li><li><a href="#최적화의-주요-용어-이해하기">최적화의 주요 용어 이해하기</a><ul><li><a href="#introduction">Introduction</a></li><li><a href="#최적화에-있어-중요한-컨셉important-concepts-in-optimization">최적화에 있어 중요한 컨셉(Important Concepts in Optimization)</a></li></ul></li><li><a href="#gradient-descent-methods">Gradient Descent Methods</a><ul><li><a href="#practical-gradient-descent-methods">Practical Gradient Descent Methods</a></li><li><a href="#batch-size-문제">Batch-size 문제</a></li><li><a href="#종류">종류</a></li></ul></li><li><a href="#regularization">Regularization</a><ul><li><a href="#정의">정의</a></li><li><a href="#종류-1">종류</a></li></ul></li><li><a href="#reference">Reference</a></li></ul>
        </div>
      </div>
      
      <h1 id="딥러닝-기초">딥러닝 기초</h1>

<h1 id="딥러닝-기본-용어-설명">딥러닝 기본 용어 설명</h1>

<h2 id="딥러닝을-활용하는-데이터-사이언티스트가-갖춰야-할-역량">딥러닝을 활용하는 데이터 사이언티스트가 갖춰야 할 역량</h2>

<ul>
  <li>프로그래밍 역량(Implementation Skills)
    <ul>
      <li>텐서플로우, 파이토치</li>
    </ul>
  </li>
  <li>수학 및 통계 역량(Math Skills)
    <ul>
      <li>선형 대수학(Linear Algebra)</li>
      <li>확률(Probability)</li>
    </ul>
  </li>
  <li>관련 도메인 지식(Knowing Papers)
    <ul>
      <li>많은 양의 최신 자료</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="딥러닝의-정의">딥러닝의 정의</h2>

<ul>
  <li>Artificial Intelligence &gt; Machine Learning &gt; Deep Learning</li>
</ul>

<p><br /></p>

<h2 id="딥러닝의-핵심-요소">딥러닝의 핵심 요소</h2>

<ul>
  <li>모델이 학습 가능한 <strong>데이터</strong>
    <ul>
      <li>문제에 의존성을 가짐</li>
      <li>데이터의 종류
        <ul>
          <li>정의 문제(Classification)</li>
          <li>특징 분류 문제(Semantic Segmentation)</li>
          <li>탐색 문제(Detection)</li>
          <li>자세 판단 문제(Pose Estimation)</li>
          <li>시각적 질의응답 문제(Visual QnA)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>데이터를 원하는 것으로 변환해주는 <strong>모델</strong>
    <ul>
      <li>input(x)로 output(y)를 도출하기 위한 파라미터들(w, b)을 찾기 위한 것</li>
      <li>2012 ~ 2020까지 대표적인 모델 예시
        <ul>
          <li>AlexNet - 2012, 첫 딥러닝 모델</li>
          <li>DQN - 2013, 딥 마인드에서 게임을 학습하는데 사용한 모델</li>
          <li>Encoder/Decoder - 2014, 번역 등에 사용한 모델</li>
          <li>AdamOptimizer - 2014, 수많은 하이퍼 파라미터의 최적화에 높은 성능을 보이는 모델</li>
          <li>GAN - 2015, 이미지 생성 모델</li>
          <li>ResNet(Residual Networks) - 2015, NN의 층을 깊게 쌓아 성능을 높인 모델</li>
          <li>Transformer - 2017, 기존 방법론들을 대체한 중요한 모델</li>
          <li>BERT - 2018, 소수의 데이터를 fine-tuning 하는 개념이 적용된 모델</li>
          <li>BIG language Models - 2019, GPT 같은 가장 진보된 NLP 모델</li>
          <li>Self Supervised Learning - 2020, SimCLR 같은 라벨되지 않은 데이터를 학습에 함께 활용하는 방법</li>
        </ul>
      </li>
      <li>그 외 모델
        <ul>
          <li>GoogLeNet</li>
          <li>DenseNet</li>
          <li>LSTM</li>
          <li>Deep AutoEncoders</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>정해진 모델과 데이터로 어떻게 학습할 지에 대한 <strong>손실 함수(Loss function)</strong>
    <ul>
      <li>손실률(실제와 예측의 차이)을 근사치로 표현한 함수</li>
      <li>클수록 오답이고, 작을수록 정답</li>
      <li>종류
        <ul>
          <li><strong>회귀 문제(Regression Task)</strong>
            <ul>
              <li><strong>평균 제곱 오차 (MSE, Mean-Squared Error)</strong>
                <ul>
                  <li>학습값과 예측값의 오차 제곱을 계산한 값</li>
                  <li>연속적 분포의 특성을 갖는 선형 회귀에서 주로 사용</li>
                </ul>
              </li>
            </ul>
          </li>
          <li><strong>분류 문제(Classification)</strong>
            <ul>
              <li><strong>크로스 엔트로피 (CE, Cross-Entropy)</strong>
                <ul>
                  <li>확률 분포와 예측 분포 사이의 차이를 측정</li>
                  <li>이산적 분포의 특성을 갖는 다항 분류에 주로 사용</li>
                </ul>
              </li>
            </ul>
          </li>
          <li><strong>확률 문제(Probability)</strong>
            <ul>
              <li><strong>최대 가능도 추정 (MLE, Maximum Likelihood Estimation)</strong>
                <ul>
                  <li>각 샘플에 있는 특징을 기여도로 계산해서 다 곱한 값</li>
                  <li>데이터의 밀도를 추정하는 방법으로 값에 대한 평균과 분산으로 모델링할 때 주로 사용</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>손실률을 최소화하는 최적화 목적의 <strong>알고리즘</strong>
    <ul>
      <li>한정된 데이터로 모델과 손실 함수를 바꿔가며 높은 성능을 내도록 함</li>
      <li>Dropout</li>
      <li>Early stopping</li>
      <li>k-fold validation</li>
      <li>Weight decay</li>
      <li>Batch normalization</li>
      <li>MixUp</li>
      <li>Ensemble</li>
      <li>Bayesian Optimization</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="뉴럴-네트워크---mlp">뉴럴 네트워크 - MLP</h1>

<h2 id="neural-networks">Neural Networks</h2>

<ul>
  <li>포유류의 신경망을 기반으로 분류, 생성, 변환 등 함수를 모방한 개념</li>
</ul>

<p><br /></p>

<h2 id="linear-neural-networks">Linear Neural Networks</h2>

<ul>
  <li>학습된 데이터가 선형의 모습으로 이루어진 가장 간단한 NN의 개념</li>
  <li>n차원 값에서 m차원 값을 찾고 싶은 경우, 행렬을 곱함
    <ul>
      <li>2개의 벡터 공간 사이의 선형성을 찾는 것</li>
    </ul>
  </li>
  <li><strong>Data</strong>: x, y로 구성된 1차원 값 N개로 구성</li>
  <li><strong>Model</strong>: x를 w라는 스칼로 곱하고, b라는 바이어스를 더함
    <ul>
      <li>모델은 x에서 y를 도출하기 위한 w, b를 찾는 것이 목적</li>
    </ul>
  </li>
  <li><strong>Loss</strong>: MSE를 사용</li>
</ul>

<p><br /></p>

<h2 id="beyond-linear-neural-networks">Beyond Linear Neural Networks</h2>

<ul>
  <li>선형 결합의 반복을 통해 네트워크를 여러개 쌓는 방법</li>
  <li>Non-linear transform(p)을 선형 결합들 사이에 추가해서 반복 결합
    <ul>
      <li>단순한 선형 결합은 행렬이 대칭하지 않기 때문에 하나인 네트워크와 같음</li>
    </ul>
  </li>
  <li>Activation functions
    <ul>
      <li>Non-linear transform을 위한 함수</li>
      <li>종류
        <ul>
          <li><strong>Rectified Linear Unit(ReLU)</strong>
            <ul>
              <li>0보다 큰 값은 그대로 쓰고, 작은 값은 0으로 두는 방법</li>
            </ul>
          </li>
          <li><strong>Sigmoid</strong>
            <ul>
              <li>출력값을 0 ~ 1로 제한하는 것</li>
            </ul>
          </li>
          <li><strong>Hyperbolic Tangent</strong>
            <ul>
              <li>출력값을 +, -로 제한하는 것</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="multi-layer-perceptron">Multi-Layer Perceptron</h2>

<ul>
  <li>input layer(x), hidden layer(h), output layer(y) 등으로 구성됨</li>
  <li>linear 또는 transformation 등 변환하는 작업을 하는 hidden layer가 있음</li>
</ul>

<p><br /></p>

<h1 id="최적화">최적화</h1>

<h1 id="최적화의-주요-용어-이해하기">최적화의 주요 용어 이해하기</h1>

<h2 id="introduction">Introduction</h2>

<ul>
  <li>최적화는 빠르고 정확한 학습을 위한 개념</li>
  <li>Gradient Descent
    <ul>
      <li>1차 미분값을 사용하여 계속 최적화를 반복해서 loss function을 최소화시키는 것</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="최적화에-있어-중요한-컨셉important-concepts-in-optimization">최적화에 있어 중요한 컨셉(Important Concepts in Optimization)</h2>

<ul>
  <li><strong>Generalization</strong>
    <ul>
      <li>Input data가 달라져도 Output에 대한 성능차이가 나지 않는 현상</li>
      <li>학습 데이터와 테스트 데이터 사이의 차이
        <ul>
          <li>좋다 =&gt; 차이가 적어서 학습한만큼 나온다</li>
        </ul>
      </li>
      <li>학습 데이터 자체가 안 좋을 경우, Generalization이 좋더라도 안 좋을 수 있음</li>
    </ul>
  </li>
  <li><strong>Underfitting vs. Overfitting</strong>
    <ul>
      <li>과소적합, 과적합은 해석하기에 따라 달라질 수 있기 때문에 이론에 가까운 개념임</li>
    </ul>
  </li>
  <li><strong>Cross-validation</strong>
    <ul>
      <li>학습데이터를 k개로 나누어 fold를 구성하고, 각 fold로 model을 생성하고 검증하는 K-fold cross-validation이 있음</li>
      <li>이 때 절대 테스트 데이터는 사용하면 안됨</li>
    </ul>
  </li>
  <li><strong>Bias and Variance</strong>
    <ul>
      <li>두가지는 반비례함</li>
      <li><strong>Bias</strong>: 평균적으로 봤을 때, 일관된 출력을 보이는 정도 (낮을수록 일관됨)</li>
      <li><strong>Variance</strong>: 입력에 대해 일관된 출력을 보이는 정도 (낮을수록 일관됨)</li>
    </ul>
  </li>
  <li><strong>Bias and Variance Tradeoff</strong>
    <ul>
      <li>cost를 줄이기 위해서, Bias와 Variance, noise를 두고 고민해야 함</li>
    </ul>
  </li>
  <li><strong>Bootstrapping</strong>
    <ul>
      <li>데이터 중 랜덤하게 일부를 뽑아 샘플링하고 각각의 모델을 생성하는 방법</li>
      <li>모델들의 예측값이 일치하는 정도를 보고, 전체적인 모델의 예측을 보고자 할 때 사용</li>
    </ul>
  </li>
  <li><strong>Bagging vs. Boosting</strong>
    <ul>
      <li><strong>Bagging(Bootstrapping aggregating)</strong>: 동일 모델을 여러개 만들어 각각 학습(병렬 학습)</li>
      <li><strong>Boosting</strong>: 순차적으로 학습(직렬 학습)</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="gradient-descent-methods">Gradient Descent Methods</h1>

<h2 id="practical-gradient-descent-methods">Practical Gradient Descent Methods</h2>

<ul>
  <li><strong>Stochastic gradient descent</strong>
    <ul>
      <li>전체 데이터 중 하나의 샘플을 이용해서 하나의 Gradient를 구하는 것을 반복하는 것</li>
    </ul>
  </li>
  <li><strong>Mini-batch gradient descent</strong>
    <ul>
      <li>전체 데이터 중 일부를 이용해서 하나의 Gradient를 구하는 것을 반복하는 것</li>
      <li>보통 제일 많이 사용하는 방법</li>
    </ul>
  </li>
  <li><strong>Batch gradient descent</strong>
    <ul>
      <li>전체 데이터 모두를 이용해서 하나의 Gradient를 구하는 것을 반복하는 것</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="batch-size-문제">Batch-size 문제</h2>

<ul>
  <li>Testing Function의 Minimum을 찾는 것이 중요</li>
  <li>Minimum의 개념
    <ul>
      <li>제일 잘 예측하는 지점</li>
      <li><strong>Flat Minimum</strong>
        <ul>
          <li>Testing Function과 편차가 크지 않아, 학습 데이터에서 나온 성능만큼 보여주는 것</li>
          <li>Generalization가 높음</li>
        </ul>
      </li>
      <li><strong>Sharp Minimum</strong>
        <ul>
          <li>Testing Function과 편차가 커서, 학습 데이터에서 나온 성능과 차이가 큼</li>
          <li>Generalization가 낮음</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="종류">종류</h2>

<ul>
  <li>공식의 용어
    <ul>
      <li>W:  NN의 Weight를 뜻함</li>
      <li>에타(η): Learning rate</li>
      <li>g: Gradient</li>
      <li>t: Step size</li>
      <li>베타(β): momentum</li>
      <li>엡실론(ε): 분모가 0이 되는 것을 방지하기 위한 값(분모값의 안정성을 위한 값)</li>
      <li>G: 파라미터가 변화한 정도를 누적한 값(gradient 제곱합)</li>
    </ul>
  </li>
  <li><strong>Stochastic Gradient Descent</strong>
    <ul>
      <li>데이터 그대로 학습하는 방법</li>
      <li>Learning rate와 Gradient를 곱한 값을 Weight에서 뺌</li>
      <li>적절한 Learning rate와 Step size를 찾기 어려움</li>
    </ul>
  </li>
  <li><strong>Momentum(관성)</strong>
    <ul>
      <li>momentum을 하이퍼 파라미터로 곱해서 다음 단계에 값이 반영되도록 한 방법</li>
      <li>일정 구간동안 학습 데이터가 반영될 수 있음</li>
    </ul>
  </li>
  <li><strong>Nesterov Accelerated Gradient</strong>
    <ul>
      <li>실제 계산되는 지점에 momentum을 가로질러서 도달하는 방법</li>
      <li>Lookahead gradient를 계산</li>
      <li>momentum보다 빠르게 도달할 수 있음</li>
    </ul>
  </li>
  <li><strong>Adagrad</strong>
    <ul>
      <li>NN의 파라미터가 변화한 정도를 조정하는 방법</li>
      <li>많이 변화했으면 둔하게 만들고, 적게 변화했으면 민감해지도록 함</li>
      <li>G가 계속 커지게 되면 점점 학습이 둔화하는 문제가 있음</li>
    </ul>
  </li>
  <li><strong>Adadelta</strong>
    <ul>
      <li>G를 단계별로 고려해서 시간에 따른 변화를 보는 방법</li>
      <li>Adagrad에서 G가 계속 커지는 현상을 막기위해 나왔으나, 많이 사용되지는 않음</li>
      <li>단계별로 이전 단계들의 파라미터를 가지고 있어서 속도에 문제가 있음</li>
    </ul>
  </li>
  <li><strong>RMSprop</strong>
    <ul>
      <li>Adagrad처럼 NN의 파라미터 변화한 정도와 단계별 사이즈를 고려하는 방법</li>
    </ul>
  </li>
  <li><strong>Adam</strong>
    <ul>
      <li>RMSprop과 Momentum의 개념을 합친 방법</li>
      <li>G의 변화 정도, 단계별 사이즈, 이전 단계에서 사용된 값을 고려</li>
      <li>일반적으로 많이 사용됨</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="regularization">Regularization</h1>

<h2 id="정의">정의</h2>

<ul>
  <li>Generalization(오차)를 줄이고 싶은 목적으로 방해되는 요소를 규제하는 방법</li>
</ul>

<p><br /></p>

<h2 id="종류-1">종류</h2>

<ul>
  <li><strong>Early Stopping</strong>
    <ul>
      <li>validation error가 커지는 시점을 기준으로 멈추는 방법</li>
    </ul>
  </li>
  <li><strong>Parameter Norm Penalty</strong>
    <ul>
      <li>NN 파라미터가 너무 커지지 않도록 패널티를 부여하는 방법</li>
    </ul>
  </li>
  <li><strong>Data Augmentation</strong>
    <ul>
      <li>데이터를 여러가지 방식으로 데이터를 늘려서 Input으로 사용하는 방법</li>
      <li>사진을 예시로 하면, 회전, 반전, 사이즈 수정 등이 있음</li>
    </ul>
  </li>
  <li><strong>Noise Robustness</strong>
    <ul>
      <li>데이터에 불규칙한 노이즈를 추가해서 Input이나 weights로 사용하는 방법</li>
      <li>글자를 예시로 하면, 해상도를 낮추는 방법이 있음</li>
    </ul>
  </li>
  <li><strong>Lebel Smoothing</strong>
    <ul>
      <li>학습데이터 2개를 뽑아서 섞어서 Input으로 사용하는 방법</li>
      <li>분류에 대한 기준을 찾기 위해 사용, 학습한 데이터 양에 비해 높은 성능을 보임</li>
      <li>사진을 예시로 하면, 강아지, 고양이에 대해 이미지와 분류 비율을 섞어서 사용함</li>
    </ul>
  </li>
  <li><strong>Dropout</strong>
    <ul>
      <li>설정한 파라미터 값만큼 NN의 Weight을 바꿔서, 일부 neuron을 0으로 바꾸는 방법</li>
    </ul>
  </li>
  <li><strong>Batch Normalization</strong>
    <ul>
      <li>평균을 빼고 분산을 나눠서(표준 편차를 줄이는) 방법</li>
      <li>각 층의 값들을 100이라 하면 0으로 줄임</li>
      <li>층이 많이 쌓일수록 높은 성능을 보여주지만, 논란이 많은 방법임</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="reference">Reference</h1>

<ul>
  <li><a href="https://m.post.naver.com/viewer/postView.naver?volumeNo=35664080&amp;memberNo=34635212">제대로 된 인공지능 스터디를 찾고 있다면? AI 심화 스터디</a></li>
  <li><a href="https://www.boostcourse.org/study-ai111-2023">[코칭스터디 10기] Beyond AI Basic 2023 스터디 전용강좌</a></li>
</ul>

      <div class="c-article__footer u-clearfix">
        <div class="c-article__tag">
          
        </div>
        <div class="c-article__share">
          <a href="https://twitter.com/intent/tweet?text=%EC%BD%94%EC%B9%AD%EC%8A%A4%ED%84%B0%EB%94%94%20Beyond%20AI%20Basic%202023%20-%203%EC%A3%BC%EC%B0%A8%20%ED%95%99%EC%8A%B5&url=https://dong-jun-shin.github.io/2023/05/21/Beyond_AI_Basic_2023_Week_3/" title="Share
          on Twitter" rel="nofollow" target="_blank"><div data-icon='ei-sc-twitter' data-size='s'></div></a>
          <a href="https://facebook.com/sharer.php?u=https://dong-jun-shin.github.io/2023/05/21/Beyond_AI_Basic_2023_Week_3/" title="Share on Facebook" rel="nofollow" target="_blank"><div data-icon='ei-sc-facebook' data-size='s'></div></a>
          <a href="https://plus.google.com/share?url=https://dong-jun-shin.github.io/2023/05/21/Beyond_AI_Basic_2023_Week_3/" title="Share on Google+" rel="nofollow" target="_blank"><div data-icon='ei-sc-google-plus' data-size='s'></div></a>
        </div>
      </div>
      <div class="c-newsletter">
  <div class="c-newsletter__header">
    <h4 class="c-newsletter__title">Newsletter</h4>
    <div class="c-newsletter__subtitle">Subscribe to this blog and receive notifications of new posts by email.</div>
  </div>
  <form class="c-newsletter-form validate" action="#" method="POST" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" target="_blank" novalidate>
    <div class="c-newsletter-form__group">
      <label class="u-screen-reader-text" for="mce-EMAIL">Email address</label>
      <input class="c-newsletter__email required email" id="mce-EMAIL" type="email" name="EMAIL" placeholder="Your email address" autocomplete="on">
      <input class="c-newsletter__button" id="mc-embedded-subscribe" type="submit" name="subscribe" value="Subscribe">
    </div>
  </form>
</div> <!-- /.c-newsletter -->
      <div class="c-recent-post">
        <h4 class="c-recent__title">You might also enjoy</h4>
        <div class="c-recent__box">
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2025/01/10/permutation_and_combination_implements/" style="background-image: url( /images/CS_Algorithm/2025/01/permutation_and_combination_implements/thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2025/01/10/permutation_and_combination_implements/">순열과 조합 - 2, 경우의 수 뿐만 아니라 경우를 직접 구해보자</a></h4>
              <div class="c-recent__date">
                <time datetime="2025-01-10T17:45:03+09:00">January 10, 2025</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2025/01/10/permutation_and_combination_theory/" style="background-image: url( /images/CS_Algorithm/2025/01/permutation_and_combination_theory/thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2025/01/10/permutation_and_combination_theory/">순열과 조합 - 1, 어떤 원리로 경우의 수를 계산할 수 있는걸까?</a></h4>
              <div class="c-recent__date">
                <time datetime="2025-01-10T17:45:02+09:00">January 10, 2025</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2024/08/21/2_years_of_experience_from_2022/" style="background-image: url( /images/Life/2024/08/2_years_of_experience_from_2022/thumbnail_retrospective-journey.jpg)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2024/08/21/2_years_of_experience_from_2022/">퇴사 회고(라 쓰고, 2022년 ~ 2024년 정리)</a></h4>
              <div class="c-recent__date">
                <time datetime="2024-08-21T23:47:38+09:00">August 21, 2024</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2024/05/21/Aws_Summit_Seoul_2024/" style="background-image: url( /images/IT_Tech/2024/05/Aws_Summit_Seoul_2024/thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2024/05/21/Aws_Summit_Seoul_2024/">AWS Summit Seoul 2024 방문기</a></h4>
              <div class="c-recent__date">
                <time datetime="2024-05-21T21:55:48+09:00">May 21, 2024</time>
              </div>
            </div>
          </div>
        
        
        </div>
      </div> <!-- /.c-recent-post -->
      
        <div class="c-comments">
  <div id="disqus_thread" class="article-comments"></div>
  <script>
    (function () {
      var d = document, s = d.createElement('script');
      s.src = '//dong-jun-shin-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
</div> <!-- /.c-comments -->
      
    </div> <!-- /.c-wrap-content -->
  </div> <!-- /.c-article__content -->
</article> <!-- /.c-article-page -->

</main> <!-- /.c-content -->
  </div> <!-- /.o-wrapper -->
  <div class="c-top" data-icon='ei-chevron-up' data-size='s' title="Scroll To Top"></div> <!-- /.c-top -->
  <script src="/js/jquery-3.3.1.min.js"></script>
<script src="/js/evil-icons.min.js"></script>
<script src="/js/jquery.fitvids.js"></script>
<script src="/js/simple-jekyll-search.min.js"></script>
<script src="/js/main.js"></script>
<!-- /javascripts -->
</body>
</html>