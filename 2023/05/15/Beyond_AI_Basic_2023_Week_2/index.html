<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>코칭스터디 Beyond AI Basic 2023 - 2주차 학습</title>
  <meta
    name="description"
    content="피처 엔지니어링피처 엔지니어링 기본 개념정의  모델의 성능을 올리기 위해 피처를 생성 및 변환하고 머신러닝 모델에 적합한 형식으로 변환하는 작업  원본 데이터 + 도메인 지식을 바탕으로 문제 해결에 도움이 되는 피처를 생성, 변환  피처 엔지니어링은 EDA를 위해 제공된 데이터에서..."
  />
  <!-- Twitter Cards -->
<meta name="twitter:title" content="코칭스터디 Beyond AI Basic 2023 - 2주차 학습">
<meta name="twitter:description" content="피처 엔지니어링

피처 엔지니어링 기본 개념

정의


  모델의 성능을 올리기 위해 피처를 생성 및 변환하고 머신러닝 모델에 적합한 형식으로 변환하는 작업
  원본 데이터 + 도메인 지식을 바탕으로 문제 해결에 도움이 되는 피처를 생성, 변환
  피처 엔지니어링은 EDA를 위해 제공된 데이터에서 데이터의 특성과 시계열 특성을 고려하고 집계함수, 누적합 등을 조합해서 도움이 되는 피처를 생성
  머신러닝에서만 하는 작업
    
      딥러닝은 모델 구조에서 피처를 모델이 직접 추출 가능
    
  
  데이터의 품질만큼 성능을 결정하는 중요한 작업
  e.g. Pandas Group By Aggregation을 사용해서, 고객 ID 기반으로 집계한 새로운 피처 생성
    
      집계함수: 개수(Count), 합계(Sum), 평균(Mean), 최대값(MAX), 최소값(MIN), 표준 편차(STD), 비대칭도(SKEW) 등이 있음
        
          표준 편차 (Standard Deviation)
            
              데이터가 어느 정도 흩어져 있는 나타냄
              낮을수록 데이터가 밀집되어 있음, 높을수록 데이터가 넓게 분포되어 있음
            
          
          비대칭도 (Skewed)
            
              데이터가 어느 방향으로 모여있는지 나타냄
              Positive하면 왼쪽, Negative하면 오른쪽으로 모여있음
            
          
        
      
      agg_func = ['count', 'sum', ...]을 정의하고 agg_dict = { 'column_name': agg_func, ...} 형태로 정의, 그리고 Pandas의 함수 중 groupby로 기준 컬럼을 선택하고 agg(agg_dict) 형태로 사용
    
  




좋은 피처와 나쁜 피처


  피처 엔지니어링을 통해 얻은 피처를 그래프로 나타내었을 때, 레이블의 분포 차이로 구분
  좋은 피처는 레이블의 분포 차이가 명확함




피처 엔지니어링 후 모델 성능 측정 방법


  Cross Validation Out of Fold
    
      Cross Validation과 Out of Fold을 합친 방법
        
          Cross Validation
            
              데이터를 여러 개의 폴드로 나눠서 검증 성능을 측정하는 방법
            
          
          Out of Fold
            
              학습한 모델로 테스트 데이터를 예측하고, 평균 앙상블하여 최종 예측값으로 사용하는 방법
            
          
        
      
      데이터 세트에 존재하는 편향된 부분의 영향력을 줄이기 위해 사용
      캐글에서 일반적으로 많이 사용
    
  
  Early Stopping
    
      검증 성능이 가장 최적이라 판단되는 지점에서 학습을 조기 종료하는 방법
      이전 스텝보다 성능이 떨어지는 경우가 반복되면 조기 종료
      e.g. Boosting 트리 개수, 딥러닝의 Epoch 수를 최적화하는데 사용
    
  
  LightGBM Early Stopping
    
      LightGBM과 Early Stopping을 합친 방법
        
          LightGBM
            
              n_estimators 하이퍼파라미터로 트리 개수를 설정해서 모델을 생성
            
          
          LightGBM만 사용했을 때, 트리 개수에 대한 최적 값을 찾기 어렵기 때문에, 크게 설정하고 Early Stopping을 사용해서 성능이 최적인 부분을 찾음
        
      
    
  




누적합을 이용한 피처 엔지니어링


  누적합(cumsum)
    
      시간 또는 순서에 따라 증가하는 데이터의 총합계를 표시하는 함수
      일반적으로 집계를 하면 시간 순서 정보가 사라지기 때문에 데이터의 특성에 따라 시간 순서 정보도 고려해야 함
      Pandas의 함수 중 groupby로 기준 컬럼을 선택하고 ['column_name'].cumsum() 형태로 사용
    
  




시계열 특성을 이용한 피처 엔지니어링


  Pandas의 함수 중 groupby로 기준 컬럼을 선택하고 ['column_name'].diff() 형태로 사용
  e.g. 주문 데이터에서의 피처 엔지니어링
    
      order_ts-first: 처음 주문 시각
      order_ts-last: 마지막 주문 시각
      order_ts-diff-max: 주문 시각 차이의 최대값
      order_ts-diff-skew: 주문 시각 차이의 비대칭도
      order_ts-diff-std: 주문 시각 차이의 표준편차
      order_ts-diff-sum: 주문 시각 차이의 합
    
  




피처 중요도와 피처 선택

피처 중요도


  정답을 예측하는데 얼마나 유용한 지를 점수로 피처에 할당하는 것
  측정 방법
    
      모델 자체에서 피처 중요도를 계산하는 방법 (Model-specific)
        
          모델마다 피처 계산 방식이 달라, 각 모델에서 제공하는 기능을 사용하여 피처 중요도를 계산
            
              모델 공통으로 order_ts-last 피처가 가장 중요하고, 그 외에는 모델별로 다름
            
          
          보통 피처 선택 시 참고용으로 많이 사용
          모델별 예시
            
              LightGBM 모델에서 중요도 계산하기
                
                  feature_importance(default: split)
                  importance_type에 따른 계산 방식 사용
                    
                      split: 트리 모델을 만드는데 피처가 몇 번 사용됐는 지 계산
                      gain: split한 결과값의 평균으로 계산
                    
                  
                
              
              XGBoost 모델에서 중요도 계산하기
                
                  importance_type에 따른 계산 방식 사용
                    
                      get_score(default: weight)
                      weight: 트리 모델을 만드는데 피처가 몇 번 사용됐는 지 계산 (split과 유사)
                      gain: split한 결과값의 평균으로 계산 (gain과 유사)
                      cover: 전체 coverage의 평균으로 계산
                      total_gain: 전체 gain의 합으로 계산
                      total_cover: 전체 coverage의 합으로 계산
                    
                  
                
              
              CatBoost 모델에서 중요도 계산하기
                
                  type에 따른 계산 방식 사용
                    
                      get_feature_importance(default: FeatureImportance)
                      FeatureImportance: 피처를 임의로 섞을 때, 모델의 성능이 얼마나 감소하는지에 따라 각 기능의 중요도를 계산
                      ShapValues: 특정 샘플의 예측에 대한 각 피처의 기여도를 계산
                      Interaction: 피처 쌍을 임의로 섞을 때, 모델의 성능이 얼마나 감소하는지에 따라 각 피처 쌍의 중요도를 계산
                      PredictionDiff: 주어진 샘플에 대해 특정 피처가 변경될 때 모델 예측의 차이를 계산
                    
                  
                
              
            
          
        
      
      모델을 학습한 후 피처 중요도를 계산하는 방법 (Model-agnostic)
        
          기존 데이터와 섞은 데이터의 에러 차이를 측정해서 피처 중요도를 계산하는 방식 (Permutation Feature Importance)
          중요한 피처일수록, 모델이 예측하지 못해서 에러 값이 커짐
          중요하지 않은 피처일수록 예측하기 때문에 에러 값이 작아짐
          실제 피처를 선택할 때 많이 사용
          계산 예시
            
              Input: Trained model, feature matrix, target vector(label), error measure(function)
              오리지널 모델로 error measure를 계산
              feature를 하나씩 돌면서 feature matrix의 데이터를 여러번 섞은 후 에러를 구함
              섞은 후 에러와 오리지널에서 얻은 에러를 비교해서 차이를 저장
              에러 차이가 큰 순서로 정렬해서 피처의 중요한 순서대로 확인
            
          
        
      
      모델별 피처 중요도 순위 예시
    
  



  
    
       
      LightGBM
      XGBoost
      CatBoost
    
  
  
    
      feature 1
      order_ts-last
      order_ts-last
      order_ts-last
    
    
      feature 2
      order_ts_diff-max
      quantity_diff-skew
      year_month_mode
    
    
      feature 3
      order_ts-first
      cumsum_price_by_prod_id-skew
      order_ts-first
    
    
      feature 4
      cumsum_price_by_prod_id-skew
      price_diff-skew
      order_ts_diff-max
    
    
      feature 5
      quantity_diff-skew
      order_ts-first
      cumsum_total_by_prod_id-sum
    
  




피처 선택


  피처 간에 비슷한 값들을 갖는다면 노이즈 데이터로 학습될 수 있기 때문에 방지하기 위해 피처를 선별
  모델 복잡도를 낮춰, 오버피팅을 방지하고 모델 속도를 향상시킴
  선택 방법
    
      Filter Method
        
          통계적인 측정을 통해 선택하는 방법
          모든 피처 셋 &gt; 서브셋 생성 &gt; 알고리즘 학습 &gt; 성능 측정
          상관관계(Correlation)를 측정하여 유사한 피처를 제거 or 피처의 분산을 계산하여 분산 값이 작은 경우 제거
          계산 속도가 빠르고 피처 간의 상관관계를 알기 좋음
        
      
      Wrapper Method
        
          예측 모델을 사용해서 선택하는 방법
          모든 피처 셋 &gt; 서브셋 생성 &gt; 알고리즘 학습 단계 반복 &gt; 성능 측정
          피처의 서브 셋을 계속 테스트해서 성능에 유용하지 않은 피처를 제거
        
      
      Embedded Method
        
          Filter와 Wrapper의 장점을 합친 방법
          모든 피처 셋 &gt; 서브셋 생성 &gt; 알고리즘 학습 + 성능 측정 단계 반복
          학습 알고리즘 자체에 피처 선택이 들어가 있음
        
      
    
  




하이퍼 파라미터 튜닝과 앙상블

하이퍼 파라미터 튜닝

하이퍼 파라미터


  모델의 성능을 더욱 끌어내기 위해, 학습 이전에 사람이 조작하는 값
  파라미터는 모델이 학습 과정에서 배우는 값 (하이퍼 파라미터와는 다름)
  e.g. learning_rate, n_estimators




튜닝


  하이퍼 파라미터를 최적화하는 과정
  최적의 값을 찾는 방법
    
      Manual Search
        
          수동으로 실험할 하이퍼 파라미터 셋을 정해, 하나씩 테스트해보는 방식
        
      
      Grid Search
        
          모든 경우를 테스트하는 방식
          e.g. learning rate 탐색 공간 [0.01, 0.05, 0.1, 0.2]로 설정하고 n_estimators 탐색 공간 [100, 200]을 설정한다면 나올 수 있는 조합의 수 8가지를 모두 테스트
        
      
      Random Search
        
          랜덤하게 하이퍼 파라미터를 선택해서 테스트하는 방식
          일반적으로 Grid Search보다 성능이 좋음
        
      
      Bayesian Optimization
        
          이전 결과를 기반으로 다음 하이퍼 파라미터의 값을 선택하는 방식
          성능이 잘 나온 영역이 있다면 집중적으로 탐색해서 찾음
        
      
    
  




Boosting Tree 하이퍼 파라미터


  정형 데이터에서 자주 사용하는 Boosting Tree 모델들의 하이퍼 파라미터
    
      Learning Rate: 모델의 학습률
      Tree depth: 트리 모델의 최대 깊이
      Number of leaves: 한 트리의 최대 리브 수
      Early stop: 검증 성능이 향상하지 않으면 조기 종료
      Row sampling ratio: 데이터 일부를 무작위로 선택하는 비율
      Column sampling ratio: 피처의 하위 집합을 무작위로 선택하는 비율
      L1 / L2 norm penalty: L1/L2 정규화
    
  



  
    
      parameter
      XGBoost
      CatBoost
      LightGBM
    
  
  
    
      Learning rate
      learning_rate
      learning_rate
      learning_rate
    
    
      Tree depth
      max_depth
      depth
      max_depth
    
    
      Number of leaves
      max_leaves
      max_leaves
      num_leaves
    
    
      Number of tree
      n_estimators
      n_estimators
      n_estimators
    
    
      Early stop
      early_stopping_rounds
      od_wait
      early_stopping_rounds
    
    
      Row sampling ratio
      subsample
      subsample
      bagging_freq
    
    
      Column sampling ratio
      colsample_bytree
      rsm
      colsample_bytree
    
    
      L1/L2 norm penalty
      alpha/lambda
      l2_leaf_reg
      lambda_l1/lambda_l2
    
  




Optuna


  하이퍼 파라미터 튜닝을 위한 오픈소스 프레임워크
  파이썬을 활용한 하이퍼 파라미터 최적화, 최신 알고리즘 사용, 쉬운 병렬화
  하이퍼 파라미터 탐색 결과를 저장해서 다음에 이어서 탐색하는 것이 가능
    
      Storage API를 이용해서 RDB, Redis, SQLite 등 Persistent 저장소 이용 가능
    
  
  하이퍼 파라미터에 대한 Visualization 기능 제공
    
      개별 하이퍼 파라미터와 Object Value의 관계에 대한 시각화
        
          Param Importances로 중요도에 대한 결과를 시각화 가능
          Optimization History로 히스토리에 대한 결과를 시각화 가능
          Slice Visualization으로 각 하이퍼 파라미터 별로 목적함수가 어떻게 변화하는지 시각화 가능
        
      
      여러개 하이퍼 파라미터와 Object Value의 관계에 대한 시각화
        
          Contour로 결과를 한번에 볼 수 있도록 시각화 가능
          Parallel Coordiinate로 결과를 흐름에 따라 볼 수 있도록 시각화 가능
        
      
    
  
  사용 방법
    
      먼저 최적화를 할 objective 함수를 정의합니다.
      objective 함수 내에 trial 객체를 사용해서 하이퍼 파라미터 범위를 정의합니다.
      study 객체를 생성하고 optimize 메소드에 objective 함수를 파라미터로 넣어 호출합니다.
          import optuna

  def objective(trial):
      x = trial.suggest_uniform('x', -10, 10)
      return (x - 2) ** 2

  study = optuna.create_study()
  study.optimize(objective, n_trials=100) # 100번동안 수행하면서 최적을 찾음

  print(study.best_params) # E.g {'x': 2.002108042}
        
      
    
  




앙상블 (Ensemble)

앙상블 러닝


  하이퍼 파라미터 튜닝 이후 더 높은 성능을 내기 위해 알고리즘 여러개를 조합해서 사용하는 방법
  여러개의 약 분류기(Weak Classifier)를 결합해서 강 분류기(String Classifier)를 만듦
  쉽게 말해, 여러 모델의 투표를 통해 다수결로 결정된 것이 더 나은 결과를 도출한다는 것 (집단 지성)
  앙상블에 대한 참고
  Cross validation을 통해 결정계수(R^2)를 얻을 수 있음



앙상블 러닝 방법


  병렬 학습
    
      배깅(Bagging) / 페이스팅(Pasting)
        
          데이터를 쪼개어 같은 알고리즘 모델 여러개에 학습시키는 방식
          배깅과 페이스팅의 차이는 배깅의 경우 훈련 셋의 중복을 허용하면서 샘플링한다는 것
        
      
      Hard / Soft 보팅(Voting)
        
          Hard Voting은 모델의 예측값을 대상으로 다수결해서 결과를 도출
          Soft Voting은 예측값의 확률 분포를 사용해서 평균을 내고 제일 높은 확률의 값을 결과로 도출
          일반적으로 Soft Voting을 많이 사용
        
      
      Bagging과 Voting의 차이
        
          Bagging은 여러개 데이터셋에 하나의 알고리즘을 적용
          Voting은 하나의 데이터셋에 여러개 알고리즘을 적용
        
      
    
  
  직렬 학습
    
      부스팅 (Boosting)
        
          여러개의 분류기(Classifier)가 이전 분류기에서 틀린 데이터에 대해 가중치를 부여하면서 순차적으로 학습하는 방식
          보통 예측 성능이 뛰어나 앙상블 러닝에서 많이 사용됨
        
      
      스택킹
        
          여러 알고리즘 모델로 각각 예측 결과를 도출한 뒤 결합해서 최종 예측 결과를 만드는 방식
          여러 알고리즘 모델을 사용한다는 점에서 배깅(Bagging) / 페이스팅(Pasting)과 차이점이 있음
          서비스가 될 수 없을 정도의 고비용이 필요하기 때문에 덜 쓰이는 방법
          장점: 학습 데이터에 한해서 우수한 성능이 나옴
          단점: 매우 많은 조합을 시도하기 때문에 오래 걸리는 문제가 있음
        
      
    
  




트리 부스팅에서 사용하는 앙상블 방식


  Decisioon Tree: Impurity
    
      노드에 섞여있는 정도를 낮춰 복잡성을 낮춰야 함
      Graphviz를 통해 트리와 정보를 시각화 가능
      불순도(Impurity) 측정 방법
        
          분산계수가 낮을수록 불순도가 낮음을 의미
          불확실성(Entropy)
            
              높을수록 예측이 어려움을 의미
            
          
          분산계수(Gini Index)
            
              높을수록 데이터가 분산되어 있음을 의미
            
          
        
      
    
  
  Gradient Boosting
    
      Label과 예측값의 차이에 가중치를 두어 선택하는 기법
      기울기가 큰 데이터는 놔두고, 작은 데이터만 랜덤하게 드랍하기 때문에 데이터 분포가 왜곡되고 정확도가 낮아짐. (이를 방지하기 위해 GOSS 기법을 사용)
      동작 과정
        
          데이터셋 준비, 미분가능한 Loss function 정의
          첫번째 값으로 초기 예측값을 설정
          n번 반복하며 Loss function을 계산하고 잔차(Negative Gradient, label과 예측값의 차이)를 확인
          Weak learner(잔차를 타겟으로 하는 트리 모델)를 생성하고 최적화를 진행
          Loss를 최소로 하는 트리 결과값을 출력
          트리 결과값에 가중치를 주어 첫번째 설정한 예측값을 업데이트
          첫번째 예측값 설정부터 업데이트까지 5단계를 반복한 뒤 최종 예측값을 출력
        
      
    
  
  XGBoost
    
      XGBoost는 Gradient Boosting의 약점을 보완하기 위해 Regularization term을 추가한 알고리즘
      root노드와 가까운 노드를 우선적으로 순회하여 수평 성장시킴
      장점
        
          다양한 Loss function을 지원해서 task에 따른 유연한 튜닝이 가능하다는 장점
        
      
      단점
        
          학습 시간이 느림
          하이퍼 파라미터가 많아 튜닝이 어려움
        
      
    
  
  LightGBM
    
      XGBoost의 단점을 보완하기 위해 트리의 깊이를 줄이고 균형있게 만듦
      Loss의 변화가 가장 큰 노드에서 분할하여 성장하는 수직 성장 방식
      사용 기법들
        
          GOSS (Gradient-based One-Side Sampling)
            
              큰 데이터는 100% 취하고, 작은 데이터는 작은 비율만 취하는 방법
              기울기가 큰 데이터가 개체 정보 획득에 있어 더욱 큰 역할을 한다는 점을 이용
            
          
          EFB (EXclusive Feature Bundling)
            
              컬럼이 많을 때 변수 개수를 줄이기 위해 컬럼들이 가진 일부 값의 차이를 무시하면서 합치는 방법 (차원 축소 기법)
              어떤 피처를 골라야 하는지가 가장 큰 문제
            
          
        
      
      장점
        
          하이퍼 파라미터를 단순화하여 튜닝의 복잡성을 개선
          데이터가 많으면 성능과 효율성에 이점이 있음
        
      
      단점
        
          데이터가 적을 경우, 오버피팅이 발생하기 쉬움
        
      
    
  
  CatBoost (Category Boosting)
    
      알고리즘으로 순서형 원칙(Ordered Principle)을 사용
        
          데이터를 섞어 랜덤하게 뽑아서(Random Permutation) 결과값을 계산하고 모델을 만듦
          데이터의 잔차는 만들어진 모델로 예측한 것을 사용
        
      
      범주형 데이터를 많이 가진 데이터셋에서 성능이 높음
      범주형 feature 처리 방법
        
          Ordered Target Encoding
            
              범주형 변수를 수치형 데이터로 인코딩하는 방식
              오버피팅 방지와 수치의 다양성을 만듦
            
          
          Categorical Feature Combinations
            
              정보 이득(Infomation gain)이 동일한 경우, 하나의 피처로 묶는 방식
              데이터 전처리에 있어 피처 선택의 부담을 줄일 수 있음
            
          
          One-Hot Encoding
            
              컬럼에 변수를 두고 Boolean과 같이 1과 0으로 나누는 방법 (데이터 전처리에 필요한 인코딩 방법)
              CatBoost에서는 범주형 변수에 한해서 자동 처리
            
          
          Optimized Parameter Tuning
            
              CatBoost에서 기본 하이퍼 파라미터의 최적화가 XGBoost, LightGBM에 비해 잘 되어 있어 크게 신경쓰지 않아도 됨
            
          
        
      
    
  




최근 딥러닝 모델에서 주목하고 있는 문제 해결 접근법


  TabNet
    
      앙상블을 아니지만 정형 데이터(Tabular Data)를 위한 딥러닝 모델
      각 의사 결정 단계에서 순차적 어텐션(Sequential Attention) 기반으로 추론할 특징(feature)을 선택해서 학습 능력이 가장 두드러진 특징(feature)을 사용
      장점
        
          다른 신경망이나 변형된 의사결정트리 보다 성능이 우수하고 대규모 정형 데이터도 처리 가능
          전처리 과정이 필요하지 않으며 피처 선택과 모델 학습의 과정이 한 번에 이루어져 효과적인 학습과 어떤 피처가 중요한 지 설명이 가능
          Supervised fine-tuning 전에 feature 값을 예측하는 비감독 사전 훈련(Unsupervised Pretrain) 단계를 적용해서 높은 성능 향상을 보여줌
            
              Unsupervised Pretrain
                
                  데이터 일부에 마스킹해서 학습시키는 방식
                
              
              Supervised fine-tuning
                
                  TabNet encoder가 Feature Engineering을 수행
                  Decision masking을 통해 Attention 기반의 Feature 선택을 수행
                
              
            
          
          인코더가 fine-tuning을 하면서 Task에 맞게 성능을 향상시킴
        
      
      단점
        
          딥러닝 모델임에도 불구하고 조절해야 할 하이퍼 파라미터가 많아서 최적화에 시간이 필요함
        
      
      모델 구조
        
          TabNet Encoder
            
              각 Decision step에 대해 Feature transformer, Attentive transformer, Feature masking으로 구성
            
          
          TabNet Decoder
            
              각 Decision step에 대해 Feature transformer로 구성
            
          
          Feature transformer
            
              공유하는 Decision step 영역, 의존하는 Decision step 영역으로 나뉨
            
          
          Attentive transformer
            
              Prior scales를 단일 layer에 맵핑해서 사용
                
                  Prior scales: 현재 Decision step 이전에 Feature가 사용된 빈도를 집계한 정보
                
              
              계수의 정규화는 Sparsemax를 사용
                
                  Sparsemax: 각 Decision step에서 가장 두드러진 Feature를 선택하기 위한 값
                
              
            
          
        
      
    
  
  +정형 데이터로 학습된 딥러닝 모델에 쓰이는 앙상블 기법
    
      Deep Ensemble: 성능을 향상시키기 위해 동일한 데이터 세트에서 훈련된 여러 심층 신경망의 조합
      Snapshot Ensembling: 서로 다른 초기화 및 학습 속도로 단일 심층 신경망을 교육한 다음 서로 다른 스냅샷 지점에서 모델의 가중치를 결합하여 성능을 향상
    
  




Reference


  제대로 된 인공지능 스터디를 찾고 있다면? AI 심화 스터디
  [코칭스터디 10기] Beyond AI Basic 2023 스터디 전용강좌

">



<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://dong-jun-shin.github.io/images/CS_AI_ML/logo.png">


<!-- Open Graph -->
<meta property="og:locale" content="">
<meta property="og:type" content="article">
<meta property="og:title" content="코칭스터디 Beyond AI Basic 2023 - 2주차 학습">

<meta property="og:image" content="https://dong-jun-shin.github.io/images/CS_AI_ML/logo.png">


<meta property="og:description" content="피처 엔지니어링

피처 엔지니어링 기본 개념

정의


  모델의 성능을 올리기 위해 피처를 생성 및 변환하고 머신러닝 모델에 적합한 형식으로 변환하는 작업
  원본 데이터 + 도메인 지식을 바탕으로 문제 해결에 도움이 되는 피처를 생성, 변환
  피처 엔지니어링은 EDA를 위해 제공된 데이터에서 데이터의 특성과 시계열 특성을 고려하고 집계함수, 누적합 등을 조합해서 도움이 되는 피처를 생성
  머신러닝에서만 하는 작업
    
      딥러닝은 모델 구조에서 피처를 모델이 직접 추출 가능
    
  
  데이터의 품질만큼 성능을 결정하는 중요한 작업
  e.g. Pandas Group By Aggregation을 사용해서, 고객 ID 기반으로 집계한 새로운 피처 생성
    
      집계함수: 개수(Count), 합계(Sum), 평균(Mean), 최대값(MAX), 최소값(MIN), 표준 편차(STD), 비대칭도(SKEW) 등이 있음
        
          표준 편차 (Standard Deviation)
            
              데이터가 어느 정도 흩어져 있는 나타냄
              낮을수록 데이터가 밀집되어 있음, 높을수록 데이터가 넓게 분포되어 있음
            
          
          비대칭도 (Skewed)
            
              데이터가 어느 방향으로 모여있는지 나타냄
              Positive하면 왼쪽, Negative하면 오른쪽으로 모여있음
            
          
        
      
      agg_func = ['count', 'sum', ...]을 정의하고 agg_dict = { 'column_name': agg_func, ...} 형태로 정의, 그리고 Pandas의 함수 중 groupby로 기준 컬럼을 선택하고 agg(agg_dict) 형태로 사용
    
  




좋은 피처와 나쁜 피처


  피처 엔지니어링을 통해 얻은 피처를 그래프로 나타내었을 때, 레이블의 분포 차이로 구분
  좋은 피처는 레이블의 분포 차이가 명확함




피처 엔지니어링 후 모델 성능 측정 방법


  Cross Validation Out of Fold
    
      Cross Validation과 Out of Fold을 합친 방법
        
          Cross Validation
            
              데이터를 여러 개의 폴드로 나눠서 검증 성능을 측정하는 방법
            
          
          Out of Fold
            
              학습한 모델로 테스트 데이터를 예측하고, 평균 앙상블하여 최종 예측값으로 사용하는 방법
            
          
        
      
      데이터 세트에 존재하는 편향된 부분의 영향력을 줄이기 위해 사용
      캐글에서 일반적으로 많이 사용
    
  
  Early Stopping
    
      검증 성능이 가장 최적이라 판단되는 지점에서 학습을 조기 종료하는 방법
      이전 스텝보다 성능이 떨어지는 경우가 반복되면 조기 종료
      e.g. Boosting 트리 개수, 딥러닝의 Epoch 수를 최적화하는데 사용
    
  
  LightGBM Early Stopping
    
      LightGBM과 Early Stopping을 합친 방법
        
          LightGBM
            
              n_estimators 하이퍼파라미터로 트리 개수를 설정해서 모델을 생성
            
          
          LightGBM만 사용했을 때, 트리 개수에 대한 최적 값을 찾기 어렵기 때문에, 크게 설정하고 Early Stopping을 사용해서 성능이 최적인 부분을 찾음
        
      
    
  




누적합을 이용한 피처 엔지니어링


  누적합(cumsum)
    
      시간 또는 순서에 따라 증가하는 데이터의 총합계를 표시하는 함수
      일반적으로 집계를 하면 시간 순서 정보가 사라지기 때문에 데이터의 특성에 따라 시간 순서 정보도 고려해야 함
      Pandas의 함수 중 groupby로 기준 컬럼을 선택하고 ['column_name'].cumsum() 형태로 사용
    
  




시계열 특성을 이용한 피처 엔지니어링


  Pandas의 함수 중 groupby로 기준 컬럼을 선택하고 ['column_name'].diff() 형태로 사용
  e.g. 주문 데이터에서의 피처 엔지니어링
    
      order_ts-first: 처음 주문 시각
      order_ts-last: 마지막 주문 시각
      order_ts-diff-max: 주문 시각 차이의 최대값
      order_ts-diff-skew: 주문 시각 차이의 비대칭도
      order_ts-diff-std: 주문 시각 차이의 표준편차
      order_ts-diff-sum: 주문 시각 차이의 합
    
  




피처 중요도와 피처 선택

피처 중요도


  정답을 예측하는데 얼마나 유용한 지를 점수로 피처에 할당하는 것
  측정 방법
    
      모델 자체에서 피처 중요도를 계산하는 방법 (Model-specific)
        
          모델마다 피처 계산 방식이 달라, 각 모델에서 제공하는 기능을 사용하여 피처 중요도를 계산
            
              모델 공통으로 order_ts-last 피처가 가장 중요하고, 그 외에는 모델별로 다름
            
          
          보통 피처 선택 시 참고용으로 많이 사용
          모델별 예시
            
              LightGBM 모델에서 중요도 계산하기
                
                  feature_importance(default: split)
                  importance_type에 따른 계산 방식 사용
                    
                      split: 트리 모델을 만드는데 피처가 몇 번 사용됐는 지 계산
                      gain: split한 결과값의 평균으로 계산
                    
                  
                
              
              XGBoost 모델에서 중요도 계산하기
                
                  importance_type에 따른 계산 방식 사용
                    
                      get_score(default: weight)
                      weight: 트리 모델을 만드는데 피처가 몇 번 사용됐는 지 계산 (split과 유사)
                      gain: split한 결과값의 평균으로 계산 (gain과 유사)
                      cover: 전체 coverage의 평균으로 계산
                      total_gain: 전체 gain의 합으로 계산
                      total_cover: 전체 coverage의 합으로 계산
                    
                  
                
              
              CatBoost 모델에서 중요도 계산하기
                
                  type에 따른 계산 방식 사용
                    
                      get_feature_importance(default: FeatureImportance)
                      FeatureImportance: 피처를 임의로 섞을 때, 모델의 성능이 얼마나 감소하는지에 따라 각 기능의 중요도를 계산
                      ShapValues: 특정 샘플의 예측에 대한 각 피처의 기여도를 계산
                      Interaction: 피처 쌍을 임의로 섞을 때, 모델의 성능이 얼마나 감소하는지에 따라 각 피처 쌍의 중요도를 계산
                      PredictionDiff: 주어진 샘플에 대해 특정 피처가 변경될 때 모델 예측의 차이를 계산
                    
                  
                
              
            
          
        
      
      모델을 학습한 후 피처 중요도를 계산하는 방법 (Model-agnostic)
        
          기존 데이터와 섞은 데이터의 에러 차이를 측정해서 피처 중요도를 계산하는 방식 (Permutation Feature Importance)
          중요한 피처일수록, 모델이 예측하지 못해서 에러 값이 커짐
          중요하지 않은 피처일수록 예측하기 때문에 에러 값이 작아짐
          실제 피처를 선택할 때 많이 사용
          계산 예시
            
              Input: Trained model, feature matrix, target vector(label), error measure(function)
              오리지널 모델로 error measure를 계산
              feature를 하나씩 돌면서 feature matrix의 데이터를 여러번 섞은 후 에러를 구함
              섞은 후 에러와 오리지널에서 얻은 에러를 비교해서 차이를 저장
              에러 차이가 큰 순서로 정렬해서 피처의 중요한 순서대로 확인
            
          
        
      
      모델별 피처 중요도 순위 예시
    
  



  
    
       
      LightGBM
      XGBoost
      CatBoost
    
  
  
    
      feature 1
      order_ts-last
      order_ts-last
      order_ts-last
    
    
      feature 2
      order_ts_diff-max
      quantity_diff-skew
      year_month_mode
    
    
      feature 3
      order_ts-first
      cumsum_price_by_prod_id-skew
      order_ts-first
    
    
      feature 4
      cumsum_price_by_prod_id-skew
      price_diff-skew
      order_ts_diff-max
    
    
      feature 5
      quantity_diff-skew
      order_ts-first
      cumsum_total_by_prod_id-sum
    
  




피처 선택


  피처 간에 비슷한 값들을 갖는다면 노이즈 데이터로 학습될 수 있기 때문에 방지하기 위해 피처를 선별
  모델 복잡도를 낮춰, 오버피팅을 방지하고 모델 속도를 향상시킴
  선택 방법
    
      Filter Method
        
          통계적인 측정을 통해 선택하는 방법
          모든 피처 셋 &gt; 서브셋 생성 &gt; 알고리즘 학습 &gt; 성능 측정
          상관관계(Correlation)를 측정하여 유사한 피처를 제거 or 피처의 분산을 계산하여 분산 값이 작은 경우 제거
          계산 속도가 빠르고 피처 간의 상관관계를 알기 좋음
        
      
      Wrapper Method
        
          예측 모델을 사용해서 선택하는 방법
          모든 피처 셋 &gt; 서브셋 생성 &gt; 알고리즘 학습 단계 반복 &gt; 성능 측정
          피처의 서브 셋을 계속 테스트해서 성능에 유용하지 않은 피처를 제거
        
      
      Embedded Method
        
          Filter와 Wrapper의 장점을 합친 방법
          모든 피처 셋 &gt; 서브셋 생성 &gt; 알고리즘 학습 + 성능 측정 단계 반복
          학습 알고리즘 자체에 피처 선택이 들어가 있음
        
      
    
  




하이퍼 파라미터 튜닝과 앙상블

하이퍼 파라미터 튜닝

하이퍼 파라미터


  모델의 성능을 더욱 끌어내기 위해, 학습 이전에 사람이 조작하는 값
  파라미터는 모델이 학습 과정에서 배우는 값 (하이퍼 파라미터와는 다름)
  e.g. learning_rate, n_estimators




튜닝


  하이퍼 파라미터를 최적화하는 과정
  최적의 값을 찾는 방법
    
      Manual Search
        
          수동으로 실험할 하이퍼 파라미터 셋을 정해, 하나씩 테스트해보는 방식
        
      
      Grid Search
        
          모든 경우를 테스트하는 방식
          e.g. learning rate 탐색 공간 [0.01, 0.05, 0.1, 0.2]로 설정하고 n_estimators 탐색 공간 [100, 200]을 설정한다면 나올 수 있는 조합의 수 8가지를 모두 테스트
        
      
      Random Search
        
          랜덤하게 하이퍼 파라미터를 선택해서 테스트하는 방식
          일반적으로 Grid Search보다 성능이 좋음
        
      
      Bayesian Optimization
        
          이전 결과를 기반으로 다음 하이퍼 파라미터의 값을 선택하는 방식
          성능이 잘 나온 영역이 있다면 집중적으로 탐색해서 찾음
        
      
    
  




Boosting Tree 하이퍼 파라미터


  정형 데이터에서 자주 사용하는 Boosting Tree 모델들의 하이퍼 파라미터
    
      Learning Rate: 모델의 학습률
      Tree depth: 트리 모델의 최대 깊이
      Number of leaves: 한 트리의 최대 리브 수
      Early stop: 검증 성능이 향상하지 않으면 조기 종료
      Row sampling ratio: 데이터 일부를 무작위로 선택하는 비율
      Column sampling ratio: 피처의 하위 집합을 무작위로 선택하는 비율
      L1 / L2 norm penalty: L1/L2 정규화
    
  



  
    
      parameter
      XGBoost
      CatBoost
      LightGBM
    
  
  
    
      Learning rate
      learning_rate
      learning_rate
      learning_rate
    
    
      Tree depth
      max_depth
      depth
      max_depth
    
    
      Number of leaves
      max_leaves
      max_leaves
      num_leaves
    
    
      Number of tree
      n_estimators
      n_estimators
      n_estimators
    
    
      Early stop
      early_stopping_rounds
      od_wait
      early_stopping_rounds
    
    
      Row sampling ratio
      subsample
      subsample
      bagging_freq
    
    
      Column sampling ratio
      colsample_bytree
      rsm
      colsample_bytree
    
    
      L1/L2 norm penalty
      alpha/lambda
      l2_leaf_reg
      lambda_l1/lambda_l2
    
  




Optuna


  하이퍼 파라미터 튜닝을 위한 오픈소스 프레임워크
  파이썬을 활용한 하이퍼 파라미터 최적화, 최신 알고리즘 사용, 쉬운 병렬화
  하이퍼 파라미터 탐색 결과를 저장해서 다음에 이어서 탐색하는 것이 가능
    
      Storage API를 이용해서 RDB, Redis, SQLite 등 Persistent 저장소 이용 가능
    
  
  하이퍼 파라미터에 대한 Visualization 기능 제공
    
      개별 하이퍼 파라미터와 Object Value의 관계에 대한 시각화
        
          Param Importances로 중요도에 대한 결과를 시각화 가능
          Optimization History로 히스토리에 대한 결과를 시각화 가능
          Slice Visualization으로 각 하이퍼 파라미터 별로 목적함수가 어떻게 변화하는지 시각화 가능
        
      
      여러개 하이퍼 파라미터와 Object Value의 관계에 대한 시각화
        
          Contour로 결과를 한번에 볼 수 있도록 시각화 가능
          Parallel Coordiinate로 결과를 흐름에 따라 볼 수 있도록 시각화 가능
        
      
    
  
  사용 방법
    
      먼저 최적화를 할 objective 함수를 정의합니다.
      objective 함수 내에 trial 객체를 사용해서 하이퍼 파라미터 범위를 정의합니다.
      study 객체를 생성하고 optimize 메소드에 objective 함수를 파라미터로 넣어 호출합니다.
          import optuna

  def objective(trial):
      x = trial.suggest_uniform('x', -10, 10)
      return (x - 2) ** 2

  study = optuna.create_study()
  study.optimize(objective, n_trials=100) # 100번동안 수행하면서 최적을 찾음

  print(study.best_params) # E.g {'x': 2.002108042}
        
      
    
  




앙상블 (Ensemble)

앙상블 러닝


  하이퍼 파라미터 튜닝 이후 더 높은 성능을 내기 위해 알고리즘 여러개를 조합해서 사용하는 방법
  여러개의 약 분류기(Weak Classifier)를 결합해서 강 분류기(String Classifier)를 만듦
  쉽게 말해, 여러 모델의 투표를 통해 다수결로 결정된 것이 더 나은 결과를 도출한다는 것 (집단 지성)
  앙상블에 대한 참고
  Cross validation을 통해 결정계수(R^2)를 얻을 수 있음



앙상블 러닝 방법


  병렬 학습
    
      배깅(Bagging) / 페이스팅(Pasting)
        
          데이터를 쪼개어 같은 알고리즘 모델 여러개에 학습시키는 방식
          배깅과 페이스팅의 차이는 배깅의 경우 훈련 셋의 중복을 허용하면서 샘플링한다는 것
        
      
      Hard / Soft 보팅(Voting)
        
          Hard Voting은 모델의 예측값을 대상으로 다수결해서 결과를 도출
          Soft Voting은 예측값의 확률 분포를 사용해서 평균을 내고 제일 높은 확률의 값을 결과로 도출
          일반적으로 Soft Voting을 많이 사용
        
      
      Bagging과 Voting의 차이
        
          Bagging은 여러개 데이터셋에 하나의 알고리즘을 적용
          Voting은 하나의 데이터셋에 여러개 알고리즘을 적용
        
      
    
  
  직렬 학습
    
      부스팅 (Boosting)
        
          여러개의 분류기(Classifier)가 이전 분류기에서 틀린 데이터에 대해 가중치를 부여하면서 순차적으로 학습하는 방식
          보통 예측 성능이 뛰어나 앙상블 러닝에서 많이 사용됨
        
      
      스택킹
        
          여러 알고리즘 모델로 각각 예측 결과를 도출한 뒤 결합해서 최종 예측 결과를 만드는 방식
          여러 알고리즘 모델을 사용한다는 점에서 배깅(Bagging) / 페이스팅(Pasting)과 차이점이 있음
          서비스가 될 수 없을 정도의 고비용이 필요하기 때문에 덜 쓰이는 방법
          장점: 학습 데이터에 한해서 우수한 성능이 나옴
          단점: 매우 많은 조합을 시도하기 때문에 오래 걸리는 문제가 있음
        
      
    
  




트리 부스팅에서 사용하는 앙상블 방식


  Decisioon Tree: Impurity
    
      노드에 섞여있는 정도를 낮춰 복잡성을 낮춰야 함
      Graphviz를 통해 트리와 정보를 시각화 가능
      불순도(Impurity) 측정 방법
        
          분산계수가 낮을수록 불순도가 낮음을 의미
          불확실성(Entropy)
            
              높을수록 예측이 어려움을 의미
            
          
          분산계수(Gini Index)
            
              높을수록 데이터가 분산되어 있음을 의미
            
          
        
      
    
  
  Gradient Boosting
    
      Label과 예측값의 차이에 가중치를 두어 선택하는 기법
      기울기가 큰 데이터는 놔두고, 작은 데이터만 랜덤하게 드랍하기 때문에 데이터 분포가 왜곡되고 정확도가 낮아짐. (이를 방지하기 위해 GOSS 기법을 사용)
      동작 과정
        
          데이터셋 준비, 미분가능한 Loss function 정의
          첫번째 값으로 초기 예측값을 설정
          n번 반복하며 Loss function을 계산하고 잔차(Negative Gradient, label과 예측값의 차이)를 확인
          Weak learner(잔차를 타겟으로 하는 트리 모델)를 생성하고 최적화를 진행
          Loss를 최소로 하는 트리 결과값을 출력
          트리 결과값에 가중치를 주어 첫번째 설정한 예측값을 업데이트
          첫번째 예측값 설정부터 업데이트까지 5단계를 반복한 뒤 최종 예측값을 출력
        
      
    
  
  XGBoost
    
      XGBoost는 Gradient Boosting의 약점을 보완하기 위해 Regularization term을 추가한 알고리즘
      root노드와 가까운 노드를 우선적으로 순회하여 수평 성장시킴
      장점
        
          다양한 Loss function을 지원해서 task에 따른 유연한 튜닝이 가능하다는 장점
        
      
      단점
        
          학습 시간이 느림
          하이퍼 파라미터가 많아 튜닝이 어려움
        
      
    
  
  LightGBM
    
      XGBoost의 단점을 보완하기 위해 트리의 깊이를 줄이고 균형있게 만듦
      Loss의 변화가 가장 큰 노드에서 분할하여 성장하는 수직 성장 방식
      사용 기법들
        
          GOSS (Gradient-based One-Side Sampling)
            
              큰 데이터는 100% 취하고, 작은 데이터는 작은 비율만 취하는 방법
              기울기가 큰 데이터가 개체 정보 획득에 있어 더욱 큰 역할을 한다는 점을 이용
            
          
          EFB (EXclusive Feature Bundling)
            
              컬럼이 많을 때 변수 개수를 줄이기 위해 컬럼들이 가진 일부 값의 차이를 무시하면서 합치는 방법 (차원 축소 기법)
              어떤 피처를 골라야 하는지가 가장 큰 문제
            
          
        
      
      장점
        
          하이퍼 파라미터를 단순화하여 튜닝의 복잡성을 개선
          데이터가 많으면 성능과 효율성에 이점이 있음
        
      
      단점
        
          데이터가 적을 경우, 오버피팅이 발생하기 쉬움
        
      
    
  
  CatBoost (Category Boosting)
    
      알고리즘으로 순서형 원칙(Ordered Principle)을 사용
        
          데이터를 섞어 랜덤하게 뽑아서(Random Permutation) 결과값을 계산하고 모델을 만듦
          데이터의 잔차는 만들어진 모델로 예측한 것을 사용
        
      
      범주형 데이터를 많이 가진 데이터셋에서 성능이 높음
      범주형 feature 처리 방법
        
          Ordered Target Encoding
            
              범주형 변수를 수치형 데이터로 인코딩하는 방식
              오버피팅 방지와 수치의 다양성을 만듦
            
          
          Categorical Feature Combinations
            
              정보 이득(Infomation gain)이 동일한 경우, 하나의 피처로 묶는 방식
              데이터 전처리에 있어 피처 선택의 부담을 줄일 수 있음
            
          
          One-Hot Encoding
            
              컬럼에 변수를 두고 Boolean과 같이 1과 0으로 나누는 방법 (데이터 전처리에 필요한 인코딩 방법)
              CatBoost에서는 범주형 변수에 한해서 자동 처리
            
          
          Optimized Parameter Tuning
            
              CatBoost에서 기본 하이퍼 파라미터의 최적화가 XGBoost, LightGBM에 비해 잘 되어 있어 크게 신경쓰지 않아도 됨
            
          
        
      
    
  




최근 딥러닝 모델에서 주목하고 있는 문제 해결 접근법


  TabNet
    
      앙상블을 아니지만 정형 데이터(Tabular Data)를 위한 딥러닝 모델
      각 의사 결정 단계에서 순차적 어텐션(Sequential Attention) 기반으로 추론할 특징(feature)을 선택해서 학습 능력이 가장 두드러진 특징(feature)을 사용
      장점
        
          다른 신경망이나 변형된 의사결정트리 보다 성능이 우수하고 대규모 정형 데이터도 처리 가능
          전처리 과정이 필요하지 않으며 피처 선택과 모델 학습의 과정이 한 번에 이루어져 효과적인 학습과 어떤 피처가 중요한 지 설명이 가능
          Supervised fine-tuning 전에 feature 값을 예측하는 비감독 사전 훈련(Unsupervised Pretrain) 단계를 적용해서 높은 성능 향상을 보여줌
            
              Unsupervised Pretrain
                
                  데이터 일부에 마스킹해서 학습시키는 방식
                
              
              Supervised fine-tuning
                
                  TabNet encoder가 Feature Engineering을 수행
                  Decision masking을 통해 Attention 기반의 Feature 선택을 수행
                
              
            
          
          인코더가 fine-tuning을 하면서 Task에 맞게 성능을 향상시킴
        
      
      단점
        
          딥러닝 모델임에도 불구하고 조절해야 할 하이퍼 파라미터가 많아서 최적화에 시간이 필요함
        
      
      모델 구조
        
          TabNet Encoder
            
              각 Decision step에 대해 Feature transformer, Attentive transformer, Feature masking으로 구성
            
          
          TabNet Decoder
            
              각 Decision step에 대해 Feature transformer로 구성
            
          
          Feature transformer
            
              공유하는 Decision step 영역, 의존하는 Decision step 영역으로 나뉨
            
          
          Attentive transformer
            
              Prior scales를 단일 layer에 맵핑해서 사용
                
                  Prior scales: 현재 Decision step 이전에 Feature가 사용된 빈도를 집계한 정보
                
              
              계수의 정규화는 Sparsemax를 사용
                
                  Sparsemax: 각 Decision step에서 가장 두드러진 Feature를 선택하기 위한 값
                
              
            
          
        
      
    
  
  +정형 데이터로 학습된 딥러닝 모델에 쓰이는 앙상블 기법
    
      Deep Ensemble: 성능을 향상시키기 위해 동일한 데이터 세트에서 훈련된 여러 심층 신경망의 조합
      Snapshot Ensembling: 서로 다른 초기화 및 학습 속도로 단일 심층 신경망을 교육한 다음 서로 다른 스냅샷 지점에서 모델의 가중치를 결합하여 성능을 향상
    
  




Reference


  제대로 된 인공지능 스터디를 찾고 있다면? AI 심화 스터디
  [코칭스터디 10기] Beyond AI Basic 2023 스터디 전용강좌

">
<meta property="og:url" content="https://dong-jun-shin.github.io/2023/05/15/Beyond_AI_Basic_2023_Week_2/">
<meta property="og:site_name" content="Jun's Dev_Blog">
  <link rel="canonical" href="https://dong-jun-shin.github.io/2023/05/15/Beyond_AI_Basic_2023_Week_2/" />
  <link
    rel="alternate"
    type="application/rss+xml"
    title="Jun's Dev_Blog"
    href="https://dong-jun-shin.github.io/feed.xml"
  />
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css?family=Volkhov:400,700" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@200;300;400;500;700;900&display=swap" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css2?family=Courier+Prime:wght@700&display=swap" rel="stylesheet" />
  <!-- Common -->
  <style>
    
    /*! normalize.css v7.0.0 | MIT License | github.com/necolas/normalize.css */html,body{scroll-behavior:smooth}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{font-weight:normal;letter-spacing:0;margin:0}article,aside,footer,header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}figcaption,figure,main{display:block}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:rgba(0,0,0,0);-webkit-text-decoration-skip:objects}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}dfn{font-style:italic}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}img{border-style:none}svg:not(:root){overflow:hidden}button,input,optgroup,select,textarea{font-family:"Noto Sans KR",sans-serif;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,html [type=button],[type=reset],[type=submit]{-webkit-appearance:button}button::-moz-focus-inner,[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{display:inline-block;vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details,menu{display:block}summary{display:list-item}canvas{display:inline-block}template{display:none}[hidden]{display:none}body,h1,h2,h3,h4,h5,h6,p,blockquote,pre,dl,dd,ol,ul,fieldset,legend,figure,hr{margin:0;padding:0}li>ul,li>ol{margin-bottom:0}table{border:.14em solid #000;border-collapse:collapse;border-spacing:0;word-break:initial;width:100%}table tr:nth-child(even){background-color:#f2fafd}thead{background-color:#a0d0ee}table th{text-align:center;padding:6px 13px;border:.1em solid #757575}table td{padding:6px 13px;border:.1em solid #757575}table tr{padding:6px 13px;border:.1em solid #757575}@-webkit-keyframes spin{100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes spin{100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.icon{position:relative;display:inline-block;width:25px;height:25px;overflow:hidden;fill:currentColor}.icon__cnt{width:100%;height:100%;background:inherit;fill:inherit;pointer-events:none;transform:translateX(0);-ms-transform:translate(0.5px, -0.3px)}.icon--m{width:50px;height:50px}.icon--l{width:100px;height:100px}.icon--xl{width:150px;height:150px}.icon--xxl{width:200px;height:200px}.icon__spinner{position:absolute;top:0;left:0;width:100%;height:100%}.icon--ei-spinner .icon__spinner,.icon--ei-spinner-2 .icon__spinner{-webkit-animation:spin 1s steps(12) infinite;animation:spin 1s steps(12) infinite}.icon--ei-spinner-3 .icon__spinner{-webkit-animation:spin 1.5s linear infinite;animation:spin 1.5s linear infinite}.icon--ei-sc-facebook{fill:#3b5998}.icon--ei-sc-github{fill:#333}.icon--ei-sc-google-plus{fill:#dd4b39}.icon--ei-sc-instagram{fill:#3f729b}.icon--ei-sc-linkedin{fill:#0976b4}.icon--ei-sc-odnoklassniki{fill:#ed812b}.icon--ei-sc-skype{fill:#00aff0}.icon--ei-sc-soundcloud{fill:#f80}.icon--ei-sc-tumblr{fill:#35465c}.icon--ei-sc-twitter{fill:#55acee}.icon--ei-sc-vimeo{fill:#1ab7ea}.icon--ei-sc-vk{fill:#45668e}.icon--ei-sc-youtube{fill:#e52d27}.icon--ei-sc-pinterest{fill:#bd081c}.icon--ei-sc-telegram{fill:#08c}*,*::after,*::before{box-sizing:border-box}h1,h2,h3,h4,h5,h6,ul,ol,dl,blockquote,p,address,hr,table,fieldset,figure,pre{margin-bottom:20px}ul,ol,dd{margin-left:20px}.highlight{background:#f7f7f7}.highlighter-rouge .highlight{background:#0d1117;color:#e6edf3;border-radius:10px}.highlight .c{color:#7ca668;font-style:italic}.highlight .ch{color:#7ca668;font-style:italic}.highlight .cm{color:#7ca668;font-style:italic}.highlight .cp{color:#7ca668;font-style:italic;font-weight:normal}.highlight .cpf{color:#7ca668;font-style:italic}.highlight .c1{color:#7ca668;font-style:italic}.highlight .cs{color:#7ca668;font-style:italic}.highlight .err{color:#f85149}.highlight .esc{color:#e6edf3}.highlight .g{color:#e6edf3}.highlight .k{color:#c586c0}.highlight .l{color:#a5d6ff}.highlight .n{color:#e6edf3}.highlight .o{color:#d4d4d4}.highlight .x{color:#e6edf3}.highlight .p{color:#d4d4d4}.highlight .gd{color:#ffa198;background-color:#490202}.highlight .ge{color:#e6edf3;font-style:italic}.highlight .ges{color:#e6edf3;font-weight:bold;font-style:italic}.highlight .gr{color:#ffa198}.highlight .gh{color:#79c0ff;font-weight:bold}.highlight .gi{color:#56d364;background-color:#0f5323}.highlight .go{color:#8b949e}.highlight .gp{color:#8b949e}.highlight .gs{color:#e6edf3;font-weight:bold}.highlight .gu{color:#79c0ff}.highlight .gt{color:#ff7b72}.highlight .g-Underline{color:#e6edf3;text-decoration:underline}.highlight .kc{color:#79c0ff}.highlight .kd{color:#569cd6}.highlight .kn{color:#ff7b72}.highlight .kp{color:#79c0ff}.highlight .kr{color:#4ec9b0}.highlight .kt{color:#4ec9b0}.highlight .ld{color:#ce9178}.highlight .sd{color:#a5d6ff}.highlight .na{color:#e6edf3}.highlight .nb{color:#4ec9b0}.highlight .nc{color:#4ec9b0;font-weight:bold}.highlight .no{color:#79c0ff;font-weight:bold}.highlight .nd{color:#d2a8ff;font-weight:bold}.highlight .ni{color:#ffa657}.highlight .ne{color:#f0883e;font-weight:bold}.highlight .nf{color:#dcdcaa;font-weight:bold}.highlight .nl{color:#4ec9b0;font-weight:bold}.highlight .nn{color:#ff7b72}.highlight .nx{color:#9cdcfe}.highlight .py{color:#79c0ff}.highlight .nt{color:#4ec9b0}.highlight .nv{color:#79c0ff}.highlight .ow{color:#ff7b72;font-weight:bold}.highlight .pm{color:#e6edf3}.highlight .w{color:#6e7681}.highlight .mb{color:#a5d6ff}.highlight .mf{color:#b5cea8}.highlight .mh{color:#a5d6ff}.highlight .mi{color:#b5cea8}.highlight .mo{color:#a5d6ff}.highlight .sa{color:#79c0ff}.highlight .sb{color:#a5d6ff}.highlight .sc{color:#a5d6ff}.highlight .dl{color:#ce9178}.highlight .sd{color:#a5d6ff}.highlight .s{color:#ce9178}.highlight .s1{color:#ce9178}.highlight .s2{color:#ce9178}.highlight .se{color:#79c0ff}.highlight .sh{color:#79c0ff}.highlight .si{color:#a5d6ff}.highlight .sx{color:#a5d6ff}.highlight .sr{color:#79c0ff}.highlight .ss{color:#a5d6ff}.highlight .bp{color:#e6edf3}.highlight .fm{color:#d2a8ff;font-weight:bold}.highlight .vc{color:#79c0ff}.highlight .vg{color:#79c0ff}.highlight .vi{color:#79c0ff}.highlight .vm{color:#79c0ff}.highlight .il{color:#a5d6ff}body{font-family:"Open Sans",Helvetica Neue,Helvetica,"Noto Sans KR",Arial,sans-serif;font-size:16px;line-height:28px;color:#404040;background-color:#fbfbfb;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}*::selection{color:#fff;background-color:#3af}.toc-container{margin-bottom:20px;display:flex;justify-content:center}.toc{background-color:#fff;border:1px solid #edeeee;border-radius:8px;padding:20px;box-shadow:0 2px 4px rgba(0,0,0,.1);width:100%;font-family:"Noto Sans KR",sans-serif;text-align:left}.toc-title{font-family:"Noto Sans KR",sans-serif;font-size:32px;font-weight:700;color:#05b;margin-bottom:20px;text-align:left;background-color:rgba(204,238,255,.5);padding:15px;border-radius:5px;border:1px solid #ccc}.toc ul{list-style-type:disc;padding-left:15px}.toc a{font-family:"Noto Sans KR",sans-serif;font-size:16px;color:hsl(205,100%,45%);text-decoration:none;display:block;transition:color .3s ease,background-color .3s ease}.toc a:hover{background-color:#eee;color:rgb(0,89.25,153);text-decoration:underline}.toc a:active{color:#05b}.toc .list-group-item.active{background-color:rgba(34,34,34,.8);color:#fff;font-weight:bold;border-radius:5px}.toc .list-group-item.disabled{color:#6c757d;background-color:rgba(0,0,0,0)}.toc .list-group-item+.list-group-item{margin-top:8px}h1,h2,h3,h4,h5,h6{font-family:"Noto Sans KR",serif;font-weight:700;line-height:initial}h1{font-weight:700;font-size:36px;line-height:110%;margin-top:1.6em;margin-bottom:.8em}h2{font-weight:700;font-size:32px;margin-top:1.6em;margin-bottom:.8em}h3{font-weight:700;font-size:28px;margin-top:1.8em;margin-bottom:.9em}h4{font-weight:700;font-size:24px;margin-top:2em;margin-bottom:1em}h5{font-weight:700;font-size:22px;margin-top:2em;margin-bottom:1em;color:#333}h6{font-weight:700;font-size:20px;margin-top:2em;margin-bottom:1em;color:#444}img{max-width:100%;height:auto;vertical-align:middle}img+strong:before{display:inline-block;content:"▲";padding-right:5px;font-size:14px}img+strong{display:block;font-size:14px}p:has(>img):has(>strong){max-width:90%;margin:50px auto;text-align:center}a{text-decoration:none;color:hsl(205,100%,45%);transition:.35s}a:hover{color:rgb(0,89.25,153)}blockquote{padding-left:20px;border-left:4px solid #3af;font-family:"Noto Sans KR",serif;font-style:normal;font-size:14px;background-color:rgb(237.58,248.3,252.32)}blockquote p{padding:10px}hr{height:4px;margin:20px 0;border:0;background-color:#6b6b6b}pre{overflow:auto;padding:14px;font-size:14px;white-space:pre-wrap;word-wrap:break-word;word-break:break-all;font-family:Courier,"Noto Sans KR",monospace}pre.highlight{padding:15px 20px}code{border-radius:10px;overflow:auto;white-space:pre-wrap;word-wrap:break-word;word-break:break-all;font-family:Menlo,Monaco,"Courier New",monospace;font-weight:bold;font-size:14px;vertical-align:middle}p code,li code{color:#eb5757;background-color:#edeeee;margin:0 2px;padding:5px 6px}pre code{font-size:14px;color:#ddd;background-color:rgba(0,0,0,0)}.language-plaintext code{color:#ddd}.o-wrapper{max-width:1440px;position:relative}.o-opacity{animation-duration:.7s;animation-delay:.2s;animation-fill-mode:both;animation-name:opacity}@keyframes opacity{from{opacity:0}to{opacity:1}}.c-btn{display:inline-block;white-space:nowrap;vertical-align:middle;font-family:"Noto Sans KR",serif;font-size:14px;text-align:center;padding:5px 15px;cursor:pointer;transition:.35s}.c-btn--primary{color:#fff;background-color:#3af;background:linear-gradient(135deg, #33aaff 0%, #62d5ff 100%)}.c-btn--secondary{color:#fff;background-color:#cfcfdd;background:linear-gradient(135deg, #a2a2bd 0%, #cfcfdd 100%)}.c-btn--bar{color:#fff;background-color:#444;background:#525252;font-size:14px;width:76%;height:40px}.c-btn--round{border-radius:30px}.c-btn--shadow{box-shadow:8px 10px 20px 0 rgba(46,61,73,.15)}.c-btn--shadow:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,.2)}.c-btn--middle{display:block;width:300px;max-width:100%}.c-btn--big{display:block;width:100%}.c-btn:hover{color:#fff;transition:.35s}.c-btn:active{transform:translateY(2px)}.c-sidebar{display:flex;flex-direction:column;justify-content:space-between;position:fixed;top:0;left:0;bottom:0;width:360px;padding:40px 20px 20px;text-align:center;box-shadow:1px 1px 0 rgba(31,35,46,.15);background-color:#fff}.c-sidebar-author{display:flex;flex-direction:column}.c-sidebar-author .c-author__cover{width:100px;height:100px;margin:0 auto 10px;border-radius:50%;overflow:hidden;background-color:#cfcfdd}.c-sidebar-author .c-author__cover img{width:100%;height:100%;border-radius:50%;transition:.35s}.c-sidebar-author .c-author__cover img:hover{transform:scale3d(0.9, 0.9, 1)}.c-sidebar-author .c-contact-menu .c-btn{min-width:110px}.c-sidebar-author .c-contact-menu .c-btn .icon{vertical-align:text-bottom;fill:#fff}.c-sidebar-author .c-author__info{font-family:"Noto Sans KR",serif}.c-sidebar-author .c-author__name{font-size:18px;font-weight:700;line-height:21px}.c-sidebar-author .c-author__job{font-size:12px;color:#a0a0a0;margin:5px 0 0}.c-sidebar-author .c-contact-menu{justify-items:center;margin:30px 0px 10px 0px}.c-sidebar-author .c-contact-menu .c-btn{width:130px}.c-sidebar-author .c-contact-menu-bar{justify-items:center;margin:0px 0px 25px 0px}.c-sidebar-author .c-contact-menu-bar .c-btn{font-size:14px;width:260px}.c-sidebar-author .c-author__about{max-width:400px;margin:0 auto 15px;font-size:13px}.c-sidebar-footer .c-social__title{position:relative;font-family:"Noto Sans KR",serif;font-size:16px;font-weight:700;color:#444}.c-sidebar-footer .c-social__title::before{content:"";display:block;height:2px;width:calc(50% - 40px);transform:translateY(-50%);position:absolute;top:50%;left:0;background-color:#444}.c-sidebar-footer .c-social__title::after{content:"";display:block;height:2px;width:calc(50% - 40px);transform:translateY(-50%);position:absolute;top:50%;right:0;background-color:#444}.c-sidebar-footer .c-social__list{list-style-type:none;padding:0;margin:15px 0}.c-sidebar-footer .c-social__list .c-social__item{display:inline-block;width:27px;height:27px}.c-sidebar-footer .c-social__list .icon{width:27px;height:27px;fill:#444;vertical-align:middle;transition:.35s}.c-sidebar-footer .c-social__list .icon:hover{fill:#3af;transform:scale(1.2);transition:.35s}.c-sidebar-footer .c-copyright p{font-size:13px;margin:0}@media only screen and (max-width: 900px){.c-sidebar{position:relative;width:100%;padding:20px}.c-sidebar .c-contact-menu{margin:20px 0}.c-sidebar-footer .c-social .c-social__title{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}.c-sidebar-footer .c-social__list{margin:0}.c-sidebar-footer .c-copyright{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}}@media only screen and (max-width: 480px){.c-sidebar-author{display:flex;flex-direction:column}.c-sidebar-author .c-author__cover{width:80px;height:80px}.c-sidebar-author .c-author__cover img{width:100%;height:100%}.c-sidebar-author .c-contact-menu{justify-items:center;margin:15px 0px 0px 0px;min-width:245px}.c-sidebar-author .c-contact-menu .c-btn{min-width:80px;font-size:12px;width:120px;height:36px;margin-bottom:10px}.c-sidebar-author .c-contact-menu-bar{justify-items:center;margin:0px 0px 25px 0px}.c-sidebar-author .c-contact-menu-bar .c-btn{min-width:80px;font-size:12px;width:244px;height:36px;padding:4px 15px}.c-sidebar-footer .c-social .c-social__title{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}.c-sidebar-footer .c-social__list{margin:0}.c-sidebar-footer .c-social__list .icon{width:25px;height:25px}.c-sidebar-footer .c-copyright{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}}.c-content{position:relative;display:flex;flex-direction:row;flex-wrap:wrap;align-items:stretch;padding:0 20px 0;margin-left:360px}@media only screen and (max-width: 900px){.c-content{position:static;padding:0 15px 0;margin-left:0}}.c-posts{width:100%;display:flex;flex-direction:row;flex-wrap:wrap}.c-post{width:100%;max-width:100%;margin-bottom:20px;display:flex;flex-direction:row;align-items:stretch;min-height:180px;border-radius:10px;overflow:hidden;transition:.35s;background-color:#fff;box-shadow:0 1px 1px 0 rgba(31,35,46,.15)}.c-post:hover{transform:translate(0px, -2px);box-shadow:0 15px 45px -10px rgba(10,16,34,.2)}.c-post .c-post-thumbnail{display:block;width:30%;max-width:100%;min-height:180px;border-radius:10px 0 0 10px;background-color:rgba(220,235,245,.2);background-size:cover;background-position:50% 50%}.c-post .c-post-content{padding:15px;width:70%}.c-post .c-post-content .c-post-title{font-size:30px;font-weight:400;margin:0 0 15px}.c-post .c-post-content .c-post-title a{text-decoration:none;color:#263959}.c-post .c-post-content .c-post-tags{padding:3px 5px;border-radius:3px;background-color:rgba(135,131,120,.2);color:#eb5757;font-size:85%;font-family:"Courier Prime","Noto Sans KR"}.c-post .c-post-content .c-post-date,.c-post .c-post-content .c-post-words{font-size:12px}.c-load-more{padding:20px;margin:20px auto 40px;font-size:13px;color:#fff;border:none;background-color:#3af;outline:none}.c-load-more:hover{background-color:hsl(205,100%,45%)}@media only screen and (max-width: 1200px){.c-post{width:48%;max-width:100%;margin:0 1% 20px;flex-direction:column}.c-post .c-post-thumbnail{width:100%;border-radius:10px 10px 0 0}.c-post .c-post-content{width:100%}.c-post .c-post-content .c-post-title{font-size:21px;margin:15px 0}}@media only screen and (max-width: 480px){.c-post{width:100%;max-width:100%;margin:0 0 20px}.c-post .c-post-content{width:100%}.c-post .c-post-content .c-post-title{font-size:21px;margin:15px 0}}.c-article{width:100%;margin:20px 0}.c-wrap-content{padding:7%;background-color:#fff}.c-article__image{position:relative;background-color:rgba(220,235,245,.2);background-position:center;background-size:cover;background-repeat:no-repeat}.c-article__image:after{content:"";display:block;padding-top:56%}.c-article__header{margin-bottom:60px;padding-bottom:10px;text-align:center;border-bottom:1px solid #6b6b6b}.c-article__header .c-article__title{margin-bottom:10px}.c-article__date span{font-size:13px;text-transform:uppercase;color:#a0a0a0}.c-article__footer{margin:60px 0 0;padding-top:20px;padding-bottom:10px;text-align:center;border-top:1px solid #6b6b6b}.c-article__footer .c-article__share{transition:.35s}.c-article__footer .c-article__share a .icon{vertical-align:middle;transition:.35s}.c-article__footer .c-article__share a .icon:hover{opacity:.7;transition:.35s}.c-article__footer .c-article__tag{margin-bottom:5px}.c-article__footer .c-article__tag a{display:inline-block;vertical-align:middle;padding:5px 10px;font-family:"Noto Sans KR",serif;font-size:10px;line-height:10px;text-transform:uppercase;background-color:rgba(115,138,160,.6);color:#fff}.c-article__footer .c-article__tag a:hover{background-color:rgba(80.2446808511,99.6723404255,118.2553191489,.6)}.c-article__footer .c-article__tag a:last-child{margin-right:0}.c-recent-post{padding:30px 0}.c-recent-post .c-recent__title{font-size:14px;text-align:center;text-transform:uppercase;margin-bottom:30px}.c-recent-post .c-recent__box{display:flex;flex-direction:row;flex-wrap:wrap}.c-recent-post .c-recent__item{max-width:23%;flex-basis:23%;margin:0 1% 20px;border-radius:10px;overflow:hidden;text-align:center;background-color:#fff;box-shadow:0 1px 1px 0 rgba(31,35,46,.15);transition:.35s}.c-recent-post .c-recent__item h4{margin-bottom:5px;font-size:12px;text-transform:uppercase}.c-recent-post .c-recent__item h4 a{color:#444}.c-recent-post .c-recent__item:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,.2)}.c-recent-post .c-recent__footer{padding:15px}.c-recent-post .c-recent__image{display:block;width:100%;min-height:180px;background-color:rgba(220,235,245,.2);background-size:cover;background-position:center;background-repeat:no-repeat}.c-recent-post .c-recent__date{color:#a0a0a0;font-size:12px}@media only screen and (max-width: 1200px){.c-recent-post .c-recent__item{max-width:48%;flex-basis:48%}}@media only screen and (max-width: 900px){.c-article{margin:15px 0}}@media only screen and (max-width: 480px){.c-wrap-content{padding:15px}.c-article__header{margin-bottom:5px}.c-article__header .c-article__title{font-size:24px;margin-bottom:5px}.c-recent-post .c-recent__item{max-width:100%;flex-basis:100%;margin:0 0 20px}}.c-blog-tags{width:100%;padding:20px;margin:20px 0 40px;background-color:#fff}.c-blog-tags h1{text-align:center;margin-bottom:0}.c-blog-tags h2{font-size:18px;text-transform:uppercase;margin:30px 0;color:#757575}.c-tag__list{list-style:none;padding:0 0 40px;margin:40px 0 0;border-bottom:1px solid #6b6b6b}.c-tag__list li{display:inline-block;margin-right:15px}.c-tag__list li a{color:#404040;text-transform:uppercase;font-size:12px}.c-tag__list li a:hover{color:hsl(0,0%,-4.9019607843%)}.c-tag__item{margin-bottom:15px}.c-tag__image{width:50px;height:50px;border-radius:50%;margin-right:5px}@media only screen and (max-width: 480px){.c-blog-tags{padding:15px}.c-blog-tags h1{font-size:27px}.c-blog-tags h2{font-size:16px;margin:15px 0}.c-tag__list{padding:0 0 30px;margin:30px 0 0}.c-tag__item{margin-bottom:5px}.c-tag__image{display:none}}.c-header{position:relative;width:100%;margin:20px 0}.c-header__box{position:relative;display:flex;flex-direction:row;justify-content:space-between;align-items:center}.c-header__box .icon--ei-search{position:absolute;top:7px;left:15px;fill:#ccc}.c-search{width:80%}.c-search .c-search__box{display:flex;align-items:center}.c-search .c-search__text{position:relative;width:100%;padding:10px 10px 10px 40px;border:1px solid #f2fafd;border-radius:30px;outline:none;color:#a0a0a0}.c-search .c-search__text::placeholder{color:#ccc}.c-search .c-search__text:hover{box-shadow:0 1px 0px rgba(132,135,138,.1);transition:.35s}.c-search .c-search-results-list{position:absolute;width:100%;margin:10px 0 0;list-style-type:none;background-color:#fff;z-index:1}.c-search .c-search-results-list li{display:flex;flex-wrap:wrap;align-items:center;margin:0;padding:20px 25px 0;background-color:#fff;line-height:1.4;border-left:solid 1px #edeeee;border-right:solid 1px #edeeee}.c-search .c-search-results-list li:first-child{border-top-left-radius:5px;border-top-right-radius:5px;border-top:solid 1px #edeeee}.c-search .c-search-results-list li:last-child{border-bottom-left-radius:5px;border-bottom-right-radius:5px;padding-bottom:25px;border-bottom:solid 1px #edeeee}.c-search .c-search-results-list li a{font-size:16px}.c-nav{flex-grow:1;padding-left:20px}.c-nav .c-nav__list{display:flex;justify-content:flex-end}.c-nav .c-nav__list .c-nav__item{display:flex;align-items:center;float:left;padding:4px 10px;font-size:10px;text-transform:uppercase;white-space:nowrap;border:1px solid #f2fafd;box-shadow:0 1px 0px rgba(132,135,138,.4);will-change:transform;transform:translateY(0px);cursor:pointer}.c-nav .c-nav__list .c-nav__item:hover{color:#222;background-color:#fff}.c-nav .c-nav__list .c-nav__item.is-active{box-shadow:0 0 0 rgba(132,135,138,.5);transform:translateY(1px);color:#cfcfdd}.c-nav .c-nav__list .c-nav__item.is-active:hover{background-color:#fbfbfb}.c-nav .c-nav__list .c-nav__item:first-child{border-radius:10px 0 0 10px}.c-nav .c-nav__list .c-nav__item:last-child{border-radius:0 10px 10px 0}.c-nav .c-nav__list .c-nav__item .icon{width:18px;height:18px;margin-right:3px}@media only screen and (max-width: 900px){.c-header{margin:15px 0}}@media only screen and (max-width: 480px){.c-header .c-header__box{flex-direction:column}.c-header .c-search{width:100%}.c-header .c-search .c-search__text{padding:8px 8px 8px 40px}.c-header .c-nav{margin-top:15px}.c-header .c-nav .c-nav__list{justify-content:center}.c-header .c-nav .c-nav__item{padding:4px 8px}}.c-categories{width:100%}.c-categories__list{width:100%;display:flex;flex-direction:row;flex-wrap:wrap}.c-categories__item{max-width:25%;flex-basis:25%;padding:0 10px 20px}.c-categories__link{height:100%;display:flex;flex-direction:column;align-items:center;padding:20px 10px;border-radius:5px;box-shadow:5px 5px 25px rgba(46,61,73,.15);background-color:#fff;transition:.35s}.c-categories__link:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,.2)}.c-categories__link:hover .c-categories__img .c-categories__more{opacity:1;transition:.35s}.c-categories__link .c-categories__container{width:100%;word-wrap:break-word}.c-categories__link .c-categories__container.c-empty-figure{display:flex;flex-direction:column;justify-content:center;flex-grow:1}.c-categories__img{position:relative;max-width:100%}.c-categories__img figure{position:relative;width:200px;max-width:100%;margin-bottom:20px;overflow:hidden;background-size:cover;background-repeat:no-repeat;background-position:center;border-radius:50%;box-shadow:inset 0 1px 3px rgba(141,165,185,.3)}.c-categories__img figure:after{content:"";display:block;padding-top:100%}.c-categories__img figure:before{content:"";position:absolute;top:0;bottom:0;left:0;right:0;background-color:rgba(0,0,0,.15)}.c-categories__img .c-categories__more{display:inline-block;position:absolute;top:50%;left:50%;transform:translate(-50%, -50%);font-weight:700;color:#fff;text-transform:uppercase;text-shadow:0 1px 0 rgba(104,172,191,.3);opacity:0;transition:.35s}.c-categories__container{text-align:center}.c-categories__container .c-categories__header{font-size:13px;margin-bottom:10px;font-weight:normal;text-transform:uppercase;color:#404040}.c-categories__container .c-categories__count{font-family:"Noto Sans KR",serif;font-size:12px;color:#404040;margin-bottom:0}.c-categories__container .c-categories__count span{display:inline-block;width:20px;height:20px;line-height:20px;vertical-align:baseline;margin-right:5px;border-radius:50%;color:#fff;background-color:#ee6c6c}@media only screen and (max-width: 1200px){.c-categories .c-categories__item{max-width:33.333%;flex-basis:33.333%}}@media only screen and (max-width: 1050px){.c-categories .c-categories__item{max-width:50%;flex-basis:50%}}@media only screen and (max-width: 480px){.c-categories .c-categories__item{max-width:100%;flex-basis:100%;padding:0 0 20px}}.c-form-box{position:absolute;top:0;width:calc(100% - 40px);min-height:100vh;padding:0 20px;background-color:#fff;z-index:1}.c-form-bnt__close{position:absolute;top:0px;left:0;width:30px;height:30px;cursor:pointer;transition:.35s}.c-form-bnt__close:hover{transform:scale(0.8);opacity:.8}.c-form{position:relative;width:750px;max-width:100%;margin:40px auto}.c-form .c-form__title{margin:0 0 40px;min-width:0;border:0;padding:0;font-family:"Noto Sans KR",serif;text-transform:uppercase;text-align:center}.c-form a{color:#404040}.c-form__group{margin-bottom:20px}.c-form__group label{display:block;text-transform:uppercase;font-size:10px}.c-form__group input,.c-form__group textarea{width:100%;padding:10px 15px;color:#404040;border:1px solid #f2fafd;outline:none;transition:.35s}.c-form__group input:focus,.c-form__group textarea:focus{box-shadow:0 4px 25px rgba(132,135,138,.1)}.c-form__group button{padding:20px;text-transform:uppercase;outline:none;border:none}.c-thank-you p{position:relative;padding:20px 40px;width:750px;max-width:100%;text-transform:uppercase;font-size:12px;line-height:18px;font-weight:700;margin:40px auto 0;text-align:center;color:#fff;background:linear-gradient(135deg, #55b5ad 0%, #5ec9c5 100%)}.c-thank-you p .c-form-bnt__close{width:25px;height:25px;background:rgba(0,0,0,0)}.c-thank-you p a{color:#fff}@media only screen and (max-width: 900px){.c-form-box{width:100%;left:0;right:0}}@media only screen and (max-width: 480px){.c-form-bnt__close{width:25px;height:25px}}.c-newsletter{padding:30px 0 60px;margin:0 auto;border-bottom:1px solid #6b6b6b}.c-newsletter__header{text-align:center}.c-newsletter__header .c-newsletter__title{font-size:14px;text-transform:uppercase;text-align:center}.c-newsletter__header .c-newsletter__subtitle{margin-bottom:15px}.c-newsletter-form{width:100%;max-width:750px;margin:0 auto}.c-newsletter-form .c-newsletter-form__group{display:flex}.c-newsletter__email{width:70%;height:40px;padding:10px 15px;border:1px solid #ddd;border-right-color:rgba(0,0,0,0);outline:none;transition:.35s}.c-newsletter__email:focus{box-shadow:0 4px 25px rgba(132,135,138,.1)}.c-newsletter__button{width:30%;height:40px;color:#fff;background-color:#3af;transition:.35s;border:none;outline:none;cursor:pointer}.c-newsletter__button:hover{background-color:hsl(205,100%,45%)}@media only screen and (max-width: 480px){.c-newsletter__button{font-size:13px}}.c-comments{padding:30px 0;border-top:1px solid #6b6b6b}.c-top{position:fixed;width:40px;height:40px;bottom:20px;color:#05b;background-color:#cef;border-radius:50%;cursor:pointer;transition:.35s;right:-100px;z-index:10;opacity:.5}.c-top--active{right:15px}.c-top:hover{color:#757575;opacity:1}.u-text-left{text-align:left}.u-text-right{text-align:right}.u-text-center{text-align:center}.u-text-justify{text-align:justify}.u-block{display:block}.u-inline-block{display:inline-block}.u-inline{display:inline}.u-full-width{display:block;width:100%}.u-vertical-center{display:flex;align-items:center;justify-content:center}.u-responsive-image{max-width:100%;height:auto;vertical-align:middle}.u-show{display:block !important}.u-hide{display:none !important}.u-invisible{visibility:hidden}.u-float-left{float:left}.u-float-right{float:right}.u-no-padding-top{padding-top:0}.u-no-padding-bottom{padding-bottom:0}.u-no-padding-left{padding-left:0}.u-no-padding-right{padding-right:0}.u-no-padding{padding:0}.u-no-margin-top{margin-top:0}.u-no-margin-bottom{margin-bottom:0}.u-no-margin-left{margin-left:0}.u-no-margin-right{margin-right:0}.u-no-margin{margin:0}.u-lists-reset{list-style-type:none;margin:0;padding:0}.u-clearfix::before,.u-clearfix::after{content:"";display:table;clear:both}.u-screen-reader-text{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}
  </style>
  <!-- KaTeX 관련 파일 -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" />
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
          { left: "\\(", right: "\\)", display: false },
          { left: "\\[", right: "\\]", display: true },
        ],
      });
    });
  </script>
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-VNMTFT1R2R"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "G-VNMTFT1R2R");
  </script>
</head>


<body>
  
    <script>
  (function (i, s, o, g, r, a, m) {
  i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
    (i[r].q = i[r].q || []).push(arguments)
}, i[r].l = 1 * new Date(); a = s.createElement(o),
    m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

  ga('create', 'G-VNMTFT1R2R', 'auto');
  ga('send', 'pageview');

</script> <!-- /google analytics -->
  
  <div class="o-wrapper">
    <aside class="c-sidebar">
  <div class="c-sidebar-author">
    <div class="c-author__cover">
      <a href="/">
        <img src="/images/Profile/profile.png" alt="Dong-Jun Shin">
      </a>
    </div>
    <div class="c-author__info">
      <div class="c-author__name">Dong-Jun Shin</div>
      <span class="c-author__job">Web Developer</span>
    </div>
    <div class="c-contact-menu">
      <div style="width: 100%">
        <a href="/about/profile" class="c-contact-btn c-btn c-btn--secondary c-btn--round c-btn--shadow">
          <div style="
            display: flex;
            flex-direction: row;
            align-items: center;">
            <span data-icon='ei-tag' data-size='s'></span>
            <span>About me</span>
          </div>
        </a>
        
        <a target="_blank" href="https://github.com/Dong-Jun-Shin" class="c-btn c-btn--primary c-btn--round c-btn--shadow">
          <div style="
            display: flex;
            flex-direction: row;
            align-items: center;">
            <span data-icon='ei-sc-github' data-size='s'></span>
            <span>Visit Github</span>
          </div>  
        </a>
      </div>
      
    </div>
    <div class="c-contact-menu-bar">
      <div style="width: 100%">
        <a href="/" class="c-contact-btn c-btn c-btn--bar c-btn--round c-btn--shadow">All Posts</a>
      </div>
    </div>
    <p class="c-author__about">개발자로 성장하며 배운 것을 정리한 블로그</p>
  </div>

  <div class="c-sidebar-footer">
    <div class="c-social">
      <div class="c-social__title">Social</div>
      <ul class="c-social__list u-lists-reset">
        
        <li class="c-social__item"><a href="https://www.linkedin.com/in/kr-jun-shin" target="_blank"><div data-icon='ei-sc-linkedin' data-size='s'></div></a></li>
        
        
        
        
        
        
        
        
        
        
          <li class="c-social__item"><a href="https://youtube.com/channel/UCIHM7drY2vvvFhrhXtpbbzw" target="_blank"><div data-icon='ei-sc-youtube' data-size='s'></div></a></li>
        
        
        
      </ul>
    </div>
    <div class="c-copyright">
      <p>2025 &copy; Dong-Jun Shin</p>
      <!-- <a target="_blank" href="https://analytics.google.com/"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fdong-jun-shin.github.io&count_bg=%23FFD540&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=true"/></a> -->
      <a target="_blank" href="https://analytics.google.com/"><img src="https://img.shields.io/badge/Info-Analytics-infomation?style=flat-square&color=yellow"/></a>
      <a target="_blank" href="https://search.google.com/search-console"><img src="https://img.shields.io/badge/Info-Search-informational?style=flat-square"/></a>
    </div>
  </div>
</aside> <!-- /.c-sidebar -->

<main class="c-content">
  <article class="c-article">
  <div class="c-article__content">
    <header class="c-header u-hide u-no-margin-top">
      <div class="c-header__box">
        <div class="c-search u-full-width">
          <div class="c-search__box">
            <label for="js-search-input" class="u-screen-reader-text">Search for Blog</label>
            <input type="text" id="js-search-input" class="c-search__text" autocomplete="off" placeholder="Type to search...">
            <div data-icon='ei-search' data-size='s'></div>
          </div>
          <ul id="js-results-container" class="c-search-results-list"></ul>
        </div>
      </div>
    </header>
    
    <div class="c-article__image o-opacity" style="background-image: url( /images/CS_AI_ML/logo.png )"></div>
    
    <div class="c-wrap-content">
      <header class="c-article__header">
        <h1 class="c-article__title">코칭스터디 Beyond AI Basic 2023 - 2주차 학습</h1>
        <div class="c-article__date">
          <span>2023, May 15</span>
        </div>
      </header>
      
      <div class="toc-container">
        <div class="toc">
          <div class="toc-title">Index</div>
          <ul><li><a href="#피처-엔지니어링">피처 엔지니어링</a></li><li><a href="#피처-엔지니어링-기본-개념">피처 엔지니어링 기본 개념</a><ul><li><a href="#정의">정의</a></li><li><a href="#좋은-피처와-나쁜-피처">좋은 피처와 나쁜 피처</a></li><li><a href="#피처-엔지니어링-후-모델-성능-측정-방법">피처 엔지니어링 후 모델 성능 측정 방법</a></li><li><a href="#누적합을-이용한-피처-엔지니어링">누적합을 이용한 피처 엔지니어링</a></li><li><a href="#시계열-특성을-이용한-피처-엔지니어링">시계열 특성을 이용한 피처 엔지니어링</a></li></ul></li><li><a href="#피처-중요도와-피처-선택">피처 중요도와 피처 선택</a><ul><li><a href="#피처-중요도">피처 중요도</a></li><li><a href="#피처-선택">피처 선택</a></li></ul></li><li><a href="#하이퍼-파라미터-튜닝과-앙상블">하이퍼 파라미터 튜닝과 앙상블</a></li><li><a href="#하이퍼-파라미터-튜닝">하이퍼 파라미터 튜닝</a><ul><li><a href="#하이퍼-파라미터">하이퍼 파라미터</a></li><li><a href="#튜닝">튜닝</a></li><li><a href="#boosting-tree-하이퍼-파라미터">Boosting Tree 하이퍼 파라미터</a></li><li><a href="#optuna">Optuna</a></li></ul></li><li><a href="#앙상블-ensemble">앙상블 (Ensemble)</a><ul><li><a href="#앙상블-러닝">앙상블 러닝</a></li><li><a href="#앙상블-러닝-방법">앙상블 러닝 방법</a></li><li><a href="#트리-부스팅에서-사용하는-앙상블-방식">트리 부스팅에서 사용하는 앙상블 방식</a></li><li><a href="#최근-딥러닝-모델에서-주목하고-있는-문제-해결-접근법">최근 딥러닝 모델에서 주목하고 있는 문제 해결 접근법</a></li></ul></li><li><a href="#reference">Reference</a></li></ul>
        </div>
      </div>
      
      <h1 id="피처-엔지니어링">피처 엔지니어링</h1>

<h1 id="피처-엔지니어링-기본-개념">피처 엔지니어링 기본 개념</h1>

<h2 id="정의">정의</h2>

<ul>
  <li>모델의 성능을 올리기 위해 피처를 생성 및 변환하고 머신러닝 모델에 적합한 형식으로 변환하는 작업</li>
  <li>원본 데이터 + 도메인 지식을 바탕으로 문제 해결에 도움이 되는 피처를 생성, 변환</li>
  <li>피처 엔지니어링은 EDA를 위해 제공된 데이터에서 데이터의 특성과 시계열 특성을 고려하고 집계함수, 누적합 등을 조합해서 도움이 되는 피처를 생성</li>
  <li>머신러닝에서만 하는 작업
    <ul>
      <li>딥러닝은 모델 구조에서 피처를 모델이 직접 추출 가능</li>
    </ul>
  </li>
  <li>데이터의 품질만큼 성능을 결정하는 중요한 작업</li>
  <li>e.g. Pandas Group By Aggregation을 사용해서, 고객 ID 기반으로 집계한 새로운 피처 생성
    <ul>
      <li>집계함수: 개수(Count), 합계(Sum), 평균(Mean), 최대값(MAX), 최소값(MIN), 표준 편차(STD), 비대칭도(SKEW) 등이 있음
        <ul>
          <li>표준 편차 (Standard Deviation)
            <ul>
              <li>데이터가 어느 정도 흩어져 있는 나타냄</li>
              <li>낮을수록 데이터가 밀집되어 있음, 높을수록 데이터가 넓게 분포되어 있음</li>
            </ul>
          </li>
          <li>비대칭도 (Skewed)
            <ul>
              <li>데이터가 어느 방향으로 모여있는지 나타냄</li>
              <li>Positive하면 왼쪽, Negative하면 오른쪽으로 모여있음</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">agg_func = ['count', 'sum', ...]</code>을 정의하고 <code class="language-plaintext highlighter-rouge">agg_dict = { 'column_name': agg_func, ...}</code> 형태로 정의, 그리고 Pandas의 함수 중 groupby로 기준 컬럼을 선택하고 <code class="language-plaintext highlighter-rouge">agg(agg_dict)</code> 형태로 사용</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="좋은-피처와-나쁜-피처">좋은 피처와 나쁜 피처</h2>

<ul>
  <li>피처 엔지니어링을 통해 얻은 피처를 그래프로 나타내었을 때, 레이블의 분포 차이로 구분</li>
  <li>좋은 피처는 레이블의 분포 차이가 명확함</li>
</ul>

<p><br /></p>

<h2 id="피처-엔지니어링-후-모델-성능-측정-방법">피처 엔지니어링 후 모델 성능 측정 방법</h2>

<ul>
  <li><strong>Cross Validation Out of Fold</strong>
    <ul>
      <li>Cross Validation과 Out of Fold을 합친 방법
        <ul>
          <li><strong>Cross Validation</strong>
            <ul>
              <li>데이터를 여러 개의 폴드로 나눠서 검증 성능을 측정하는 방법</li>
            </ul>
          </li>
          <li><strong>Out of Fold</strong>
            <ul>
              <li>학습한 모델로 테스트 데이터를 예측하고, 평균 앙상블하여 최종 예측값으로 사용하는 방법</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>데이터 세트에 존재하는 편향된 부분의 영향력을 줄이기 위해 사용</li>
      <li>캐글에서 일반적으로 많이 사용</li>
    </ul>
  </li>
  <li><strong>Early Stopping</strong>
    <ul>
      <li>검증 성능이 가장 최적이라 판단되는 지점에서 학습을 조기 종료하는 방법</li>
      <li>이전 스텝보다 성능이 떨어지는 경우가 반복되면 조기 종료</li>
      <li>e.g. Boosting 트리 개수, 딥러닝의 Epoch 수를 최적화하는데 사용</li>
    </ul>
  </li>
  <li><strong>LightGBM Early Stopping</strong>
    <ul>
      <li>LightGBM과 Early Stopping을 합친 방법
        <ul>
          <li>LightGBM
            <ul>
              <li>n_estimators 하이퍼파라미터로 트리 개수를 설정해서 모델을 생성</li>
            </ul>
          </li>
          <li>LightGBM만 사용했을 때, 트리 개수에 대한 최적 값을 찾기 어렵기 때문에, 크게 설정하고 Early Stopping을 사용해서 성능이 최적인 부분을 찾음</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="누적합을-이용한-피처-엔지니어링">누적합을 이용한 피처 엔지니어링</h2>

<ul>
  <li><strong>누적합(cumsum)</strong>
    <ul>
      <li>시간 또는 순서에 따라 증가하는 데이터의 총합계를 표시하는 함수</li>
      <li>일반적으로 집계를 하면 시간 순서 정보가 사라지기 때문에 데이터의 특성에 따라 시간 순서 정보도 고려해야 함</li>
      <li>Pandas의 함수 중 groupby로 기준 컬럼을 선택하고 <code class="language-plaintext highlighter-rouge">['column_name'].cumsum()</code> 형태로 사용</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="시계열-특성을-이용한-피처-엔지니어링">시계열 특성을 이용한 피처 엔지니어링</h2>

<ul>
  <li>Pandas의 함수 중 groupby로 기준 컬럼을 선택하고 <code class="language-plaintext highlighter-rouge">['column_name'].diff()</code> 형태로 사용</li>
  <li>e.g. 주문 데이터에서의 피처 엔지니어링
    <ul>
      <li>order_ts-first: 처음 주문 시각</li>
      <li>order_ts-last: 마지막 주문 시각</li>
      <li>order_ts-diff-max: 주문 시각 차이의 최대값</li>
      <li>order_ts-diff-skew: 주문 시각 차이의 비대칭도</li>
      <li>order_ts-diff-std: 주문 시각 차이의 표준편차</li>
      <li>order_ts-diff-sum: 주문 시각 차이의 합</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="피처-중요도와-피처-선택">피처 중요도와 피처 선택</h1>

<h2 id="피처-중요도">피처 중요도</h2>

<ul>
  <li>정답을 예측하는데 얼마나 유용한 지를 점수로 피처에 할당하는 것</li>
  <li>측정 방법
    <ul>
      <li>모델 자체에서 피처 중요도를 계산하는 방법 (<strong>Model-specific</strong>)
        <ul>
          <li>모델마다 피처 계산 방식이 달라, 각 모델에서 제공하는 기능을 사용하여 피처 중요도를 계산
            <ul>
              <li>모델 공통으로 <code class="language-plaintext highlighter-rouge">order_ts-last</code> 피처가 가장 중요하고, 그 외에는 모델별로 다름</li>
            </ul>
          </li>
          <li>보통 피처 선택 시 참고용으로 많이 사용</li>
          <li>모델별 예시
            <ul>
              <li>LightGBM 모델에서 중요도 계산하기
                <ul>
                  <li><code class="language-plaintext highlighter-rouge">feature_importance(default: split)</code></li>
                  <li>importance_type에 따른 계산 방식 사용
                    <ul>
                      <li>split: 트리 모델을 만드는데 피처가 몇 번 사용됐는 지 계산</li>
                      <li>gain: split한 결과값의 평균으로 계산</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>XGBoost 모델에서 중요도 계산하기
                <ul>
                  <li>importance_type에 따른 계산 방식 사용
                    <ul>
                      <li><code class="language-plaintext highlighter-rouge">get_score(default: weight)</code></li>
                      <li>weight: 트리 모델을 만드는데 피처가 몇 번 사용됐는 지 계산 (split과 유사)</li>
                      <li>gain: split한 결과값의 평균으로 계산 (gain과 유사)</li>
                      <li>cover: 전체 coverage의 평균으로 계산</li>
                      <li>total_gain: 전체 gain의 합으로 계산</li>
                      <li>total_cover: 전체 coverage의 합으로 계산</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>CatBoost 모델에서 중요도 계산하기
                <ul>
                  <li>type에 따른 계산 방식 사용
                    <ul>
                      <li><code class="language-plaintext highlighter-rouge">get_feature_importance(default: FeatureImportance)</code></li>
                      <li>FeatureImportance: 피처를 임의로 섞을 때, 모델의 성능이 얼마나 감소하는지에 따라 각 기능의 중요도를 계산</li>
                      <li>ShapValues: 특정 샘플의 예측에 대한 각 피처의 기여도를 계산</li>
                      <li>Interaction: 피처 쌍을 임의로 섞을 때, 모델의 성능이 얼마나 감소하는지에 따라 각 피처 쌍의 중요도를 계산</li>
                      <li>PredictionDiff: 주어진 샘플에 대해 특정 피처가 변경될 때 모델 예측의 차이를 계산</li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>모델을 학습한 후 피처 중요도를 계산하는 방법 (<strong>Model-agnostic</strong>)
        <ul>
          <li>기존 데이터와 섞은 데이터의 에러 차이를 측정해서 피처 중요도를 계산하는 방식 (Permutation Feature Importance)</li>
          <li>중요한 피처일수록, 모델이 예측하지 못해서 에러 값이 커짐</li>
          <li>중요하지 않은 피처일수록 예측하기 때문에 에러 값이 작아짐</li>
          <li>실제 피처를 선택할 때 많이 사용</li>
          <li>계산 예시
            <ul>
              <li>Input: Trained model, feature matrix, target vector(label), error measure(function)</li>
              <li>오리지널 모델로 error measure를 계산</li>
              <li>feature를 하나씩 돌면서 feature matrix의 데이터를 여러번 섞은 후 에러를 구함</li>
              <li>섞은 후 에러와 오리지널에서 얻은 에러를 비교해서 차이를 저장</li>
              <li>에러 차이가 큰 순서로 정렬해서 피처의 중요한 순서대로 확인</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>모델별 피처 중요도 순위 예시</li>
    </ul>
  </li>
</ul>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>LightGBM</th>
      <th>XGBoost</th>
      <th>CatBoost</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>feature 1</td>
      <td>order_ts-last</td>
      <td>order_ts-last</td>
      <td>order_ts-last</td>
    </tr>
    <tr>
      <td>feature 2</td>
      <td>order_ts_diff-max</td>
      <td>quantity_diff-skew</td>
      <td>year_month_mode</td>
    </tr>
    <tr>
      <td>feature 3</td>
      <td>order_ts-first</td>
      <td>cumsum_price_by_prod_id-skew</td>
      <td>order_ts-first</td>
    </tr>
    <tr>
      <td>feature 4</td>
      <td>cumsum_price_by_prod_id-skew</td>
      <td>price_diff-skew</td>
      <td>order_ts_diff-max</td>
    </tr>
    <tr>
      <td>feature 5</td>
      <td>quantity_diff-skew</td>
      <td>order_ts-first</td>
      <td>cumsum_total_by_prod_id-sum</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h2 id="피처-선택">피처 선택</h2>

<ul>
  <li>피처 간에 비슷한 값들을 갖는다면 노이즈 데이터로 학습될 수 있기 때문에 방지하기 위해 피처를 선별</li>
  <li>모델 복잡도를 낮춰, 오버피팅을 방지하고 모델 속도를 향상시킴</li>
  <li>선택 방법
    <ul>
      <li><strong>Filter Method</strong>
        <ul>
          <li>통계적인 측정을 통해 선택하는 방법</li>
          <li>모든 피처 셋 &gt; 서브셋 생성 &gt; 알고리즘 학습 &gt; 성능 측정</li>
          <li>상관관계(Correlation)를 측정하여 유사한 피처를 제거 or 피처의 분산을 계산하여 분산 값이 작은 경우 제거</li>
          <li>계산 속도가 빠르고 피처 간의 상관관계를 알기 좋음</li>
        </ul>
      </li>
      <li><strong>Wrapper Method</strong>
        <ul>
          <li>예측 모델을 사용해서 선택하는 방법</li>
          <li>모든 피처 셋 &gt; <code class="language-plaintext highlighter-rouge">서브셋 생성 &gt; 알고리즘 학습</code> 단계 반복 &gt; 성능 측정</li>
          <li>피처의 서브 셋을 계속 테스트해서 성능에 유용하지 않은 피처를 제거</li>
        </ul>
      </li>
      <li><strong>Embedded Method</strong>
        <ul>
          <li>Filter와 Wrapper의 장점을 합친 방법</li>
          <li>모든 피처 셋 &gt; <code class="language-plaintext highlighter-rouge">서브셋 생성 &gt; 알고리즘 학습 + 성능 측정</code> 단계 반복</li>
          <li>학습 알고리즘 자체에 피처 선택이 들어가 있음</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="하이퍼-파라미터-튜닝과-앙상블">하이퍼 파라미터 튜닝과 앙상블</h1>

<h1 id="하이퍼-파라미터-튜닝">하이퍼 파라미터 튜닝</h1>

<h2 id="하이퍼-파라미터">하이퍼 파라미터</h2>

<ul>
  <li>모델의 성능을 더욱 끌어내기 위해, 학습 이전에 사람이 조작하는 값</li>
  <li>파라미터는 모델이 학습 과정에서 배우는 값 (하이퍼 파라미터와는 다름)</li>
  <li>e.g. learning_rate, n_estimators</li>
</ul>

<p><br /></p>

<h2 id="튜닝">튜닝</h2>

<ul>
  <li>하이퍼 파라미터를 최적화하는 과정</li>
  <li>최적의 값을 찾는 방법
    <ul>
      <li><strong>Manual Search</strong>
        <ul>
          <li>수동으로 실험할 하이퍼 파라미터 셋을 정해, 하나씩 테스트해보는 방식</li>
        </ul>
      </li>
      <li><strong>Grid Search</strong>
        <ul>
          <li>모든 경우를 테스트하는 방식</li>
          <li>e.g. <code class="language-plaintext highlighter-rouge">learning rate 탐색 공간 [0.01, 0.05, 0.1, 0.2]</code>로 설정하고 <code class="language-plaintext highlighter-rouge">n_estimators 탐색 공간 [100, 200]</code>을 설정한다면 나올 수 있는 조합의 수 8가지를 모두 테스트</li>
        </ul>
      </li>
      <li><strong>Random Search</strong>
        <ul>
          <li>랜덤하게 하이퍼 파라미터를 선택해서 테스트하는 방식</li>
          <li>일반적으로 Grid Search보다 성능이 좋음</li>
        </ul>
      </li>
      <li><strong>Bayesian Optimization</strong>
        <ul>
          <li>이전 결과를 기반으로 다음 하이퍼 파라미터의 값을 선택하는 방식</li>
          <li>성능이 잘 나온 영역이 있다면 집중적으로 탐색해서 찾음</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="boosting-tree-하이퍼-파라미터">Boosting Tree 하이퍼 파라미터</h2>

<ul>
  <li>정형 데이터에서 자주 사용하는 Boosting Tree 모델들의 하이퍼 파라미터
    <ul>
      <li>Learning Rate: 모델의 학습률</li>
      <li>Tree depth: 트리 모델의 최대 깊이</li>
      <li>Number of leaves: 한 트리의 최대 리브 수</li>
      <li>Early stop: 검증 성능이 향상하지 않으면 조기 종료</li>
      <li>Row sampling ratio: 데이터 일부를 무작위로 선택하는 비율</li>
      <li>Column sampling ratio: 피처의 하위 집합을 무작위로 선택하는 비율</li>
      <li>L1 / L2 norm penalty: L1/L2 정규화</li>
    </ul>
  </li>
</ul>

<table>
  <thead>
    <tr>
      <th>parameter</th>
      <th>XGBoost</th>
      <th>CatBoost</th>
      <th>LightGBM</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Learning rate</td>
      <td>learning_rate</td>
      <td>learning_rate</td>
      <td>learning_rate</td>
    </tr>
    <tr>
      <td>Tree depth</td>
      <td>max_depth</td>
      <td>depth</td>
      <td>max_depth</td>
    </tr>
    <tr>
      <td>Number of leaves</td>
      <td>max_leaves</td>
      <td>max_leaves</td>
      <td>num_leaves</td>
    </tr>
    <tr>
      <td>Number of tree</td>
      <td>n_estimators</td>
      <td>n_estimators</td>
      <td>n_estimators</td>
    </tr>
    <tr>
      <td>Early stop</td>
      <td>early_stopping_rounds</td>
      <td>od_wait</td>
      <td>early_stopping_rounds</td>
    </tr>
    <tr>
      <td>Row sampling ratio</td>
      <td>subsample</td>
      <td>subsample</td>
      <td>bagging_freq</td>
    </tr>
    <tr>
      <td>Column sampling ratio</td>
      <td>colsample_bytree</td>
      <td>rsm</td>
      <td>colsample_bytree</td>
    </tr>
    <tr>
      <td>L1/L2 norm penalty</td>
      <td>alpha/lambda</td>
      <td>l2_leaf_reg</td>
      <td>lambda_l1/lambda_l2</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h2 id="optuna">Optuna</h2>

<ul>
  <li>하이퍼 파라미터 튜닝을 위한 오픈소스 프레임워크</li>
  <li>파이썬을 활용한 하이퍼 파라미터 최적화, 최신 알고리즘 사용, 쉬운 병렬화</li>
  <li>하이퍼 파라미터 탐색 결과를 저장해서 다음에 이어서 탐색하는 것이 가능
    <ul>
      <li>Storage API를 이용해서 RDB, Redis, SQLite 등 Persistent 저장소 이용 가능</li>
    </ul>
  </li>
  <li>하이퍼 파라미터에 대한 Visualization 기능 제공
    <ul>
      <li>개별 하이퍼 파라미터와 Object Value의 관계에 대한 시각화
        <ul>
          <li>Param Importances로 중요도에 대한 결과를 시각화 가능</li>
          <li>Optimization History로 히스토리에 대한 결과를 시각화 가능</li>
          <li>Slice Visualization으로 각 하이퍼 파라미터 별로 목적함수가 어떻게 변화하는지 시각화 가능</li>
        </ul>
      </li>
      <li>여러개 하이퍼 파라미터와 Object Value의 관계에 대한 시각화
        <ul>
          <li>Contour로 결과를 한번에 볼 수 있도록 시각화 가능</li>
          <li>Parallel Coordiinate로 결과를 흐름에 따라 볼 수 있도록 시각화 가능</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>사용 방법
    <ul>
      <li>먼저 최적화를 할 objective 함수를 정의합니다.</li>
      <li>objective 함수 내에 trial 객체를 사용해서 하이퍼 파라미터 범위를 정의합니다.</li>
      <li>study 객체를 생성하고 optimize 메소드에 objective 함수를 파라미터로 넣어 호출합니다.
        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kn">import</span> <span class="n">optuna</span>

  <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_uniform</span><span class="p">(</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
      <span class="nf">return </span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>

  <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="p">.</span><span class="nf">create_study</span><span class="p">()</span>
  <span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span> <span class="c1"># 100번동안 수행하면서 최적을 찾음
</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">study</span><span class="p">.</span><span class="n">best_params</span><span class="p">)</span> <span class="c1"># E.g {'x': 2.002108042}
</span></code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="앙상블-ensemble">앙상블 (Ensemble)</h1>

<h2 id="앙상블-러닝">앙상블 러닝</h2>

<ul>
  <li>하이퍼 파라미터 튜닝 이후 더 높은 성능을 내기 위해 알고리즘 여러개를 조합해서 사용하는 방법</li>
  <li>여러개의 약 분류기(Weak Classifier)를 결합해서 강 분류기(String Classifier)를 만듦</li>
  <li>쉽게 말해, 여러 모델의 투표를 통해 다수결로 결정된 것이 더 나은 결과를 도출한다는 것 (집단 지성)</li>
  <li><a href="https://subinium.github.io/introduction-to-ensemble-1/#:~:text=%EC%95%99%EC%83%81%EB%B8%94(Ensemble)%20%ED%95%99%EC%8A%B5%EC%9D%80%20%EC%97%AC%EB%9F%AC,%EB%A5%BC%20%EA%B0%80%EC%A7%80%EA%B3%A0%20%EC%9D%B4%ED%95%B4%ED%95%98%EB%A9%B4%20%EC%A2%8B%EC%8A%B5%EB%8B%88%EB%8B%A4.">앙상블에 대한 참고</a></li>
  <li>Cross validation을 통해 <a href="https://newsight.tistory.com/259">결정계수(R^2)</a>를 얻을 수 있음
<br /></li>
</ul>

<h2 id="앙상블-러닝-방법">앙상블 러닝 방법</h2>

<ul>
  <li>병렬 학습
    <ul>
      <li><strong>배깅(Bagging) / 페이스팅(Pasting)</strong>
        <ul>
          <li>데이터를 쪼개어 같은 알고리즘 모델 여러개에 학습시키는 방식</li>
          <li>배깅과 페이스팅의 차이는 배깅의 경우 훈련 셋의 중복을 허용하면서 샘플링한다는 것</li>
        </ul>
      </li>
      <li><strong>Hard / Soft 보팅(Voting)</strong>
        <ul>
          <li>Hard Voting은 모델의 예측값을 대상으로 다수결해서 결과를 도출</li>
          <li>Soft Voting은 예측값의 확률 분포를 사용해서 평균을 내고 제일 높은 확률의 값을 결과로 도출</li>
          <li>일반적으로 Soft Voting을 많이 사용</li>
        </ul>
      </li>
      <li>Bagging과 Voting의 차이
        <ul>
          <li>Bagging은 여러개 데이터셋에 하나의 알고리즘을 적용</li>
          <li>Voting은 하나의 데이터셋에 여러개 알고리즘을 적용</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>직렬 학습
    <ul>
      <li><strong>부스팅 (Boosting)</strong>
        <ul>
          <li>여러개의 분류기(Classifier)가 이전 분류기에서 틀린 데이터에 대해 가중치를 부여하면서 순차적으로 학습하는 방식</li>
          <li>보통 예측 성능이 뛰어나 앙상블 러닝에서 많이 사용됨</li>
        </ul>
      </li>
      <li><strong>스택킹</strong>
        <ul>
          <li>여러 알고리즘 모델로 각각 예측 결과를 도출한 뒤 결합해서 최종 예측 결과를 만드는 방식</li>
          <li>여러 알고리즘 모델을 사용한다는 점에서 <code class="language-plaintext highlighter-rouge">배깅(Bagging) / 페이스팅(Pasting)</code>과 차이점이 있음</li>
          <li>서비스가 될 수 없을 정도의 고비용이 필요하기 때문에 덜 쓰이는 방법</li>
          <li>장점: 학습 데이터에 한해서 우수한 성능이 나옴</li>
          <li>단점: 매우 많은 조합을 시도하기 때문에 오래 걸리는 문제가 있음</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="트리-부스팅에서-사용하는-앙상블-방식">트리 부스팅에서 사용하는 앙상블 방식</h2>

<ul>
  <li><strong>Decisioon Tree: Impurity</strong>
    <ul>
      <li>노드에 섞여있는 정도를 낮춰 복잡성을 낮춰야 함</li>
      <li><code class="language-plaintext highlighter-rouge">Graphviz</code>를 통해 트리와 정보를 시각화 가능</li>
      <li>불순도(Impurity) 측정 방법
        <ul>
          <li>분산계수가 낮을수록 불순도가 낮음을 의미</li>
          <li>불확실성(Entropy)
            <ul>
              <li>높을수록 예측이 어려움을 의미</li>
            </ul>
          </li>
          <li>분산계수(Gini Index)
            <ul>
              <li>높을수록 데이터가 분산되어 있음을 의미</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Gradient Boosting</strong>
    <ul>
      <li>Label과 예측값의 차이에 가중치를 두어 선택하는 기법</li>
      <li>기울기가 큰 데이터는 놔두고, 작은 데이터만 랜덤하게 드랍하기 때문에 데이터 분포가 왜곡되고 정확도가 낮아짐. (이를 방지하기 위해 GOSS 기법을 사용)</li>
      <li>동작 과정
        <ul>
          <li>데이터셋 준비, 미분가능한 Loss function 정의</li>
          <li>첫번째 값으로 초기 예측값을 설정</li>
          <li>n번 반복하며 Loss function을 계산하고 잔차(Negative Gradient, label과 예측값의 차이)를 확인</li>
          <li>Weak learner(잔차를 타겟으로 하는 트리 모델)를 생성하고 최적화를 진행</li>
          <li>Loss를 최소로 하는 트리 결과값을 출력</li>
          <li>트리 결과값에 가중치를 주어 첫번째 설정한 예측값을 업데이트</li>
          <li>첫번째 예측값 설정부터 업데이트까지 5단계를 반복한 뒤 최종 예측값을 출력</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>XGBoost</strong>
    <ul>
      <li>XGBoost는 Gradient Boosting의 약점을 보완하기 위해 Regularization term을 추가한 알고리즘</li>
      <li>root노드와 가까운 노드를 우선적으로 순회하여 수평 성장시킴</li>
      <li>장점
        <ul>
          <li>다양한 Loss function을 지원해서 task에 따른 유연한 튜닝이 가능하다는 장점</li>
        </ul>
      </li>
      <li>단점
        <ul>
          <li>학습 시간이 느림</li>
          <li>하이퍼 파라미터가 많아 튜닝이 어려움</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>LightGBM</strong>
    <ul>
      <li>XGBoost의 단점을 보완하기 위해 트리의 깊이를 줄이고 균형있게 만듦</li>
      <li>Loss의 변화가 가장 큰 노드에서 분할하여 성장하는 수직 성장 방식</li>
      <li>사용 기법들
        <ul>
          <li>GOSS (Gradient-based One-Side Sampling)
            <ul>
              <li>큰 데이터는 100% 취하고, 작은 데이터는 작은 비율만 취하는 방법</li>
              <li>기울기가 큰 데이터가 개체 정보 획득에 있어 더욱 큰 역할을 한다는 점을 이용</li>
            </ul>
          </li>
          <li>EFB (EXclusive Feature Bundling)
            <ul>
              <li>컬럼이 많을 때 변수 개수를 줄이기 위해 컬럼들이 가진 일부 값의 차이를 무시하면서 합치는 방법 (차원 축소 기법)</li>
              <li>어떤 피처를 골라야 하는지가 가장 큰 문제</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>장점
        <ul>
          <li>하이퍼 파라미터를 단순화하여 튜닝의 복잡성을 개선</li>
          <li>데이터가 많으면 성능과 효율성에 이점이 있음</li>
        </ul>
      </li>
      <li>단점
        <ul>
          <li>데이터가 적을 경우, 오버피팅이 발생하기 쉬움</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>CatBoost (Category Boosting)</strong>
    <ul>
      <li>알고리즘으로 순서형 원칙(Ordered Principle)을 사용
        <ul>
          <li>데이터를 섞어 랜덤하게 뽑아서(Random Permutation) 결과값을 계산하고 모델을 만듦</li>
          <li>데이터의 잔차는 만들어진 모델로 예측한 것을 사용</li>
        </ul>
      </li>
      <li>범주형 데이터를 많이 가진 데이터셋에서 성능이 높음</li>
      <li>범주형 feature 처리 방법
        <ul>
          <li>Ordered Target Encoding
            <ul>
              <li>범주형 변수를 수치형 데이터로 인코딩하는 방식</li>
              <li>오버피팅 방지와 수치의 다양성을 만듦</li>
            </ul>
          </li>
          <li>Categorical Feature Combinations
            <ul>
              <li>정보 이득(Infomation gain)이 동일한 경우, 하나의 피처로 묶는 방식</li>
              <li>데이터 전처리에 있어 피처 선택의 부담을 줄일 수 있음</li>
            </ul>
          </li>
          <li>One-Hot Encoding
            <ul>
              <li>컬럼에 변수를 두고 Boolean과 같이 1과 0으로 나누는 방법 (데이터 전처리에 필요한 인코딩 방법)</li>
              <li>CatBoost에서는 범주형 변수에 한해서 자동 처리</li>
            </ul>
          </li>
          <li>Optimized Parameter Tuning
            <ul>
              <li>CatBoost에서 기본 하이퍼 파라미터의 최적화가 XGBoost, LightGBM에 비해 잘 되어 있어 크게 신경쓰지 않아도 됨</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="최근-딥러닝-모델에서-주목하고-있는-문제-해결-접근법">최근 딥러닝 모델에서 주목하고 있는 문제 해결 접근법</h2>

<ul>
  <li><strong>TabNet</strong>
    <ul>
      <li>앙상블을 아니지만 정형 데이터(Tabular Data)를 위한 딥러닝 모델</li>
      <li>각 의사 결정 단계에서 <code class="language-plaintext highlighter-rouge">순차적 어텐션(Sequential Attention)</code> 기반으로 추론할 특징(feature)을 선택해서 학습 능력이 가장 두드러진 특징(feature)을 사용</li>
      <li>장점
        <ul>
          <li>다른 신경망이나 변형된 의사결정트리 보다 성능이 우수하고 대규모 정형 데이터도 처리 가능</li>
          <li>전처리 과정이 필요하지 않으며 피처 선택과 모델 학습의 과정이 한 번에 이루어져 효과적인 학습과 어떤 피처가 중요한 지 설명이 가능</li>
          <li><code class="language-plaintext highlighter-rouge">Supervised fine-tuning</code> 전에 feature 값을 예측하는 <code class="language-plaintext highlighter-rouge">비감독 사전 훈련(Unsupervised Pretrain)</code> 단계를 적용해서 높은 성능 향상을 보여줌
            <ul>
              <li><code class="language-plaintext highlighter-rouge">Unsupervised Pretrain</code>
                <ul>
                  <li>데이터 일부에 마스킹해서 학습시키는 방식</li>
                </ul>
              </li>
              <li><code class="language-plaintext highlighter-rouge">Supervised fine-tuning</code>
                <ul>
                  <li><code class="language-plaintext highlighter-rouge">TabNet encoder</code>가 Feature Engineering을 수행</li>
                  <li><code class="language-plaintext highlighter-rouge">Decision masking</code>을 통해 Attention 기반의 Feature 선택을 수행</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>인코더가 fine-tuning을 하면서 Task에 맞게 성능을 향상시킴</li>
        </ul>
      </li>
      <li>단점
        <ul>
          <li>딥러닝 모델임에도 불구하고 조절해야 할 하이퍼 파라미터가 많아서 최적화에 시간이 필요함</li>
        </ul>
      </li>
      <li>모델 구조
        <ul>
          <li><strong>TabNet Encoder</strong>
            <ul>
              <li>각 Decision step에 대해 <code class="language-plaintext highlighter-rouge">Feature transformer, Attentive transformer, Feature masking</code>으로 구성</li>
            </ul>
          </li>
          <li><strong>TabNet Decoder</strong>
            <ul>
              <li>각 Decision step에 대해 <code class="language-plaintext highlighter-rouge">Feature transformer</code>로 구성</li>
            </ul>
          </li>
          <li><strong>Feature transformer</strong>
            <ul>
              <li>공유하는 Decision step 영역, 의존하는 Decision step 영역으로 나뉨</li>
            </ul>
          </li>
          <li><strong>Attentive transformer</strong>
            <ul>
              <li>Prior scales를 단일 layer에 맵핑해서 사용
                <ul>
                  <li>Prior scales: 현재 Decision step 이전에 Feature가 사용된 빈도를 집계한 정보</li>
                </ul>
              </li>
              <li>계수의 정규화는 Sparsemax를 사용
                <ul>
                  <li>Sparsemax: 각 Decision step에서 가장 두드러진 Feature를 선택하기 위한 값</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>+정형 데이터로 학습된 딥러닝 모델에 쓰이는 앙상블 기법</strong>
    <ul>
      <li>Deep Ensemble: 성능을 향상시키기 위해 동일한 데이터 세트에서 훈련된 여러 심층 신경망의 조합</li>
      <li>Snapshot Ensembling: 서로 다른 초기화 및 학습 속도로 단일 심층 신경망을 교육한 다음 서로 다른 스냅샷 지점에서 모델의 가중치를 결합하여 성능을 향상</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="reference">Reference</h1>

<ul>
  <li><a href="https://m.post.naver.com/viewer/postView.naver?volumeNo=35664080&amp;memberNo=34635212">제대로 된 인공지능 스터디를 찾고 있다면? AI 심화 스터디</a></li>
  <li><a href="https://www.boostcourse.org/study-ai111-2023">[코칭스터디 10기] Beyond AI Basic 2023 스터디 전용강좌</a></li>
</ul>

      <div class="c-article__footer u-clearfix">
        <div class="c-article__tag">
          
        </div>
        <div class="c-article__share">
          <a href="https://twitter.com/intent/tweet?text=%EC%BD%94%EC%B9%AD%EC%8A%A4%ED%84%B0%EB%94%94%20Beyond%20AI%20Basic%202023%20-%202%EC%A3%BC%EC%B0%A8%20%ED%95%99%EC%8A%B5&url=https://dong-jun-shin.github.io/2023/05/15/Beyond_AI_Basic_2023_Week_2/" title="Share
          on Twitter" rel="nofollow" target="_blank"><div data-icon='ei-sc-twitter' data-size='s'></div></a>
          <a href="https://facebook.com/sharer.php?u=https://dong-jun-shin.github.io/2023/05/15/Beyond_AI_Basic_2023_Week_2/" title="Share on Facebook" rel="nofollow" target="_blank"><div data-icon='ei-sc-facebook' data-size='s'></div></a>
          <a href="https://plus.google.com/share?url=https://dong-jun-shin.github.io/2023/05/15/Beyond_AI_Basic_2023_Week_2/" title="Share on Google+" rel="nofollow" target="_blank"><div data-icon='ei-sc-google-plus' data-size='s'></div></a>
        </div>
      </div>
      <div class="c-newsletter">
  <div class="c-newsletter__header">
    <h4 class="c-newsletter__title">Newsletter</h4>
    <div class="c-newsletter__subtitle">Subscribe to this blog and receive notifications of new posts by email.</div>
  </div>
  <form class="c-newsletter-form validate" action="#" method="POST" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" target="_blank" novalidate>
    <div class="c-newsletter-form__group">
      <label class="u-screen-reader-text" for="mce-EMAIL">Email address</label>
      <input class="c-newsletter__email required email" id="mce-EMAIL" type="email" name="EMAIL" placeholder="Your email address" autocomplete="on">
      <input class="c-newsletter__button" id="mc-embedded-subscribe" type="submit" name="subscribe" value="Subscribe">
    </div>
  </form>
</div> <!-- /.c-newsletter -->
      <div class="c-recent-post">
        <h4 class="c-recent__title">You might also enjoy</h4>
        <div class="c-recent__box">
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2025/01/10/permutation_and_combination_implements/" style="background-image: url( /images/CS_Algorithm/2025/01/permutation_and_combination_implements/thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2025/01/10/permutation_and_combination_implements/">순열과 조합 - 2, 경우의 수 뿐만 아니라 경우를 직접 구해보자</a></h4>
              <div class="c-recent__date">
                <time datetime="2025-01-10T17:45:03+09:00">January 10, 2025</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2025/01/10/permutation_and_combination_theory/" style="background-image: url( /images/CS_Algorithm/2025/01/permutation_and_combination_theory/thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2025/01/10/permutation_and_combination_theory/">순열과 조합 - 1, 어떤 원리로 경우의 수를 계산할 수 있는걸까?</a></h4>
              <div class="c-recent__date">
                <time datetime="2025-01-10T17:45:02+09:00">January 10, 2025</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2024/08/21/2_years_of_experience_from_2022/" style="background-image: url( /images/Life/2024/08/2_years_of_experience_from_2022/thumbnail_retrospective-journey.jpg)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2024/08/21/2_years_of_experience_from_2022/">퇴사 회고(라 쓰고, 2022년 ~ 2024년 정리)</a></h4>
              <div class="c-recent__date">
                <time datetime="2024-08-21T23:47:38+09:00">August 21, 2024</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2024/05/21/Aws_Summit_Seoul_2024/" style="background-image: url( /images/IT_Tech/2024/05/Aws_Summit_Seoul_2024/thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2024/05/21/Aws_Summit_Seoul_2024/">AWS Summit Seoul 2024 방문기</a></h4>
              <div class="c-recent__date">
                <time datetime="2024-05-21T21:55:48+09:00">May 21, 2024</time>
              </div>
            </div>
          </div>
        
        
        </div>
      </div> <!-- /.c-recent-post -->
      
        <div class="c-comments">
  <div id="disqus_thread" class="article-comments"></div>
  <script>
    (function () {
      var d = document, s = d.createElement('script');
      s.src = '//dong-jun-shin-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
</div> <!-- /.c-comments -->
      
    </div> <!-- /.c-wrap-content -->
  </div> <!-- /.c-article__content -->
</article> <!-- /.c-article-page -->

</main> <!-- /.c-content -->
  </div> <!-- /.o-wrapper -->
  <div class="c-top" data-icon='ei-chevron-up' data-size='s' title="Scroll To Top"></div> <!-- /.c-top -->
  <script src="/js/jquery-3.3.1.min.js"></script>
<script src="/js/evil-icons.min.js"></script>
<script src="/js/jquery.fitvids.js"></script>
<script src="/js/simple-jekyll-search.min.js"></script>
<script src="/js/main.js"></script>
<!-- /javascripts -->
</body>
</html>