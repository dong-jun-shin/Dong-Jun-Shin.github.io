<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>코칭스터디 Beyond AI Basic 2023 - 1주차 학습</title>
  <meta
    name="description"
    content="개발환경 준비하기가상환경 구성가상환경 만들기  Python + miniconda3(Anaconda) 설치  가상환경 생성    # conda create -n {ENV_NAME} python={PYTHON_VERSION}conda create -n virtual_workspace ..."
  />
  <!-- Twitter Cards -->
<meta name="twitter:title" content="코칭스터디 Beyond AI Basic 2023 - 1주차 학습">
<meta name="twitter:description" content="개발환경 준비하기

가상환경 구성

가상환경 만들기


  Python + miniconda3(Anaconda) 설치
  가상환경 생성
    # conda create -n {ENV_NAME} python={PYTHON_VERSION}

conda create -n virtual_workspace python=3.8
    
  
  가상환경 활성화
    # conda activate {ENV_NAME}

(base) &gt; conda activate virtual_workspace
(virtual_workspace) &gt; ...
    
  
  가상환경 비활성화
    (virtual_workspace) &gt; conda deactivate
(base) &gt; ...
    
  




의존 라이브러리 설치


  목록
    
      catboost
      matplotlib
      numpy
      pandas
      scikit-learn
      seaborn
      xgboost
      lightgbm
      tqdm
      notebook
      optuna
    
  


# pip 업그레이드
(virtual_workspace) &gt; pip install --upgrade pip

# requirments.txt 참고하여 라이브러리 설치
(virtual_workspace) &gt; pip install -r requirements-window.txt




주피터 노트북 실행

(virtual_workspace) &gt; cd notebook
(virtual_workspace) &gt; jupyter notebook




정형 데이터 소개

정형 데이터와 비정형 데이터의 차이


  정형 데이터
    
      행(인스턴스), 열(피처)로 구성된 엑셀 파일, RDB와 같은 형식
      가장 기본적인 데이터로, 분야를 막론하고 많은 데이터가 존재
    
  
  비정형 데이터
    
      이미지, 비디오, 음성, 자연어 등 틀이 없는 데이터
      머신러닝과 함께 활용도가 높아짐
    
  
  정형데이터 분석
    
      상상력, 통찰력 기반의 데이터 분석이 중요
      예시로 전쟁 당시 전투기 생존력 향상을 위한 연구에서 전투기에 총알이 어디에 많이 박혔는지 낸 통계를 보고 총알을 맞지 않은 부위에 대한 보강을 해법으로 제시
    
  




데이터 문제 및 이해


  평가지표와 각종 시각화를 이용해서 데이터 이해




평가지표 이해

분류, 회귀 평가지표 소개


  지도학습의 큰 범주에 속함
  분류
    
      예측해야 할 대상의 개수가 정해져 있는 문제
      이미지에서 개, 고양이 등 객체 분류, 사기 탐지에서 정상 케이스 분류
    
  
  회귀
    
      예측해야 할 대상이 연속적인 숫자인 문제
      일기 예보의 기온 예측, 집값 예측 등 수치를 예측
    
  
  평가지표
    
      회귀, 분류 머신러닝이 문제를 해결하는 성능을 평가하는 지표
    
  




Confusion Matrix


  2진 분류의 예측 오류에 대해 나타낸 행렬(TN, FP, FN, TP)
  예측과 실제에 대해 ‘Negative, Positive’로 분류




Accuracy, Precision, Recall


  Accuracy(정확도)
    
      전체 예측 중 진짜 맞힌 정도
      (TP + TN) / (TP + TN + FP + FN)
      불균형한 데이터에 사용하기는 부적절
    
  
  Precision(정밀도)
    
      틀리던 맞던, 참이라 예측한 것 중 진짜 참인 정도
      TP / (TP + FP)
      Negative를 Positive라 판단하면 안되는 경우 사용
      예시: 스팸 메일 분류
    
  
  Recall(재현률)
    
      참은 참, 거짓은 거짓이라 예측한 것 중 진짜 참인 정도
      TP / (TP + FN)
      Positive를 Negative라 판단하면 안되는 경우 사용
      예시: 악성 종양 분류 등
    
  




ROC, AUC


  ROC(Receiver Operating Characteristic, 수신자 조작 특성)
    
      임계값의 변화를 그래프로 표현한 것
      TPR(True Posive Ratio)이 Y축 (예측을 맞힌 비율)
      FPR(False Positive Ratio)이 X축 (잘못 예측한 비율)
    
  
  AUC(Area Under the Curve, )
    
      그래프 전체 면적에서 곡선 아래 공간이 차지하는 비율
      0 ~ 1의 값을 가짐, 1에 가까울수록 우수한 예측 성능
      그래프에서 대각선 직선의 아래에 해당하는 최소 0.5 이상은 나와야 유의미
    
  




쇼핑 데이터를 활용한 예측 실습

머신러닝 없는 베이스라인 모델과 과거 데이터를 이용해서 미래 데이터 예측하기


  베이스라인 모델이란?
    
      모델의 성능을 비교하는 참조 지점으로 사용되는 단순한 모델 또는 휴리스틱
      머신러닝 모델이 의미있기 위해 넘어야 하는 최소한의 성능을 제공하는 모델
    
  
  예측 방법
    
      첫번째 베이스라인 모델은 머신러닝 모델을 사용하지 않고, 이전 월 고객 구매액을 계산한 후에 이를 예측값으로 사용해서 베이스라인 모델 구현
      이전 월 고객 총 구매액이 300을 넘을 경우 확률을 1, 300 이하일 경우 고객 총 구매액을 300으로 나눈 값을 예측 확률로 사용
      2011년 10월을 training 데이터, 2011년 11월을 validation 데이터로 해서 베이스라인 모델의 validation 성능을 측정하고 2011년 12월 데이터를 예측
    
  
  구현
    
      Label 생성 함수, 평가지표 출력 함수 정의
      Training 데이터 로드
      데이터의 타입과 null을 체크 (Pandas info, isna, sum 함수를 이용)
      Pandas shape 속성으로 전체 개수를 가져와 null 데이터 비율 체크
      Pandas describe 함수로 기본 통계량 확인 (include=’all’ 설정하면 수치형, 범주형 데이터도 확인 가능)
      베이스라인 모델 함수 정의
      2011년 10월 training 데이터로 만든 베이스라인 모델로 2011년 11월 데이터를 예측
      예측 데이터 분포를 차트와 그래프로 시각화해서 확인
      실 데이터와 비교해서 평가지표 확인
    
  


탐색적 자료 분석

EDA(Exploratory Data Analysis, 탐색적 데이터 분석)

EDA의 의미


  분석자의 끝없는 상상력으로 가설을 세우고, 통찰력으로 데이터를 분석하는 과정
  데이터의 특징과 내재하는 구조적 관계를 알기 위함
  개별 변수의 분포, 변수간의 분포와 관계를 시각화, 통계적 방법을 통해 다양한 각도에서 관찰하고 이해
  예시: 히스토그램, 카운트 플롯, Correlation 히트맵, Word Cloud




EDA 과정


  데이터마다 상이한 도메인
    
      분야마다 도메인이 다르고, 해결할 문제가 다르기 때문에 일반화가 어렵고 정해진 답이 없음
      그래서 처음 데이터를 접하고 EDA를 진행할 때는 개별 변수의 분포, 변수간의 분포와 관계의 분석과 가설 수립에서 시작됨
    
  
  데이터에 의문을 가지고, 관찰하는 과정의 반복을 통해 데이터와 문제를 이해하는 과정
    
      예측할 타겟 변수를 선정
      개별 변수의 분포, 연속형, 범주형 변수 그래프를 분석해서 특징 도출
      (성별, 지위, 지역, 결혼 여부 등)변수 간의 관계 분석해서 가설을 수립
    
  




범주형 데이터


  카테고리 등을 나타낼 때 유용한 데이터
  보통 문자열로 되어 있어 모델의 입력 데이터로 직접 사용할 수 없음
  인코딩을 통해 수치형 변수로 변환이 필요
  인코딩 방법으로 One Hot Encoding, Label Encoding, Frequency, Target Encoding, Embedding 등이 있음




정형 데이터 전처리

데이터 전처리


  EDA 분석을 위한 데이터, 모델에 입력할 데이터를 얻기 위해 데이터의 연속형 데이터, 범주형 데이터, 결측치, 이상치를 처리하는 과정
  선형, 트리, 딥러닝 등 모델과 목적에 따라 얻고자 하는 데이터가 달라짐
  신뢰도 있고 정확한 데이터를 얻는 제일 중요한 과정임




전처리에 필요한 다양한 인코딩 방법과 장단점


  연속형 데이터 전처리
    
      Scaling
        
          데이터의 단위 혹은 분포를 변경하는 방법
          선형기반의 모델을 사용할 때 필요
          연속형 변수를 처리에 활용
        
      
      Scaling의 종류
        
          Scale 변경
            
              Min Max Scaling
                
                  Minimum 값을 빼고, Max값과 Min 값의 차이로 나눔
                
              
              Standard Scaling
                
                  평균 값을 빼고, 표준 편차로 나눔
                
              
              Robust Scaling
                
                  중위 값을 빼고 IQR(상위 75%에 해당하는 값 - 상위 25%에 해당하는 값)으로 나눔
                  보통 이상치의 영향을 덜 받음
                
              
            
          
          Scale, Distribution(분포) 변경
            
              분포 변환의 장점
                
                  Feature와 Target의 관계를 더욱 직접적인 관계를 갖도록 함
                  특정 Feature가 선형 모델에 성능을 올릴 수 있음
                
              
              Log Transformation
                
                  변수의 분포가 치우쳐 있는 경우, 정규 분포 같은 분포로 변환
                
              
              Quantile Transformation
                
                  값을 균일하게 변화시키거나 정규 분포로 변환
                  Log Transformation과 차이점은 어떤 분포던 변환 가능
                
              
            
          
          Binning
            
              연속형 변수를 범주형 변수로 변형하는 방법
              Overfitting이 발생하는 경우를 방지
                
                  Overfitting: 구간을 나눌 수 있는 데이터에서 중간중간 유의미한 정보가 있는 경우
                
              
            
          
        
      
    
  
  범주형 데이터 전처리
    
      One Hot Encoding
        
          컬럼에 변수를 두고 Boolean과 같이 1과 0으로 나누는 방법
          장점: 변수의 의미가 명확
          단점: 변수의 종류가 많아지면 분석이 복잡해짐 (차원의 저주)
            
              차원의 저주(Curse of dimensionality): 차원이 높아질수록 발생하는 다양한 현상들
            
          
        
      
      Label Encoding
        
          컬럼의 수는 1개로 유지하고 값에 의미를 부여
            
              e.g. 1: 개, 2: 고양이, 3: 둘 다
            
          
          단점: 숫자의 순서에 의미가 부여되어 특징으로 여겨질 수 있음
        
      
      Frequency Encoding
        
          변수의 값이 등장한 빈도를 측정해서 값을 사용
          빈도수를 변수의 Label로 사용
          장점: 값에 의미가 있는 범주형 데이터로 만들 수 있음
          단점: 다른 종류의 변수가 같은 Target 변수값을 가질 수 있음
        
      
      Target Encoding
        
          각각의 변수 종류가 가지는 Target 변수의 평균을 사용
          단점: 다른 변수가 같은 Target 변수 평균을 갖게 될 수 있음
        
      
      Embedding
        
          Text 데이터의 관계값을 이용해서 더 낮은 차원으로 변환하는 방법
        
      
    
  




데이터 상 결측치와 이상치 처리 방법


  결측치 처리 방법
    
      특정 패턴을 갖고 있는 경우
        
          패턴에 맞춰, 결측치를 채우는 방법
        
      
      특정 패턴이 없는 경우
        
          패턴이 없는 경우, 잘못된 방법을 사용 시 상관관계가 무너질 수 있으니 결측치 비율에 따라 주의해서 처리해야 함
          단변량 분석(Univariate)
            
              제거
                
                  데이터가 충분히 많아야 가능
                  테스트 데이터에 결측치가 있을 경우 사용하기 어려움
                  결측치 비율이 너무 크다면 포함된 변수 자체를 제거 가능
                
              
              평균값 삽입
              중위값 삽입
              상수값 삽입
            
          
          다변량 분석(Multivariate)
            
              Linear, KNN 등 머신러닝 모델을 활용해 주변 변수들을 기반으로 결측치의 값을 예측하는 방법
              존재하는 데이터 중 결측치를 가진 샘플과 가장 유사한 샘플의 값을 이용하는 방법
              인구, 인원, 강수량, 지명, 온도, 습도, 풍속, 풍향 등의 결측치를 채우는 예시가 있음
            
          
        
      
    
  
  이상치 처리 방법
    
      이상치는 모델의 성능에 큰 영향을 끼치기 때문에 조심스럽게 처리해야 함
      이상치 처리 관점
        
          정성적인 측면
            
              이상치 발생 이유와 이상치의 의미를 고려해야 함
                
                  과정을 통해 처리 방법을 선택
                
              
            
          
          성능적인 측면
            
              Train Test Distribution
                
                  트레이닝 데이터와 테스트 데이터에 같은 이상치가 있는데, 트레이닝 데이터에서 이상치를 제거한 경우, 모델의 예측력이 떨어질 수 있다는 것을 고려해야 함
                  트레이닝 데이터에만 있는 이상치를 제거해야 함
                
              
            
          
        
      
      이상치 탐색 방법
        
          Z-Score
          IQR
        
      
    
  




머신러닝 기본 개념 소개

Underfitting과 Overfitting


  본 적이 없는 데이터를 잘 표현하지 못하는 상황임
  Underfitting
    
      데이터를 잘 설명하지 못하는 상황
    
  
  Overfitting
    
      데이터를 과도하게 설명하는 상황
      제어하고 방지하기 위한 방법
        
          Regularization(정형화)
            
              Early Stopping
                
                  Traning 데이터를 다시 한번 Train과 Validation Set으로 나누어 학습과 관찰을 하는 방법
                  Validation Error가 지속적으로 증가하는 지점에 학습을 중단
                
              
              Parameter Norm Penalty
                
                  데이터에 패널티를 부여하는 파라미터 L1, L2를 설정하는 방법
                  L1(Lasso, least absolute shrinkage and selection operator): 가중치, 기울기
                    
                      일부 가중치가 0에 수렴하고, 이로 인해 feature의 수가 감소하는 효과
                    
                  
                  L2(Ridge): 모델의 복잡도 조정
                    
                      가중치를 0의 방향으로 잡아당기는 효과
                    
                  
                  정형 데이터도 적용 가능
                
              
              Data Augmentation
                
                  데이터 변형을 통해 데이터 개수를 늘려서 다양한 데이터로 학습할 수 있게 하는 방법
                  이미지 데이터를 다룰 때 회전, 반전, 확대, 축소 등의 방법으로 많이 사용
                  정형 데이터도 적용 가능
                
              
              SMOTE
                
                  불균형한 데이터에서 소수 데이터를 활용해서 사이사이에 데이터를 생성하는 방법
                  정형데이터에서 Data Augmentation와 같은 효과를 내는 방법으로 많이 사용
                
              
              Dropout
                
                  일부의 Feature와 Node만 사용하여 학습하는 방법 (가지치기)
                
              
              Column sample by tree
                
                  Tree 모델을 만들 때, 렌덤하게 샘플링해서 일부 데이터만 사용
                  정형데이터에서 Dropout과 같은 효과를 내는 방법으로도 사용
                
              
            
          
        
      
    
  




검증 전략


  데이터셋의 구성
    
      종류
        
          Train
            
              모델을 훈련하는 데이터셋
              Validation, Test를 제외한 나머지 데이터셋으로 품질에 따라 Noise 데이터를 포함할 지 여부를 고려해야 함
            
          
          Validation
            
              모델의 성능을 파악하기 위한 데이터셋
              Test Set을 제외한 전체 데이터를 대표할 수 있도록 구성
            
          
          Test
            
              모델을 테스트하기 위한 데이터셋
              최대한 전체 데이터를 대표할 수 있도록 구성
              테스트 데이터를 바꾸는 것은 프로젝트 진행에 매우 위험하기 때문에 정해놓고 Validation Set을 바꾸면서 다루어야 함.
            
          
        
      
      데이터셋을 선정하는 방법
        
          Hold-out Validation
            
              하나의 Train Set, Validation Set으로 고정해서 사용하는 방법
              불균형한 데이터가 특정 Set에 몰릴 수 있기 때문에 각 클래스 비율을 고려해야 함
              Random sampling
                
                  무작위로 선택해서 나누는 방법
                  대표성이 유지되고 간편
                  데이터 사이즈가 작다면 전체 데이터를 대표하기에 어려울 수 있기 때문에 주의
                
              
              Stratified Split
                
                  클래스 비율에 따라 Train, Validation Set도 같은 비율로 나누는 방법
                  각 클래스의 분포를 유지할 수 있음
                
              
            
          
          Cross Validation
            
              여러개의 Train Set, Validation Set으로 구성해서 사용
              K-Fold
                
                  각 상황별로 모델을 학습시킨 후, 최종적으로 각자 학습된 모델들을 모두 사용해서 예측하는 방식
                
              
              Stratified K-Fold
                
                  데이터셋의 비율을 유지시키면서 상황별 모델 학습시키는 방식
                  데이터셋의 비율을 유지시켜 주는게 성능에 좋음
                  보통 8:2 비율을 유지
                
              
              Group K-Fold
                
                  데이터셋을 그룹으로 만들어 상황별 모델 학습시키는 방식
                  동일 Group이 같은 Fold에 들어가지 않도록 구성
                  Group은 항상 Fold 개수보다 커야 함
                
              
              Time series split
                
                  이전 데이터를 이용해서 다음 데이터를 예측하는 방식
                  학습 시, 미래 데이터로 과거 데이터를 예측하지 않도록 하기 위함
                  앞쪽 Fold일수록 Train 데이터가 적을 수 있다는 것을 유의해야 함
                
              
            
          
        
      
    
  




재현율


  학습된 모델로 예측할 때마다 샘플링이 다를 수 있고, 성능도 다를 수 있음
  이런 랜덤을 기반으로 실행되는 결과를 고정시켜주기 위해 Seed를 고정해서 사용




머신 러닝 Workflow


  Raw Data에서 데이터 추출
  데이터 전처리를 진행
  Feature Engineering, Scaling, Selection을 수행
  머신 러닝 알고리즘으로 모델링 및 학습을 진행
  Test Set으로 성능 평가를 진행
  필요에 따라 2 ~ 3을 반복




트리 모델 소개

Tree Model


  Feature 값을 특정 기준으로 분류해 트리 모양으로 구성되며, 목적에 맞는 의사결정을 만드는 모델
  가장 기본이 되는 모델은 의사결정트리(Decision Tree)가 있음
  그 외에 Random Forest, AdaBoost, GBM, XGBoost/LightGBM/CatBoost 등이 있음 (트리의 발전 순)


Bagging &amp; Boosting


  Bagging
    
      데이터셋을 랜덤하게 샘플해서 트리를 생성하고 생성한 트리의 의사 결정들을 취합하여 하나의 의사결정으로 구성하는 방식
      대표적으로 Random Forest가 있음
      구성 알고리즘
        
          Bootstrap: Data를 여러 번 Sampling
          Aggregation: 종합(Ensemble)
          Bagging = Bootstrap + Aggregation
        
      
    
  
  Boosting
    
      초기에 랜덤하게 선택된 데이터셋을 이용해서 틀을 만들고 , 맞지 않는 데이터들에 Weight를 부여하여 다음 트리 생성에 반영하는 방식
      대표적으로 LightGBM, XGBoost, CatBoost가 있음
    
  
  Bagging과 Boosting 차이
    
      가장 큰 차이는 Train 데이터를 어떻게 다루냐의 차이
      Tree 생성 방법
        
          Bagging은 병렬 모델로 트리를 생성 (각 모델은 연관 없음)
          Boosting은 순차적 모델로 트리를 생성 (이전 Tree 오류를 기반으로 생성)
        
      
      특징
        
          Bagging은 다양한 Tree 생성
          Boosting은 정밀한 Tree 생성
        
      
    
  


LightGBM, XGBoost, CatBoost


  Tree가 성장하는 방식에 따라 구분됨 (제한하지 않는다면 크게 다르지 않을 수 있음)
  균형적 구조
    
      XGBoost
      CatBoost
    
  
  비 균형적 구조
    
      LightGBM
    
  
  Category 변수 다루기
    
      LightGBM, CatBoost는 pandas의 category 데이터 타입 가능
        
          category 데이터에 대해 우수한 모델 성능
        
      
      XGBoost는 numeric 데이터 타입만 가능 (전처리 필요)
    
  


Hyper-parameter 살펴보기


  Learning Rate (학습률)
    
      모델이 제대로 학습하기 위한 파라미터로, 작을수록 수렴 속도가 느려지고 클수록 발산하게 됨
      Gradient Descent의 Learning Rate와 같은 개념
    
  
  Tree Depth &amp; Leaves
    
      트리의 깊이(Depth)와 잎사귀(Leaves)를 설정
      값을 너무 크게 주거나 제한하지 않으면 Overfitting의 위험이 있음
    
  
  Column &amp; Row Sampling Ratio
    
      컬럼(Feature) 또는 로우(Instance) 중 랜덤으로 일부만 사용해서 Tree를 만듦
      Overfitting이 발생할 확률이 비교적 낮음
      다양한 조합으로 여러가지 트리를 만들 수 있음
    
  



  
    
      Parameter
      XGBoost
      CatBoost
      LightGBM
    
  
  
    
      Learning rate
      learning_rate
      learning_rate
      learning_rate
    
    
      Tree depth
      max_depth
      depth
      max_depth
    
    
      Number of leaves
      max_leaves
      max_leaves
      num_leaves
    
    
      Number of tree
      n_estimators
      n_estimators
      n_estimators
    
    
      Early stop
      early_stopping_rounds
      od_wait
      early_stopping_rounds
    
    
      Row sampling ratio
      subsample
      subsample
      bagging_freq
    
    
      Column sampling ratio
      colsample_bytree
      rsm
      colsample_bytree
    
    
      L1/L2 norm penalty
      alpha/lambda
      l2_leaf_reg
      lambda_l1/lambda_l2
    
  


Reference


  제대로 된 인공지능 스터디를 찾고 있다면? AI 심화 스터디
  [코칭스터디 10기] Beyond AI Basic 2023 스터디 전용강좌

">



<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://dong-jun-shin.github.io/images/CS_AI_ML/2023/05/Beyond_AI_Basic_2023_Week_1/0.png">


<!-- Open Graph -->
<meta property="og:locale" content="">
<meta property="og:type" content="article">
<meta property="og:title" content="코칭스터디 Beyond AI Basic 2023 - 1주차 학습">

<meta property="og:image" content="https://dong-jun-shin.github.io/images/CS_AI_ML/2023/05/Beyond_AI_Basic_2023_Week_1/0.png">


<meta property="og:description" content="개발환경 준비하기

가상환경 구성

가상환경 만들기


  Python + miniconda3(Anaconda) 설치
  가상환경 생성
    # conda create -n {ENV_NAME} python={PYTHON_VERSION}

conda create -n virtual_workspace python=3.8
    
  
  가상환경 활성화
    # conda activate {ENV_NAME}

(base) &gt; conda activate virtual_workspace
(virtual_workspace) &gt; ...
    
  
  가상환경 비활성화
    (virtual_workspace) &gt; conda deactivate
(base) &gt; ...
    
  




의존 라이브러리 설치


  목록
    
      catboost
      matplotlib
      numpy
      pandas
      scikit-learn
      seaborn
      xgboost
      lightgbm
      tqdm
      notebook
      optuna
    
  


# pip 업그레이드
(virtual_workspace) &gt; pip install --upgrade pip

# requirments.txt 참고하여 라이브러리 설치
(virtual_workspace) &gt; pip install -r requirements-window.txt




주피터 노트북 실행

(virtual_workspace) &gt; cd notebook
(virtual_workspace) &gt; jupyter notebook




정형 데이터 소개

정형 데이터와 비정형 데이터의 차이


  정형 데이터
    
      행(인스턴스), 열(피처)로 구성된 엑셀 파일, RDB와 같은 형식
      가장 기본적인 데이터로, 분야를 막론하고 많은 데이터가 존재
    
  
  비정형 데이터
    
      이미지, 비디오, 음성, 자연어 등 틀이 없는 데이터
      머신러닝과 함께 활용도가 높아짐
    
  
  정형데이터 분석
    
      상상력, 통찰력 기반의 데이터 분석이 중요
      예시로 전쟁 당시 전투기 생존력 향상을 위한 연구에서 전투기에 총알이 어디에 많이 박혔는지 낸 통계를 보고 총알을 맞지 않은 부위에 대한 보강을 해법으로 제시
    
  




데이터 문제 및 이해


  평가지표와 각종 시각화를 이용해서 데이터 이해




평가지표 이해

분류, 회귀 평가지표 소개


  지도학습의 큰 범주에 속함
  분류
    
      예측해야 할 대상의 개수가 정해져 있는 문제
      이미지에서 개, 고양이 등 객체 분류, 사기 탐지에서 정상 케이스 분류
    
  
  회귀
    
      예측해야 할 대상이 연속적인 숫자인 문제
      일기 예보의 기온 예측, 집값 예측 등 수치를 예측
    
  
  평가지표
    
      회귀, 분류 머신러닝이 문제를 해결하는 성능을 평가하는 지표
    
  




Confusion Matrix


  2진 분류의 예측 오류에 대해 나타낸 행렬(TN, FP, FN, TP)
  예측과 실제에 대해 ‘Negative, Positive’로 분류




Accuracy, Precision, Recall


  Accuracy(정확도)
    
      전체 예측 중 진짜 맞힌 정도
      (TP + TN) / (TP + TN + FP + FN)
      불균형한 데이터에 사용하기는 부적절
    
  
  Precision(정밀도)
    
      틀리던 맞던, 참이라 예측한 것 중 진짜 참인 정도
      TP / (TP + FP)
      Negative를 Positive라 판단하면 안되는 경우 사용
      예시: 스팸 메일 분류
    
  
  Recall(재현률)
    
      참은 참, 거짓은 거짓이라 예측한 것 중 진짜 참인 정도
      TP / (TP + FN)
      Positive를 Negative라 판단하면 안되는 경우 사용
      예시: 악성 종양 분류 등
    
  




ROC, AUC


  ROC(Receiver Operating Characteristic, 수신자 조작 특성)
    
      임계값의 변화를 그래프로 표현한 것
      TPR(True Posive Ratio)이 Y축 (예측을 맞힌 비율)
      FPR(False Positive Ratio)이 X축 (잘못 예측한 비율)
    
  
  AUC(Area Under the Curve, )
    
      그래프 전체 면적에서 곡선 아래 공간이 차지하는 비율
      0 ~ 1의 값을 가짐, 1에 가까울수록 우수한 예측 성능
      그래프에서 대각선 직선의 아래에 해당하는 최소 0.5 이상은 나와야 유의미
    
  




쇼핑 데이터를 활용한 예측 실습

머신러닝 없는 베이스라인 모델과 과거 데이터를 이용해서 미래 데이터 예측하기


  베이스라인 모델이란?
    
      모델의 성능을 비교하는 참조 지점으로 사용되는 단순한 모델 또는 휴리스틱
      머신러닝 모델이 의미있기 위해 넘어야 하는 최소한의 성능을 제공하는 모델
    
  
  예측 방법
    
      첫번째 베이스라인 모델은 머신러닝 모델을 사용하지 않고, 이전 월 고객 구매액을 계산한 후에 이를 예측값으로 사용해서 베이스라인 모델 구현
      이전 월 고객 총 구매액이 300을 넘을 경우 확률을 1, 300 이하일 경우 고객 총 구매액을 300으로 나눈 값을 예측 확률로 사용
      2011년 10월을 training 데이터, 2011년 11월을 validation 데이터로 해서 베이스라인 모델의 validation 성능을 측정하고 2011년 12월 데이터를 예측
    
  
  구현
    
      Label 생성 함수, 평가지표 출력 함수 정의
      Training 데이터 로드
      데이터의 타입과 null을 체크 (Pandas info, isna, sum 함수를 이용)
      Pandas shape 속성으로 전체 개수를 가져와 null 데이터 비율 체크
      Pandas describe 함수로 기본 통계량 확인 (include=’all’ 설정하면 수치형, 범주형 데이터도 확인 가능)
      베이스라인 모델 함수 정의
      2011년 10월 training 데이터로 만든 베이스라인 모델로 2011년 11월 데이터를 예측
      예측 데이터 분포를 차트와 그래프로 시각화해서 확인
      실 데이터와 비교해서 평가지표 확인
    
  


탐색적 자료 분석

EDA(Exploratory Data Analysis, 탐색적 데이터 분석)

EDA의 의미


  분석자의 끝없는 상상력으로 가설을 세우고, 통찰력으로 데이터를 분석하는 과정
  데이터의 특징과 내재하는 구조적 관계를 알기 위함
  개별 변수의 분포, 변수간의 분포와 관계를 시각화, 통계적 방법을 통해 다양한 각도에서 관찰하고 이해
  예시: 히스토그램, 카운트 플롯, Correlation 히트맵, Word Cloud




EDA 과정


  데이터마다 상이한 도메인
    
      분야마다 도메인이 다르고, 해결할 문제가 다르기 때문에 일반화가 어렵고 정해진 답이 없음
      그래서 처음 데이터를 접하고 EDA를 진행할 때는 개별 변수의 분포, 변수간의 분포와 관계의 분석과 가설 수립에서 시작됨
    
  
  데이터에 의문을 가지고, 관찰하는 과정의 반복을 통해 데이터와 문제를 이해하는 과정
    
      예측할 타겟 변수를 선정
      개별 변수의 분포, 연속형, 범주형 변수 그래프를 분석해서 특징 도출
      (성별, 지위, 지역, 결혼 여부 등)변수 간의 관계 분석해서 가설을 수립
    
  




범주형 데이터


  카테고리 등을 나타낼 때 유용한 데이터
  보통 문자열로 되어 있어 모델의 입력 데이터로 직접 사용할 수 없음
  인코딩을 통해 수치형 변수로 변환이 필요
  인코딩 방법으로 One Hot Encoding, Label Encoding, Frequency, Target Encoding, Embedding 등이 있음




정형 데이터 전처리

데이터 전처리


  EDA 분석을 위한 데이터, 모델에 입력할 데이터를 얻기 위해 데이터의 연속형 데이터, 범주형 데이터, 결측치, 이상치를 처리하는 과정
  선형, 트리, 딥러닝 등 모델과 목적에 따라 얻고자 하는 데이터가 달라짐
  신뢰도 있고 정확한 데이터를 얻는 제일 중요한 과정임




전처리에 필요한 다양한 인코딩 방법과 장단점


  연속형 데이터 전처리
    
      Scaling
        
          데이터의 단위 혹은 분포를 변경하는 방법
          선형기반의 모델을 사용할 때 필요
          연속형 변수를 처리에 활용
        
      
      Scaling의 종류
        
          Scale 변경
            
              Min Max Scaling
                
                  Minimum 값을 빼고, Max값과 Min 값의 차이로 나눔
                
              
              Standard Scaling
                
                  평균 값을 빼고, 표준 편차로 나눔
                
              
              Robust Scaling
                
                  중위 값을 빼고 IQR(상위 75%에 해당하는 값 - 상위 25%에 해당하는 값)으로 나눔
                  보통 이상치의 영향을 덜 받음
                
              
            
          
          Scale, Distribution(분포) 변경
            
              분포 변환의 장점
                
                  Feature와 Target의 관계를 더욱 직접적인 관계를 갖도록 함
                  특정 Feature가 선형 모델에 성능을 올릴 수 있음
                
              
              Log Transformation
                
                  변수의 분포가 치우쳐 있는 경우, 정규 분포 같은 분포로 변환
                
              
              Quantile Transformation
                
                  값을 균일하게 변화시키거나 정규 분포로 변환
                  Log Transformation과 차이점은 어떤 분포던 변환 가능
                
              
            
          
          Binning
            
              연속형 변수를 범주형 변수로 변형하는 방법
              Overfitting이 발생하는 경우를 방지
                
                  Overfitting: 구간을 나눌 수 있는 데이터에서 중간중간 유의미한 정보가 있는 경우
                
              
            
          
        
      
    
  
  범주형 데이터 전처리
    
      One Hot Encoding
        
          컬럼에 변수를 두고 Boolean과 같이 1과 0으로 나누는 방법
          장점: 변수의 의미가 명확
          단점: 변수의 종류가 많아지면 분석이 복잡해짐 (차원의 저주)
            
              차원의 저주(Curse of dimensionality): 차원이 높아질수록 발생하는 다양한 현상들
            
          
        
      
      Label Encoding
        
          컬럼의 수는 1개로 유지하고 값에 의미를 부여
            
              e.g. 1: 개, 2: 고양이, 3: 둘 다
            
          
          단점: 숫자의 순서에 의미가 부여되어 특징으로 여겨질 수 있음
        
      
      Frequency Encoding
        
          변수의 값이 등장한 빈도를 측정해서 값을 사용
          빈도수를 변수의 Label로 사용
          장점: 값에 의미가 있는 범주형 데이터로 만들 수 있음
          단점: 다른 종류의 변수가 같은 Target 변수값을 가질 수 있음
        
      
      Target Encoding
        
          각각의 변수 종류가 가지는 Target 변수의 평균을 사용
          단점: 다른 변수가 같은 Target 변수 평균을 갖게 될 수 있음
        
      
      Embedding
        
          Text 데이터의 관계값을 이용해서 더 낮은 차원으로 변환하는 방법
        
      
    
  




데이터 상 결측치와 이상치 처리 방법


  결측치 처리 방법
    
      특정 패턴을 갖고 있는 경우
        
          패턴에 맞춰, 결측치를 채우는 방법
        
      
      특정 패턴이 없는 경우
        
          패턴이 없는 경우, 잘못된 방법을 사용 시 상관관계가 무너질 수 있으니 결측치 비율에 따라 주의해서 처리해야 함
          단변량 분석(Univariate)
            
              제거
                
                  데이터가 충분히 많아야 가능
                  테스트 데이터에 결측치가 있을 경우 사용하기 어려움
                  결측치 비율이 너무 크다면 포함된 변수 자체를 제거 가능
                
              
              평균값 삽입
              중위값 삽입
              상수값 삽입
            
          
          다변량 분석(Multivariate)
            
              Linear, KNN 등 머신러닝 모델을 활용해 주변 변수들을 기반으로 결측치의 값을 예측하는 방법
              존재하는 데이터 중 결측치를 가진 샘플과 가장 유사한 샘플의 값을 이용하는 방법
              인구, 인원, 강수량, 지명, 온도, 습도, 풍속, 풍향 등의 결측치를 채우는 예시가 있음
            
          
        
      
    
  
  이상치 처리 방법
    
      이상치는 모델의 성능에 큰 영향을 끼치기 때문에 조심스럽게 처리해야 함
      이상치 처리 관점
        
          정성적인 측면
            
              이상치 발생 이유와 이상치의 의미를 고려해야 함
                
                  과정을 통해 처리 방법을 선택
                
              
            
          
          성능적인 측면
            
              Train Test Distribution
                
                  트레이닝 데이터와 테스트 데이터에 같은 이상치가 있는데, 트레이닝 데이터에서 이상치를 제거한 경우, 모델의 예측력이 떨어질 수 있다는 것을 고려해야 함
                  트레이닝 데이터에만 있는 이상치를 제거해야 함
                
              
            
          
        
      
      이상치 탐색 방법
        
          Z-Score
          IQR
        
      
    
  




머신러닝 기본 개념 소개

Underfitting과 Overfitting


  본 적이 없는 데이터를 잘 표현하지 못하는 상황임
  Underfitting
    
      데이터를 잘 설명하지 못하는 상황
    
  
  Overfitting
    
      데이터를 과도하게 설명하는 상황
      제어하고 방지하기 위한 방법
        
          Regularization(정형화)
            
              Early Stopping
                
                  Traning 데이터를 다시 한번 Train과 Validation Set으로 나누어 학습과 관찰을 하는 방법
                  Validation Error가 지속적으로 증가하는 지점에 학습을 중단
                
              
              Parameter Norm Penalty
                
                  데이터에 패널티를 부여하는 파라미터 L1, L2를 설정하는 방법
                  L1(Lasso, least absolute shrinkage and selection operator): 가중치, 기울기
                    
                      일부 가중치가 0에 수렴하고, 이로 인해 feature의 수가 감소하는 효과
                    
                  
                  L2(Ridge): 모델의 복잡도 조정
                    
                      가중치를 0의 방향으로 잡아당기는 효과
                    
                  
                  정형 데이터도 적용 가능
                
              
              Data Augmentation
                
                  데이터 변형을 통해 데이터 개수를 늘려서 다양한 데이터로 학습할 수 있게 하는 방법
                  이미지 데이터를 다룰 때 회전, 반전, 확대, 축소 등의 방법으로 많이 사용
                  정형 데이터도 적용 가능
                
              
              SMOTE
                
                  불균형한 데이터에서 소수 데이터를 활용해서 사이사이에 데이터를 생성하는 방법
                  정형데이터에서 Data Augmentation와 같은 효과를 내는 방법으로 많이 사용
                
              
              Dropout
                
                  일부의 Feature와 Node만 사용하여 학습하는 방법 (가지치기)
                
              
              Column sample by tree
                
                  Tree 모델을 만들 때, 렌덤하게 샘플링해서 일부 데이터만 사용
                  정형데이터에서 Dropout과 같은 효과를 내는 방법으로도 사용
                
              
            
          
        
      
    
  




검증 전략


  데이터셋의 구성
    
      종류
        
          Train
            
              모델을 훈련하는 데이터셋
              Validation, Test를 제외한 나머지 데이터셋으로 품질에 따라 Noise 데이터를 포함할 지 여부를 고려해야 함
            
          
          Validation
            
              모델의 성능을 파악하기 위한 데이터셋
              Test Set을 제외한 전체 데이터를 대표할 수 있도록 구성
            
          
          Test
            
              모델을 테스트하기 위한 데이터셋
              최대한 전체 데이터를 대표할 수 있도록 구성
              테스트 데이터를 바꾸는 것은 프로젝트 진행에 매우 위험하기 때문에 정해놓고 Validation Set을 바꾸면서 다루어야 함.
            
          
        
      
      데이터셋을 선정하는 방법
        
          Hold-out Validation
            
              하나의 Train Set, Validation Set으로 고정해서 사용하는 방법
              불균형한 데이터가 특정 Set에 몰릴 수 있기 때문에 각 클래스 비율을 고려해야 함
              Random sampling
                
                  무작위로 선택해서 나누는 방법
                  대표성이 유지되고 간편
                  데이터 사이즈가 작다면 전체 데이터를 대표하기에 어려울 수 있기 때문에 주의
                
              
              Stratified Split
                
                  클래스 비율에 따라 Train, Validation Set도 같은 비율로 나누는 방법
                  각 클래스의 분포를 유지할 수 있음
                
              
            
          
          Cross Validation
            
              여러개의 Train Set, Validation Set으로 구성해서 사용
              K-Fold
                
                  각 상황별로 모델을 학습시킨 후, 최종적으로 각자 학습된 모델들을 모두 사용해서 예측하는 방식
                
              
              Stratified K-Fold
                
                  데이터셋의 비율을 유지시키면서 상황별 모델 학습시키는 방식
                  데이터셋의 비율을 유지시켜 주는게 성능에 좋음
                  보통 8:2 비율을 유지
                
              
              Group K-Fold
                
                  데이터셋을 그룹으로 만들어 상황별 모델 학습시키는 방식
                  동일 Group이 같은 Fold에 들어가지 않도록 구성
                  Group은 항상 Fold 개수보다 커야 함
                
              
              Time series split
                
                  이전 데이터를 이용해서 다음 데이터를 예측하는 방식
                  학습 시, 미래 데이터로 과거 데이터를 예측하지 않도록 하기 위함
                  앞쪽 Fold일수록 Train 데이터가 적을 수 있다는 것을 유의해야 함
                
              
            
          
        
      
    
  




재현율


  학습된 모델로 예측할 때마다 샘플링이 다를 수 있고, 성능도 다를 수 있음
  이런 랜덤을 기반으로 실행되는 결과를 고정시켜주기 위해 Seed를 고정해서 사용




머신 러닝 Workflow


  Raw Data에서 데이터 추출
  데이터 전처리를 진행
  Feature Engineering, Scaling, Selection을 수행
  머신 러닝 알고리즘으로 모델링 및 학습을 진행
  Test Set으로 성능 평가를 진행
  필요에 따라 2 ~ 3을 반복




트리 모델 소개

Tree Model


  Feature 값을 특정 기준으로 분류해 트리 모양으로 구성되며, 목적에 맞는 의사결정을 만드는 모델
  가장 기본이 되는 모델은 의사결정트리(Decision Tree)가 있음
  그 외에 Random Forest, AdaBoost, GBM, XGBoost/LightGBM/CatBoost 등이 있음 (트리의 발전 순)


Bagging &amp; Boosting


  Bagging
    
      데이터셋을 랜덤하게 샘플해서 트리를 생성하고 생성한 트리의 의사 결정들을 취합하여 하나의 의사결정으로 구성하는 방식
      대표적으로 Random Forest가 있음
      구성 알고리즘
        
          Bootstrap: Data를 여러 번 Sampling
          Aggregation: 종합(Ensemble)
          Bagging = Bootstrap + Aggregation
        
      
    
  
  Boosting
    
      초기에 랜덤하게 선택된 데이터셋을 이용해서 틀을 만들고 , 맞지 않는 데이터들에 Weight를 부여하여 다음 트리 생성에 반영하는 방식
      대표적으로 LightGBM, XGBoost, CatBoost가 있음
    
  
  Bagging과 Boosting 차이
    
      가장 큰 차이는 Train 데이터를 어떻게 다루냐의 차이
      Tree 생성 방법
        
          Bagging은 병렬 모델로 트리를 생성 (각 모델은 연관 없음)
          Boosting은 순차적 모델로 트리를 생성 (이전 Tree 오류를 기반으로 생성)
        
      
      특징
        
          Bagging은 다양한 Tree 생성
          Boosting은 정밀한 Tree 생성
        
      
    
  


LightGBM, XGBoost, CatBoost


  Tree가 성장하는 방식에 따라 구분됨 (제한하지 않는다면 크게 다르지 않을 수 있음)
  균형적 구조
    
      XGBoost
      CatBoost
    
  
  비 균형적 구조
    
      LightGBM
    
  
  Category 변수 다루기
    
      LightGBM, CatBoost는 pandas의 category 데이터 타입 가능
        
          category 데이터에 대해 우수한 모델 성능
        
      
      XGBoost는 numeric 데이터 타입만 가능 (전처리 필요)
    
  


Hyper-parameter 살펴보기


  Learning Rate (학습률)
    
      모델이 제대로 학습하기 위한 파라미터로, 작을수록 수렴 속도가 느려지고 클수록 발산하게 됨
      Gradient Descent의 Learning Rate와 같은 개념
    
  
  Tree Depth &amp; Leaves
    
      트리의 깊이(Depth)와 잎사귀(Leaves)를 설정
      값을 너무 크게 주거나 제한하지 않으면 Overfitting의 위험이 있음
    
  
  Column &amp; Row Sampling Ratio
    
      컬럼(Feature) 또는 로우(Instance) 중 랜덤으로 일부만 사용해서 Tree를 만듦
      Overfitting이 발생할 확률이 비교적 낮음
      다양한 조합으로 여러가지 트리를 만들 수 있음
    
  



  
    
      Parameter
      XGBoost
      CatBoost
      LightGBM
    
  
  
    
      Learning rate
      learning_rate
      learning_rate
      learning_rate
    
    
      Tree depth
      max_depth
      depth
      max_depth
    
    
      Number of leaves
      max_leaves
      max_leaves
      num_leaves
    
    
      Number of tree
      n_estimators
      n_estimators
      n_estimators
    
    
      Early stop
      early_stopping_rounds
      od_wait
      early_stopping_rounds
    
    
      Row sampling ratio
      subsample
      subsample
      bagging_freq
    
    
      Column sampling ratio
      colsample_bytree
      rsm
      colsample_bytree
    
    
      L1/L2 norm penalty
      alpha/lambda
      l2_leaf_reg
      lambda_l1/lambda_l2
    
  


Reference


  제대로 된 인공지능 스터디를 찾고 있다면? AI 심화 스터디
  [코칭스터디 10기] Beyond AI Basic 2023 스터디 전용강좌

">
<meta property="og:url" content="https://dong-jun-shin.github.io/2023/05/08/Beyond_AI_Basic_2023_Week_1/">
<meta property="og:site_name" content="Jun's Dev_Blog">
  <link rel="canonical" href="https://dong-jun-shin.github.io/2023/05/08/Beyond_AI_Basic_2023_Week_1/" />
  <link
    rel="alternate"
    type="application/rss+xml"
    title="Jun's Dev_Blog"
    href="https://dong-jun-shin.github.io/feed.xml"
  />
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css?family=Volkhov:400,700" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@200;300;400;500;700;900&display=swap" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css2?family=Courier+Prime:wght@700&display=swap" rel="stylesheet" />
  <!-- Common -->
  <style>
    
    /*! normalize.css v7.0.0 | MIT License | github.com/necolas/normalize.css */html,body{scroll-behavior:smooth}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{font-weight:normal;letter-spacing:0;margin:0}article,aside,footer,header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}figcaption,figure,main{display:block}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:rgba(0,0,0,0);-webkit-text-decoration-skip:objects}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}dfn{font-style:italic}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}img{border-style:none}svg:not(:root){overflow:hidden}button,input,optgroup,select,textarea{font-family:"Noto Sans KR",sans-serif;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,html [type=button],[type=reset],[type=submit]{-webkit-appearance:button}button::-moz-focus-inner,[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{display:inline-block;vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details,menu{display:block}summary{display:list-item}canvas{display:inline-block}template{display:none}[hidden]{display:none}body,h1,h2,h3,h4,h5,h6,p,blockquote,pre,dl,dd,ol,ul,fieldset,legend,figure,hr{margin:0;padding:0}li>ul,li>ol{margin-bottom:0}table{border:.14em solid #000;border-collapse:collapse;border-spacing:0;word-break:initial;width:100%}table tr:nth-child(even){background-color:#f2fafd}thead{background-color:#a0d0ee}table th{text-align:center;padding:6px 13px;border:.1em solid #757575}table td{padding:6px 13px;border:.1em solid #757575}table tr{padding:6px 13px;border:.1em solid #757575}@-webkit-keyframes spin{100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes spin{100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.icon{position:relative;display:inline-block;width:25px;height:25px;overflow:hidden;fill:currentColor}.icon__cnt{width:100%;height:100%;background:inherit;fill:inherit;pointer-events:none;transform:translateX(0);-ms-transform:translate(0.5px, -0.3px)}.icon--m{width:50px;height:50px}.icon--l{width:100px;height:100px}.icon--xl{width:150px;height:150px}.icon--xxl{width:200px;height:200px}.icon__spinner{position:absolute;top:0;left:0;width:100%;height:100%}.icon--ei-spinner .icon__spinner,.icon--ei-spinner-2 .icon__spinner{-webkit-animation:spin 1s steps(12) infinite;animation:spin 1s steps(12) infinite}.icon--ei-spinner-3 .icon__spinner{-webkit-animation:spin 1.5s linear infinite;animation:spin 1.5s linear infinite}.icon--ei-sc-facebook{fill:#3b5998}.icon--ei-sc-github{fill:#333}.icon--ei-sc-google-plus{fill:#dd4b39}.icon--ei-sc-instagram{fill:#3f729b}.icon--ei-sc-linkedin{fill:#0976b4}.icon--ei-sc-odnoklassniki{fill:#ed812b}.icon--ei-sc-skype{fill:#00aff0}.icon--ei-sc-soundcloud{fill:#f80}.icon--ei-sc-tumblr{fill:#35465c}.icon--ei-sc-twitter{fill:#55acee}.icon--ei-sc-vimeo{fill:#1ab7ea}.icon--ei-sc-vk{fill:#45668e}.icon--ei-sc-youtube{fill:#e52d27}.icon--ei-sc-pinterest{fill:#bd081c}.icon--ei-sc-telegram{fill:#08c}*,*::after,*::before{box-sizing:border-box}h1,h2,h3,h4,h5,h6,ul,ol,dl,blockquote,p,address,hr,table,fieldset,figure,pre{margin-bottom:20px}ul,ol,dd{margin-left:20px}.highlight{background:#f7f7f7}.highlighter-rouge .highlight{background:#0d1117;color:#e6edf3;border-radius:10px}.highlight .c{color:#7ca668;font-style:italic}.highlight .ch{color:#7ca668;font-style:italic}.highlight .cm{color:#7ca668;font-style:italic}.highlight .cp{color:#7ca668;font-style:italic;font-weight:normal}.highlight .cpf{color:#7ca668;font-style:italic}.highlight .c1{color:#7ca668;font-style:italic}.highlight .cs{color:#7ca668;font-style:italic}.highlight .err{color:#f85149}.highlight .esc{color:#e6edf3}.highlight .g{color:#e6edf3}.highlight .k{color:#c586c0}.highlight .l{color:#a5d6ff}.highlight .n{color:#e6edf3}.highlight .o{color:#d4d4d4}.highlight .x{color:#e6edf3}.highlight .p{color:#d4d4d4}.highlight .gd{color:#ffa198;background-color:#490202}.highlight .ge{color:#e6edf3;font-style:italic}.highlight .ges{color:#e6edf3;font-weight:bold;font-style:italic}.highlight .gr{color:#ffa198}.highlight .gh{color:#79c0ff;font-weight:bold}.highlight .gi{color:#56d364;background-color:#0f5323}.highlight .go{color:#8b949e}.highlight .gp{color:#8b949e}.highlight .gs{color:#e6edf3;font-weight:bold}.highlight .gu{color:#79c0ff}.highlight .gt{color:#ff7b72}.highlight .g-Underline{color:#e6edf3;text-decoration:underline}.highlight .kc{color:#79c0ff}.highlight .kd{color:#569cd6}.highlight .kn{color:#ff7b72}.highlight .kp{color:#79c0ff}.highlight .kr{color:#4ec9b0}.highlight .kt{color:#4ec9b0}.highlight .ld{color:#ce9178}.highlight .sd{color:#a5d6ff}.highlight .na{color:#e6edf3}.highlight .nb{color:#4ec9b0}.highlight .nc{color:#4ec9b0;font-weight:bold}.highlight .no{color:#79c0ff;font-weight:bold}.highlight .nd{color:#d2a8ff;font-weight:bold}.highlight .ni{color:#ffa657}.highlight .ne{color:#f0883e;font-weight:bold}.highlight .nf{color:#dcdcaa;font-weight:bold}.highlight .nl{color:#4ec9b0;font-weight:bold}.highlight .nn{color:#ff7b72}.highlight .nx{color:#9cdcfe}.highlight .py{color:#79c0ff}.highlight .nt{color:#4ec9b0}.highlight .nv{color:#79c0ff}.highlight .ow{color:#ff7b72;font-weight:bold}.highlight .pm{color:#e6edf3}.highlight .w{color:#6e7681}.highlight .mb{color:#a5d6ff}.highlight .mf{color:#b5cea8}.highlight .mh{color:#a5d6ff}.highlight .mi{color:#b5cea8}.highlight .mo{color:#a5d6ff}.highlight .sa{color:#79c0ff}.highlight .sb{color:#a5d6ff}.highlight .sc{color:#a5d6ff}.highlight .dl{color:#ce9178}.highlight .sd{color:#a5d6ff}.highlight .s{color:#ce9178}.highlight .s1{color:#ce9178}.highlight .s2{color:#ce9178}.highlight .se{color:#79c0ff}.highlight .sh{color:#79c0ff}.highlight .si{color:#a5d6ff}.highlight .sx{color:#a5d6ff}.highlight .sr{color:#79c0ff}.highlight .ss{color:#a5d6ff}.highlight .bp{color:#e6edf3}.highlight .fm{color:#d2a8ff;font-weight:bold}.highlight .vc{color:#79c0ff}.highlight .vg{color:#79c0ff}.highlight .vi{color:#79c0ff}.highlight .vm{color:#79c0ff}.highlight .il{color:#a5d6ff}body{font-family:"Open Sans",Helvetica Neue,Helvetica,"Noto Sans KR",Arial,sans-serif;font-size:16px;line-height:28px;color:#404040;background-color:#fbfbfb;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}*::selection{color:#fff;background-color:#3af}.toc-container{margin-bottom:20px;display:flex;justify-content:center}.toc{background-color:#fff;border:1px solid #edeeee;border-radius:8px;padding:20px;box-shadow:0 2px 4px rgba(0,0,0,.1);width:100%;font-family:"Noto Sans KR",sans-serif;text-align:left}.toc-title{font-family:"Noto Sans KR",sans-serif;font-size:32px;font-weight:700;color:#05b;margin-bottom:20px;text-align:left;background-color:rgba(204,238,255,.5);padding:15px;border-radius:5px;border:1px solid #ccc}.toc ul{list-style-type:disc;padding-left:15px}.toc a{font-family:"Noto Sans KR",sans-serif;font-size:16px;color:hsl(205,100%,45%);text-decoration:none;display:block;transition:color .3s ease,background-color .3s ease}.toc a:hover{background-color:#eee;color:rgb(0,89.25,153);text-decoration:underline}.toc a:active{color:#05b}.toc .list-group-item.active{background-color:rgba(34,34,34,.8);color:#fff;font-weight:bold;border-radius:5px}.toc .list-group-item.disabled{color:#6c757d;background-color:rgba(0,0,0,0)}.toc .list-group-item+.list-group-item{margin-top:8px}h1,h2,h3,h4,h5,h6{font-family:"Noto Sans KR",serif;font-weight:700;line-height:initial}h1{font-weight:700;font-size:36px;line-height:110%;margin-top:1.6em;margin-bottom:.8em}h2{font-weight:700;font-size:32px;margin-top:1.6em;margin-bottom:.8em}h3{font-weight:700;font-size:28px;margin-top:1.8em;margin-bottom:.9em}h4{font-weight:700;font-size:24px;margin-top:2em;margin-bottom:1em}h5{font-weight:700;font-size:22px;margin-top:2em;margin-bottom:1em;color:#333}h6{font-weight:700;font-size:20px;margin-top:2em;margin-bottom:1em;color:#444}img{max-width:100%;height:auto;vertical-align:middle}img+strong:before{display:inline-block;content:"▲";padding-right:5px;font-size:14px}img+strong{display:block;font-size:14px}p:has(>img):has(>strong){max-width:90%;margin:50px auto;text-align:center}a{text-decoration:none;color:hsl(205,100%,45%);transition:.35s}a:hover{color:rgb(0,89.25,153)}blockquote{padding-left:20px;border-left:4px solid #3af;font-family:"Noto Sans KR",serif;font-style:normal;font-size:14px;background-color:rgb(237.58,248.3,252.32)}blockquote p{padding:10px}hr{height:4px;margin:20px 0;border:0;background-color:#6b6b6b}pre{overflow:auto;padding:14px;font-size:14px;white-space:pre-wrap;word-wrap:break-word;word-break:break-all;font-family:Courier,"Noto Sans KR",monospace}pre.highlight{padding:15px 20px}code{border-radius:10px;overflow:auto;white-space:pre-wrap;word-wrap:break-word;word-break:break-all;font-family:Menlo,Monaco,"Courier New",monospace;font-weight:bold;font-size:14px;vertical-align:middle}p code,li code{color:#eb5757;background-color:#edeeee;margin:0 2px;padding:5px 6px}pre code{font-size:14px;color:#ddd;background-color:rgba(0,0,0,0)}.language-plaintext code{color:#ddd}.o-wrapper{max-width:1440px;position:relative}.o-opacity{animation-duration:.7s;animation-delay:.2s;animation-fill-mode:both;animation-name:opacity}@keyframes opacity{from{opacity:0}to{opacity:1}}.c-btn{display:inline-block;white-space:nowrap;vertical-align:middle;font-family:"Noto Sans KR",serif;font-size:14px;text-align:center;padding:5px 15px;cursor:pointer;transition:.35s}.c-btn--primary{color:#fff;background-color:#3af;background:linear-gradient(135deg, #33aaff 0%, #62d5ff 100%)}.c-btn--secondary{color:#fff;background-color:#cfcfdd;background:linear-gradient(135deg, #a2a2bd 0%, #cfcfdd 100%)}.c-btn--bar{color:#fff;background-color:#444;background:#525252;font-size:14px;width:76%;height:40px}.c-btn--round{border-radius:30px}.c-btn--shadow{box-shadow:8px 10px 20px 0 rgba(46,61,73,.15)}.c-btn--shadow:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,.2)}.c-btn--middle{display:block;width:300px;max-width:100%}.c-btn--big{display:block;width:100%}.c-btn:hover{color:#fff;transition:.35s}.c-btn:active{transform:translateY(2px)}.c-sidebar{display:flex;flex-direction:column;justify-content:space-between;position:fixed;top:0;left:0;bottom:0;width:360px;padding:40px 20px 20px;text-align:center;box-shadow:1px 1px 0 rgba(31,35,46,.15);background-color:#fff}.c-sidebar-author{display:flex;flex-direction:column}.c-sidebar-author .c-author__cover{width:100px;height:100px;margin:0 auto 10px;border-radius:50%;overflow:hidden;background-color:#cfcfdd}.c-sidebar-author .c-author__cover img{width:100%;height:100%;border-radius:50%;transition:.35s}.c-sidebar-author .c-author__cover img:hover{transform:scale3d(0.9, 0.9, 1)}.c-sidebar-author .c-contact-menu .c-btn{min-width:110px}.c-sidebar-author .c-contact-menu .c-btn .icon{vertical-align:text-bottom;fill:#fff}.c-sidebar-author .c-author__info{font-family:"Noto Sans KR",serif}.c-sidebar-author .c-author__name{font-size:18px;font-weight:700;line-height:21px}.c-sidebar-author .c-author__job{font-size:12px;color:#a0a0a0;margin:5px 0 0}.c-sidebar-author .c-contact-menu{justify-items:center;margin:30px 0px 10px 0px}.c-sidebar-author .c-contact-menu .c-btn{width:130px}.c-sidebar-author .c-contact-menu-bar{justify-items:center;margin:0px 0px 25px 0px}.c-sidebar-author .c-contact-menu-bar .c-btn{font-size:14px;width:260px}.c-sidebar-author .c-author__about{max-width:400px;margin:0 auto 15px;font-size:13px}.c-sidebar-footer .c-social__title{position:relative;font-family:"Noto Sans KR",serif;font-size:16px;font-weight:700;color:#444}.c-sidebar-footer .c-social__title::before{content:"";display:block;height:2px;width:calc(50% - 40px);transform:translateY(-50%);position:absolute;top:50%;left:0;background-color:#444}.c-sidebar-footer .c-social__title::after{content:"";display:block;height:2px;width:calc(50% - 40px);transform:translateY(-50%);position:absolute;top:50%;right:0;background-color:#444}.c-sidebar-footer .c-social__list{list-style-type:none;padding:0;margin:15px 0}.c-sidebar-footer .c-social__list .c-social__item{display:inline-block;width:27px;height:27px}.c-sidebar-footer .c-social__list .icon{width:27px;height:27px;fill:#444;vertical-align:middle;transition:.35s}.c-sidebar-footer .c-social__list .icon:hover{fill:#3af;transform:scale(1.2);transition:.35s}.c-sidebar-footer .c-copyright p{font-size:13px;margin:0}@media only screen and (max-width: 900px){.c-sidebar{position:relative;width:100%;padding:20px}.c-sidebar .c-contact-menu{margin:20px 0}.c-sidebar-footer .c-social .c-social__title{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}.c-sidebar-footer .c-social__list{margin:0}.c-sidebar-footer .c-copyright{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}}@media only screen and (max-width: 480px){.c-sidebar-author{display:flex;flex-direction:column}.c-sidebar-author .c-author__cover{width:80px;height:80px}.c-sidebar-author .c-author__cover img{width:100%;height:100%}.c-sidebar-author .c-contact-menu{justify-items:center;margin:15px 0px 0px 0px;min-width:245px}.c-sidebar-author .c-contact-menu .c-btn{min-width:80px;font-size:12px;width:120px;height:36px;margin-bottom:10px}.c-sidebar-author .c-contact-menu-bar{justify-items:center;margin:0px 0px 25px 0px}.c-sidebar-author .c-contact-menu-bar .c-btn{min-width:80px;font-size:12px;width:244px;height:36px;padding:4px 15px}.c-sidebar-footer .c-social .c-social__title{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}.c-sidebar-footer .c-social__list{margin:0}.c-sidebar-footer .c-social__list .icon{width:25px;height:25px}.c-sidebar-footer .c-copyright{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}}.c-content{position:relative;display:flex;flex-direction:row;flex-wrap:wrap;align-items:stretch;padding:0 20px 0;margin-left:360px}@media only screen and (max-width: 900px){.c-content{position:static;padding:0 15px 0;margin-left:0}}.c-posts{width:100%;display:flex;flex-direction:row;flex-wrap:wrap}.c-post{width:100%;max-width:100%;margin-bottom:20px;display:flex;flex-direction:row;align-items:stretch;min-height:180px;border-radius:10px;overflow:hidden;transition:.35s;background-color:#fff;box-shadow:0 1px 1px 0 rgba(31,35,46,.15)}.c-post:hover{transform:translate(0px, -2px);box-shadow:0 15px 45px -10px rgba(10,16,34,.2)}.c-post .c-post-thumbnail{display:block;width:30%;max-width:100%;min-height:180px;border-radius:10px 0 0 10px;background-color:rgba(220,235,245,.2);background-size:cover;background-position:50% 50%}.c-post .c-post-content{padding:15px;width:70%}.c-post .c-post-content .c-post-title{font-size:30px;font-weight:400;margin:0 0 15px}.c-post .c-post-content .c-post-title a{text-decoration:none;color:#263959}.c-post .c-post-content .c-post-tags{padding:3px 5px;border-radius:3px;background-color:rgba(135,131,120,.2);color:#eb5757;font-size:85%;font-family:"Courier Prime","Noto Sans KR"}.c-post .c-post-content .c-post-date,.c-post .c-post-content .c-post-words{font-size:12px}.c-load-more{padding:20px;margin:20px auto 40px;font-size:13px;color:#fff;border:none;background-color:#3af;outline:none}.c-load-more:hover{background-color:hsl(205,100%,45%)}@media only screen and (max-width: 1200px){.c-post{width:48%;max-width:100%;margin:0 1% 20px;flex-direction:column}.c-post .c-post-thumbnail{width:100%;border-radius:10px 10px 0 0}.c-post .c-post-content{width:100%}.c-post .c-post-content .c-post-title{font-size:21px;margin:15px 0}}@media only screen and (max-width: 480px){.c-post{width:100%;max-width:100%;margin:0 0 20px}.c-post .c-post-content{width:100%}.c-post .c-post-content .c-post-title{font-size:21px;margin:15px 0}}.c-article{width:100%;margin:20px 0}.c-wrap-content{padding:7%;background-color:#fff}.c-article__image{position:relative;background-color:rgba(220,235,245,.2);background-position:center;background-size:cover;background-repeat:no-repeat}.c-article__image:after{content:"";display:block;padding-top:56%}.c-article__header{margin-bottom:60px;padding-bottom:10px;text-align:center;border-bottom:1px solid #6b6b6b}.c-article__header .c-article__title{margin-bottom:10px}.c-article__date span{font-size:13px;text-transform:uppercase;color:#a0a0a0}.c-article__footer{margin:60px 0 0;padding-top:20px;padding-bottom:10px;text-align:center;border-top:1px solid #6b6b6b}.c-article__footer .c-article__share{transition:.35s}.c-article__footer .c-article__share a .icon{vertical-align:middle;transition:.35s}.c-article__footer .c-article__share a .icon:hover{opacity:.7;transition:.35s}.c-article__footer .c-article__tag{margin-bottom:5px}.c-article__footer .c-article__tag a{display:inline-block;vertical-align:middle;padding:5px 10px;font-family:"Noto Sans KR",serif;font-size:10px;line-height:10px;text-transform:uppercase;background-color:rgba(115,138,160,.6);color:#fff}.c-article__footer .c-article__tag a:hover{background-color:rgba(80.2446808511,99.6723404255,118.2553191489,.6)}.c-article__footer .c-article__tag a:last-child{margin-right:0}.c-recent-post{padding:30px 0}.c-recent-post .c-recent__title{font-size:14px;text-align:center;text-transform:uppercase;margin-bottom:30px}.c-recent-post .c-recent__box{display:flex;flex-direction:row;flex-wrap:wrap}.c-recent-post .c-recent__item{max-width:23%;flex-basis:23%;margin:0 1% 20px;border-radius:10px;overflow:hidden;text-align:center;background-color:#fff;box-shadow:0 1px 1px 0 rgba(31,35,46,.15);transition:.35s}.c-recent-post .c-recent__item h4{margin-bottom:5px;font-size:12px;text-transform:uppercase}.c-recent-post .c-recent__item h4 a{color:#444}.c-recent-post .c-recent__item:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,.2)}.c-recent-post .c-recent__footer{padding:15px}.c-recent-post .c-recent__image{display:block;width:100%;min-height:180px;background-color:rgba(220,235,245,.2);background-size:cover;background-position:center;background-repeat:no-repeat}.c-recent-post .c-recent__date{color:#a0a0a0;font-size:12px}@media only screen and (max-width: 1200px){.c-recent-post .c-recent__item{max-width:48%;flex-basis:48%}}@media only screen and (max-width: 900px){.c-article{margin:15px 0}}@media only screen and (max-width: 480px){.c-wrap-content{padding:15px}.c-article__header{margin-bottom:5px}.c-article__header .c-article__title{font-size:24px;margin-bottom:5px}.c-recent-post .c-recent__item{max-width:100%;flex-basis:100%;margin:0 0 20px}}.c-blog-tags{width:100%;padding:20px;margin:20px 0 40px;background-color:#fff}.c-blog-tags h1{text-align:center;margin-bottom:0}.c-blog-tags h2{font-size:18px;text-transform:uppercase;margin:30px 0;color:#757575}.c-tag__list{list-style:none;padding:0 0 40px;margin:40px 0 0;border-bottom:1px solid #6b6b6b}.c-tag__list li{display:inline-block;margin-right:15px}.c-tag__list li a{color:#404040;text-transform:uppercase;font-size:12px}.c-tag__list li a:hover{color:hsl(0,0%,-4.9019607843%)}.c-tag__item{margin-bottom:15px}.c-tag__image{width:50px;height:50px;border-radius:50%;margin-right:5px}@media only screen and (max-width: 480px){.c-blog-tags{padding:15px}.c-blog-tags h1{font-size:27px}.c-blog-tags h2{font-size:16px;margin:15px 0}.c-tag__list{padding:0 0 30px;margin:30px 0 0}.c-tag__item{margin-bottom:5px}.c-tag__image{display:none}}.c-header{position:relative;width:100%;margin:20px 0}.c-header__box{position:relative;display:flex;flex-direction:row;justify-content:space-between;align-items:center}.c-header__box .icon--ei-search{position:absolute;top:7px;left:15px;fill:#ccc}.c-search{width:80%}.c-search .c-search__box{display:flex;align-items:center}.c-search .c-search__text{position:relative;width:100%;padding:10px 10px 10px 40px;border:1px solid #f2fafd;border-radius:30px;outline:none;color:#a0a0a0}.c-search .c-search__text::placeholder{color:#ccc}.c-search .c-search__text:hover{box-shadow:0 1px 0px rgba(132,135,138,.1);transition:.35s}.c-search .c-search-results-list{position:absolute;width:100%;margin:10px 0 0;list-style-type:none;background-color:#fff;z-index:1}.c-search .c-search-results-list li{display:flex;flex-wrap:wrap;align-items:center;margin:0;padding:20px 25px 0;background-color:#fff;line-height:1.4;border-left:solid 1px #edeeee;border-right:solid 1px #edeeee}.c-search .c-search-results-list li:first-child{border-top-left-radius:5px;border-top-right-radius:5px;border-top:solid 1px #edeeee}.c-search .c-search-results-list li:last-child{border-bottom-left-radius:5px;border-bottom-right-radius:5px;padding-bottom:25px;border-bottom:solid 1px #edeeee}.c-search .c-search-results-list li a{font-size:16px}.c-nav{flex-grow:1;padding-left:20px}.c-nav .c-nav__list{display:flex;justify-content:flex-end}.c-nav .c-nav__list .c-nav__item{display:flex;align-items:center;float:left;padding:4px 10px;font-size:10px;text-transform:uppercase;white-space:nowrap;border:1px solid #f2fafd;box-shadow:0 1px 0px rgba(132,135,138,.4);will-change:transform;transform:translateY(0px);cursor:pointer}.c-nav .c-nav__list .c-nav__item:hover{color:#222;background-color:#fff}.c-nav .c-nav__list .c-nav__item.is-active{box-shadow:0 0 0 rgba(132,135,138,.5);transform:translateY(1px);color:#cfcfdd}.c-nav .c-nav__list .c-nav__item.is-active:hover{background-color:#fbfbfb}.c-nav .c-nav__list .c-nav__item:first-child{border-radius:10px 0 0 10px}.c-nav .c-nav__list .c-nav__item:last-child{border-radius:0 10px 10px 0}.c-nav .c-nav__list .c-nav__item .icon{width:18px;height:18px;margin-right:3px}@media only screen and (max-width: 900px){.c-header{margin:15px 0}}@media only screen and (max-width: 480px){.c-header .c-header__box{flex-direction:column}.c-header .c-search{width:100%}.c-header .c-search .c-search__text{padding:8px 8px 8px 40px}.c-header .c-nav{margin-top:15px}.c-header .c-nav .c-nav__list{justify-content:center}.c-header .c-nav .c-nav__item{padding:4px 8px}}.c-categories{width:100%}.c-categories__list{width:100%;display:flex;flex-direction:row;flex-wrap:wrap}.c-categories__item{max-width:25%;flex-basis:25%;padding:0 10px 20px}.c-categories__link{height:100%;display:flex;flex-direction:column;align-items:center;padding:20px 10px;border-radius:5px;box-shadow:5px 5px 25px rgba(46,61,73,.15);background-color:#fff;transition:.35s}.c-categories__link:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,.2)}.c-categories__link:hover .c-categories__img .c-categories__more{opacity:1;transition:.35s}.c-categories__link .c-categories__container{width:100%;word-wrap:break-word}.c-categories__link .c-categories__container.c-empty-figure{display:flex;flex-direction:column;justify-content:center;flex-grow:1}.c-categories__img{position:relative;max-width:100%}.c-categories__img figure{position:relative;width:200px;max-width:100%;margin-bottom:20px;overflow:hidden;background-size:cover;background-repeat:no-repeat;background-position:center;border-radius:50%;box-shadow:inset 0 1px 3px rgba(141,165,185,.3)}.c-categories__img figure:after{content:"";display:block;padding-top:100%}.c-categories__img figure:before{content:"";position:absolute;top:0;bottom:0;left:0;right:0;background-color:rgba(0,0,0,.15)}.c-categories__img .c-categories__more{display:inline-block;position:absolute;top:50%;left:50%;transform:translate(-50%, -50%);font-weight:700;color:#fff;text-transform:uppercase;text-shadow:0 1px 0 rgba(104,172,191,.3);opacity:0;transition:.35s}.c-categories__container{text-align:center}.c-categories__container .c-categories__header{font-size:13px;margin-bottom:10px;font-weight:normal;text-transform:uppercase;color:#404040}.c-categories__container .c-categories__count{font-family:"Noto Sans KR",serif;font-size:12px;color:#404040;margin-bottom:0}.c-categories__container .c-categories__count span{display:inline-block;width:20px;height:20px;line-height:20px;vertical-align:baseline;margin-right:5px;border-radius:50%;color:#fff;background-color:#ee6c6c}@media only screen and (max-width: 1200px){.c-categories .c-categories__item{max-width:33.333%;flex-basis:33.333%}}@media only screen and (max-width: 1050px){.c-categories .c-categories__item{max-width:50%;flex-basis:50%}}@media only screen and (max-width: 480px){.c-categories .c-categories__item{max-width:100%;flex-basis:100%;padding:0 0 20px}}.c-form-box{position:absolute;top:0;width:calc(100% - 40px);min-height:100vh;padding:0 20px;background-color:#fff;z-index:1}.c-form-bnt__close{position:absolute;top:0px;left:0;width:30px;height:30px;cursor:pointer;transition:.35s}.c-form-bnt__close:hover{transform:scale(0.8);opacity:.8}.c-form{position:relative;width:750px;max-width:100%;margin:40px auto}.c-form .c-form__title{margin:0 0 40px;min-width:0;border:0;padding:0;font-family:"Noto Sans KR",serif;text-transform:uppercase;text-align:center}.c-form a{color:#404040}.c-form__group{margin-bottom:20px}.c-form__group label{display:block;text-transform:uppercase;font-size:10px}.c-form__group input,.c-form__group textarea{width:100%;padding:10px 15px;color:#404040;border:1px solid #f2fafd;outline:none;transition:.35s}.c-form__group input:focus,.c-form__group textarea:focus{box-shadow:0 4px 25px rgba(132,135,138,.1)}.c-form__group button{padding:20px;text-transform:uppercase;outline:none;border:none}.c-thank-you p{position:relative;padding:20px 40px;width:750px;max-width:100%;text-transform:uppercase;font-size:12px;line-height:18px;font-weight:700;margin:40px auto 0;text-align:center;color:#fff;background:linear-gradient(135deg, #55b5ad 0%, #5ec9c5 100%)}.c-thank-you p .c-form-bnt__close{width:25px;height:25px;background:rgba(0,0,0,0)}.c-thank-you p a{color:#fff}@media only screen and (max-width: 900px){.c-form-box{width:100%;left:0;right:0}}@media only screen and (max-width: 480px){.c-form-bnt__close{width:25px;height:25px}}.c-newsletter{padding:30px 0 60px;margin:0 auto;border-bottom:1px solid #6b6b6b}.c-newsletter__header{text-align:center}.c-newsletter__header .c-newsletter__title{font-size:14px;text-transform:uppercase;text-align:center}.c-newsletter__header .c-newsletter__subtitle{margin-bottom:15px}.c-newsletter-form{width:100%;max-width:750px;margin:0 auto}.c-newsletter-form .c-newsletter-form__group{display:flex}.c-newsletter__email{width:70%;height:40px;padding:10px 15px;border:1px solid #ddd;border-right-color:rgba(0,0,0,0);outline:none;transition:.35s}.c-newsletter__email:focus{box-shadow:0 4px 25px rgba(132,135,138,.1)}.c-newsletter__button{width:30%;height:40px;color:#fff;background-color:#3af;transition:.35s;border:none;outline:none;cursor:pointer}.c-newsletter__button:hover{background-color:hsl(205,100%,45%)}@media only screen and (max-width: 480px){.c-newsletter__button{font-size:13px}}.c-comments{padding:30px 0;border-top:1px solid #6b6b6b}.c-top{position:fixed;width:40px;height:40px;bottom:20px;color:#05b;background-color:#cef;border-radius:50%;cursor:pointer;transition:.35s;right:-100px;z-index:10;opacity:.5}.c-top--active{right:15px}.c-top:hover{color:#757575;opacity:1}.u-text-left{text-align:left}.u-text-right{text-align:right}.u-text-center{text-align:center}.u-text-justify{text-align:justify}.u-block{display:block}.u-inline-block{display:inline-block}.u-inline{display:inline}.u-full-width{display:block;width:100%}.u-vertical-center{display:flex;align-items:center;justify-content:center}.u-responsive-image{max-width:100%;height:auto;vertical-align:middle}.u-show{display:block !important}.u-hide{display:none !important}.u-invisible{visibility:hidden}.u-float-left{float:left}.u-float-right{float:right}.u-no-padding-top{padding-top:0}.u-no-padding-bottom{padding-bottom:0}.u-no-padding-left{padding-left:0}.u-no-padding-right{padding-right:0}.u-no-padding{padding:0}.u-no-margin-top{margin-top:0}.u-no-margin-bottom{margin-bottom:0}.u-no-margin-left{margin-left:0}.u-no-margin-right{margin-right:0}.u-no-margin{margin:0}.u-lists-reset{list-style-type:none;margin:0;padding:0}.u-clearfix::before,.u-clearfix::after{content:"";display:table;clear:both}.u-screen-reader-text{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}
  </style>
  <!-- KaTeX 관련 파일 -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" />
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
          { left: "\\(", right: "\\)", display: false },
          { left: "\\[", right: "\\]", display: true },
        ],
      });
    });
  </script>
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-VNMTFT1R2R"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "G-VNMTFT1R2R");
  </script>
</head>


<body>
  
    <script>
  (function (i, s, o, g, r, a, m) {
  i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
    (i[r].q = i[r].q || []).push(arguments)
}, i[r].l = 1 * new Date(); a = s.createElement(o),
    m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

  ga('create', 'G-VNMTFT1R2R', 'auto');
  ga('send', 'pageview');

</script> <!-- /google analytics -->
  
  <div class="o-wrapper">
    <aside class="c-sidebar">
  <div class="c-sidebar-author">
    <div class="c-author__cover">
      <a href="/">
        <img src="/images/Profile/profile.png" alt="Dong-Jun Shin">
      </a>
    </div>
    <div class="c-author__info">
      <div class="c-author__name">Dong-Jun Shin</div>
      <span class="c-author__job">Web Developer</span>
    </div>
    <div class="c-contact-menu">
      <div style="width: 100%">
        <a href="/about/profile" class="c-contact-btn c-btn c-btn--secondary c-btn--round c-btn--shadow">
          <div style="
            display: flex;
            flex-direction: row;
            align-items: center;">
            <span data-icon='ei-tag' data-size='s'></span>
            <span>About me</span>
          </div>
        </a>
        
        <a target="_blank" href="https://github.com/Dong-Jun-Shin" class="c-btn c-btn--primary c-btn--round c-btn--shadow">
          <div style="
            display: flex;
            flex-direction: row;
            align-items: center;">
            <span data-icon='ei-sc-github' data-size='s'></span>
            <span>Visit Github</span>
          </div>  
        </a>
      </div>
      
    </div>
    <div class="c-contact-menu-bar">
      <div style="width: 100%">
        <a href="/" class="c-contact-btn c-btn c-btn--bar c-btn--round c-btn--shadow">All Posts</a>
      </div>
    </div>
    <p class="c-author__about">개발자로 성장하며 배운 것을 정리한 블로그</p>
  </div>

  <div class="c-sidebar-footer">
    <div class="c-social">
      <div class="c-social__title">Social</div>
      <ul class="c-social__list u-lists-reset">
        
        <li class="c-social__item"><a href="https://www.linkedin.com/in/kr-jun-shin" target="_blank"><div data-icon='ei-sc-linkedin' data-size='s'></div></a></li>
        
        
        
        
        
        
        
        
        
        
          <li class="c-social__item"><a href="https://youtube.com/channel/UCIHM7drY2vvvFhrhXtpbbzw" target="_blank"><div data-icon='ei-sc-youtube' data-size='s'></div></a></li>
        
        
        
      </ul>
    </div>
    <div class="c-copyright">
      <p>2025 &copy; Dong-Jun Shin</p>
      <!-- <a target="_blank" href="https://analytics.google.com/"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fdong-jun-shin.github.io&count_bg=%23FFD540&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=true"/></a> -->
      <a target="_blank" href="https://analytics.google.com/"><img src="https://img.shields.io/badge/Info-Analytics-infomation?style=flat-square&color=yellow"/></a>
      <a target="_blank" href="https://search.google.com/search-console"><img src="https://img.shields.io/badge/Info-Search-informational?style=flat-square"/></a>
    </div>
  </div>
</aside> <!-- /.c-sidebar -->

<main class="c-content">
  <article class="c-article">
  <div class="c-article__content">
    <header class="c-header u-hide u-no-margin-top">
      <div class="c-header__box">
        <div class="c-search u-full-width">
          <div class="c-search__box">
            <label for="js-search-input" class="u-screen-reader-text">Search for Blog</label>
            <input type="text" id="js-search-input" class="c-search__text" autocomplete="off" placeholder="Type to search...">
            <div data-icon='ei-search' data-size='s'></div>
          </div>
          <ul id="js-results-container" class="c-search-results-list"></ul>
        </div>
      </div>
    </header>
    
    <div class="c-article__image o-opacity" style="background-image: url( /images/CS_AI_ML/2023/05/Beyond_AI_Basic_2023_Week_1/0.png )"></div>
    
    <div class="c-wrap-content">
      <header class="c-article__header">
        <h1 class="c-article__title">코칭스터디 Beyond AI Basic 2023 - 1주차 학습</h1>
        <div class="c-article__date">
          <span>2023, May 08</span>
        </div>
      </header>
      
      <div class="toc-container">
        <div class="toc">
          <div class="toc-title">Index</div>
          <ul><li><a href="#개발환경-준비하기">개발환경 준비하기</a></li><li><a href="#가상환경-구성">가상환경 구성</a><ul><li><a href="#가상환경-만들기">가상환경 만들기</a></li><li><a href="#의존-라이브러리-설치">의존 라이브러리 설치</a></li><li><a href="#주피터-노트북-실행">주피터 노트북 실행</a></li></ul></li><li><a href="#정형-데이터-소개">정형 데이터 소개</a><ul><li><a href="#정형-데이터와-비정형-데이터의-차이">정형 데이터와 비정형 데이터의 차이</a></li><li><a href="#데이터-문제-및-이해">데이터 문제 및 이해</a></li><li><a href="#평가지표-이해">평가지표 이해</a><ul><li><a href="#분류-회귀-평가지표-소개">분류, 회귀 평가지표 소개</a></li><li><a href="#confusion-matrix">Confusion Matrix</a></li><li><a href="#accuracy-precision-recall">Accuracy, Precision, Recall</a></li><li><a href="#roc-auc">ROC, AUC</a></li></ul></li></ul></li><li><a href="#쇼핑-데이터를-활용한-예측-실습">쇼핑 데이터를 활용한 예측 실습</a><ul><li><a href="#머신러닝-없는-베이스라인-모델과-과거-데이터를-이용해서-미래-데이터-예측하기">머신러닝 없는 베이스라인 모델과 과거 데이터를 이용해서 미래 데이터 예측하기</a></li></ul></li><li><a href="#탐색적-자료-분석">탐색적 자료 분석</a><ul><li><a href="#edaexploratory-data-analysis-탐색적-데이터-분석">EDA(Exploratory Data Analysis, 탐색적 데이터 분석)</a><ul><li><a href="#eda의-의미">EDA의 의미</a></li><li><a href="#eda-과정">EDA 과정</a></li><li><a href="#범주형-데이터">범주형 데이터</a></li></ul></li></ul></li><li><a href="#정형-데이터-전처리">정형 데이터 전처리</a><ul><li><a href="#데이터-전처리">데이터 전처리</a></li><li><a href="#전처리에-필요한-다양한-인코딩-방법과-장단점">전처리에 필요한 다양한 인코딩 방법과 장단점</a></li><li><a href="#데이터-상-결측치와-이상치-처리-방법">데이터 상 결측치와 이상치 처리 방법</a></li></ul></li><li><a href="#머신러닝-기본-개념-소개">머신러닝 기본 개념 소개</a><ul><li><a href="#underfitting과-overfitting">Underfitting과 Overfitting</a></li><li><a href="#검증-전략">검증 전략</a></li><li><a href="#재현율">재현율</a></li><li><a href="#머신-러닝-workflow">머신 러닝 Workflow</a></li></ul></li><li><a href="#트리-모델-소개">트리 모델 소개</a><ul><li><a href="#tree-model">Tree Model</a></li><li><a href="#bagging--boosting">Bagging &amp; Boosting</a></li><li><a href="#lightgbm-xgboost-catboost">LightGBM, XGBoost, CatBoost</a></li><li><a href="#hyper-parameter-살펴보기">Hyper-parameter 살펴보기</a></li></ul></li><li><a href="#reference">Reference</a></li></ul>
        </div>
      </div>
      
      <h1 id="개발환경-준비하기">개발환경 준비하기</h1>

<h1 id="가상환경-구성">가상환경 구성</h1>

<h2 id="가상환경-만들기">가상환경 만들기</h2>

<ul>
  <li>Python + miniconda3(Anaconda) 설치</li>
  <li>가상환경 생성
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># conda create -n {ENV_NAME} python={PYTHON_VERSION}
</span>
<span class="n">conda</span> <span class="n">create</span> <span class="o">-</span><span class="n">n</span> <span class="n">virtual_workspace</span> <span class="n">python</span><span class="o">=</span><span class="mf">3.8</span>
</code></pre></div>    </div>
  </li>
  <li>가상환경 활성화
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># conda activate {ENV_NAME}
</span>
<span class="p">(</span><span class="n">base</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">conda</span> <span class="n">activate</span> <span class="n">virtual_workspace</span>
<span class="p">(</span><span class="n">virtual_workspace</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">...</span>
</code></pre></div>    </div>
  </li>
  <li>가상환경 비활성화
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">virtual_workspace</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">conda</span> <span class="n">deactivate</span>
<span class="p">(</span><span class="n">base</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">...</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<h2 id="의존-라이브러리-설치">의존 라이브러리 설치</h2>

<ul>
  <li>목록
    <ul>
      <li>catboost</li>
      <li>matplotlib</li>
      <li>numpy</li>
      <li>pandas</li>
      <li>scikit-learn</li>
      <li>seaborn</li>
      <li>xgboost</li>
      <li>lightgbm</li>
      <li>tqdm</li>
      <li>notebook</li>
      <li>optuna</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pip 업그레이드
</span><span class="p">(</span><span class="n">virtual_workspace</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="n">pip</span>

<span class="c1"># requirments.txt 참고하여 라이브러리 설치
</span><span class="p">(</span><span class="n">virtual_workspace</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">r</span> <span class="n">requirements</span><span class="o">-</span><span class="n">window</span><span class="p">.</span><span class="n">txt</span>
</code></pre></div></div>

<p><br /></p>

<h2 id="주피터-노트북-실행">주피터 노트북 실행</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">virtual_workspace</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">cd</span> <span class="n">notebook</span>
<span class="p">(</span><span class="n">virtual_workspace</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">jupyter</span> <span class="n">notebook</span>
</code></pre></div></div>

<p><br /></p>

<h1 id="정형-데이터-소개">정형 데이터 소개</h1>

<h2 id="정형-데이터와-비정형-데이터의-차이">정형 데이터와 비정형 데이터의 차이</h2>

<ul>
  <li>정형 데이터
    <ul>
      <li>행(인스턴스), 열(피처)로 구성된 엑셀 파일, RDB와 같은 형식</li>
      <li>가장 기본적인 데이터로, 분야를 막론하고 많은 데이터가 존재</li>
    </ul>
  </li>
  <li>비정형 데이터
    <ul>
      <li>이미지, 비디오, 음성, 자연어 등 틀이 없는 데이터</li>
      <li>머신러닝과 함께 활용도가 높아짐</li>
    </ul>
  </li>
  <li>정형데이터 분석
    <ul>
      <li>상상력, 통찰력 기반의 데이터 분석이 중요</li>
      <li>예시로 전쟁 당시 전투기 생존력 향상을 위한 연구에서 전투기에 총알이 어디에 많이 박혔는지 낸 통계를 보고 총알을 맞지 않은 부위에 대한 보강을 해법으로 제시</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="데이터-문제-및-이해">데이터 문제 및 이해</h2>

<ul>
  <li>평가지표와 각종 시각화를 이용해서 데이터 이해</li>
</ul>

<p><br /></p>

<h2 id="평가지표-이해">평가지표 이해</h2>

<h3 id="분류-회귀-평가지표-소개">분류, 회귀 평가지표 소개</h3>

<ul>
  <li>지도학습의 큰 범주에 속함</li>
  <li>분류
    <ul>
      <li>예측해야 할 대상의 개수가 정해져 있는 문제</li>
      <li>이미지에서 개, 고양이 등 객체 분류, 사기 탐지에서 정상 케이스 분류</li>
    </ul>
  </li>
  <li>회귀
    <ul>
      <li>예측해야 할 대상이 연속적인 숫자인 문제</li>
      <li>일기 예보의 기온 예측, 집값 예측 등 수치를 예측</li>
    </ul>
  </li>
  <li>평가지표
    <ul>
      <li>회귀, 분류 머신러닝이 문제를 해결하는 성능을 평가하는 지표</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="confusion-matrix">Confusion Matrix</h3>

<ul>
  <li>2진 분류의 예측 오류에 대해 나타낸 행렬(TN, FP, FN, TP)</li>
  <li>예측과 실제에 대해 ‘Negative, Positive’로 분류</li>
</ul>

<p><br /></p>

<h3 id="accuracy-precision-recall">Accuracy, Precision, Recall</h3>

<ul>
  <li>Accuracy(정확도)
    <ul>
      <li>전체 예측 중 진짜 맞힌 정도</li>
      <li>(TP + TN) / (TP + TN + FP + FN)</li>
      <li>불균형한 데이터에 사용하기는 부적절</li>
    </ul>
  </li>
  <li>Precision(정밀도)
    <ul>
      <li>틀리던 맞던, 참이라 예측한 것 중 진짜 참인 정도</li>
      <li>TP / (TP + FP)</li>
      <li>Negative를 Positive라 판단하면 안되는 경우 사용</li>
      <li>예시: 스팸 메일 분류</li>
    </ul>
  </li>
  <li>Recall(재현률)
    <ul>
      <li>참은 참, 거짓은 거짓이라 예측한 것 중 진짜 참인 정도</li>
      <li>TP / (TP + FN)</li>
      <li>Positive를 Negative라 판단하면 안되는 경우 사용</li>
      <li>예시: 악성 종양 분류 등</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="roc-auc">ROC, AUC</h3>

<ul>
  <li>ROC(Receiver Operating Characteristic, 수신자 조작 특성)
    <ul>
      <li>임계값의 변화를 그래프로 표현한 것</li>
      <li>TPR(True Posive Ratio)이 Y축 (예측을 맞힌 비율)</li>
      <li>FPR(False Positive Ratio)이 X축 (잘못 예측한 비율)</li>
    </ul>
  </li>
  <li>AUC(Area Under the Curve, )
    <ul>
      <li>그래프 전체 면적에서 곡선 아래 공간이 차지하는 비율</li>
      <li>0 ~ 1의 값을 가짐, 1에 가까울수록 우수한 예측 성능</li>
      <li>그래프에서 대각선 직선의 아래에 해당하는 최소 0.5 이상은 나와야 유의미</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="쇼핑-데이터를-활용한-예측-실습">쇼핑 데이터를 활용한 예측 실습</h1>

<h2 id="머신러닝-없는-베이스라인-모델과-과거-데이터를-이용해서-미래-데이터-예측하기">머신러닝 없는 베이스라인 모델과 과거 데이터를 이용해서 미래 데이터 예측하기</h2>

<ul>
  <li>베이스라인 모델이란?
    <ul>
      <li>모델의 성능을 비교하는 참조 지점으로 사용되는 단순한 모델 또는 휴리스틱</li>
      <li>머신러닝 모델이 의미있기 위해 넘어야 하는 최소한의 성능을 제공하는 모델</li>
    </ul>
  </li>
  <li>예측 방법
    <ul>
      <li>첫번째 베이스라인 모델은 머신러닝 모델을 사용하지 않고, 이전 월 고객 구매액을 계산한 후에 이를 예측값으로 사용해서 베이스라인 모델 구현</li>
      <li>이전 월 고객 총 구매액이 300을 넘을 경우 확률을 1, 300 이하일 경우 고객 총 구매액을 300으로 나눈 값을 예측 확률로 사용</li>
      <li>2011년 10월을 training 데이터, 2011년 11월을 validation 데이터로 해서 베이스라인 모델의 validation 성능을 측정하고 2011년 12월 데이터를 예측</li>
    </ul>
  </li>
  <li>구현
    <ul>
      <li>Label 생성 함수, 평가지표 출력 함수 정의</li>
      <li>Training 데이터 로드</li>
      <li>데이터의 타입과 null을 체크 (Pandas info, isna, sum 함수를 이용)</li>
      <li>Pandas shape 속성으로 전체 개수를 가져와 null 데이터 비율 체크</li>
      <li>Pandas describe 함수로 기본 통계량 확인 (include=’all’ 설정하면 수치형, 범주형 데이터도 확인 가능)</li>
      <li>베이스라인 모델 함수 정의</li>
      <li>2011년 10월 training 데이터로 만든 베이스라인 모델로 2011년 11월 데이터를 예측</li>
      <li>예측 데이터 분포를 차트와 그래프로 시각화해서 확인</li>
      <li>실 데이터와 비교해서 평가지표 확인</li>
    </ul>
  </li>
</ul>

<h1 id="탐색적-자료-분석">탐색적 자료 분석</h1>

<h2 id="edaexploratory-data-analysis-탐색적-데이터-분석">EDA(Exploratory Data Analysis, 탐색적 데이터 분석)</h2>

<h3 id="eda의-의미">EDA의 의미</h3>

<ul>
  <li>분석자의 끝없는 상상력으로 가설을 세우고, 통찰력으로 데이터를 분석하는 과정</li>
  <li>데이터의 특징과 내재하는 구조적 관계를 알기 위함</li>
  <li><code class="language-plaintext highlighter-rouge">개별 변수의 분포</code>, <code class="language-plaintext highlighter-rouge">변수간의 분포와 관계</code>를 시각화, 통계적 방법을 통해 다양한 각도에서 관찰하고 이해</li>
  <li>예시: 히스토그램, 카운트 플롯, Correlation 히트맵, Word Cloud</li>
</ul>

<p><br /></p>

<h3 id="eda-과정">EDA 과정</h3>

<ul>
  <li>데이터마다 상이한 도메인
    <ul>
      <li>분야마다 도메인이 다르고, 해결할 문제가 다르기 때문에 일반화가 어렵고 정해진 답이 없음</li>
      <li>그래서 처음 데이터를 접하고 EDA를 진행할 때는 <code class="language-plaintext highlighter-rouge">개별 변수의 분포</code>, <code class="language-plaintext highlighter-rouge">변수간의 분포와 관계</code>의 분석과 가설 수립에서 시작됨</li>
    </ul>
  </li>
  <li>데이터에 의문을 가지고, 관찰하는 과정의 반복을 통해 데이터와 문제를 이해하는 과정
    <ol>
      <li>예측할 타겟 변수를 선정</li>
      <li><code class="language-plaintext highlighter-rouge">개별 변수의 분포</code>, <code class="language-plaintext highlighter-rouge">연속형, 범주형 변수 그래프</code>를 분석해서 특징 도출</li>
      <li>(성별, 지위, 지역, 결혼 여부 등)변수 간의 관계 분석해서 가설을 수립</li>
    </ol>
  </li>
</ul>

<p><br /></p>

<h3 id="범주형-데이터">범주형 데이터</h3>

<ul>
  <li>카테고리 등을 나타낼 때 유용한 데이터</li>
  <li>보통 문자열로 되어 있어 모델의 입력 데이터로 직접 사용할 수 없음</li>
  <li>인코딩을 통해 수치형 변수로 변환이 필요</li>
  <li>인코딩 방법으로 One Hot Encoding, Label Encoding, Frequency, Target Encoding, Embedding 등이 있음</li>
</ul>

<p><br /></p>

<h1 id="정형-데이터-전처리">정형 데이터 전처리</h1>

<h2 id="데이터-전처리">데이터 전처리</h2>

<ul>
  <li>EDA 분석을 위한 데이터, 모델에 입력할 데이터를 얻기 위해 데이터의 연속형 데이터, 범주형 데이터, 결측치, 이상치를 처리하는 과정</li>
  <li>선형, 트리, 딥러닝 등 모델과 목적에 따라 얻고자 하는 데이터가 달라짐</li>
  <li>신뢰도 있고 정확한 데이터를 얻는 제일 중요한 과정임</li>
</ul>

<p><br /></p>

<h2 id="전처리에-필요한-다양한-인코딩-방법과-장단점">전처리에 필요한 다양한 인코딩 방법과 장단점</h2>

<ul>
  <li>연속형 데이터 전처리
    <ul>
      <li>Scaling
        <ul>
          <li>데이터의 단위 혹은 분포를 변경하는 방법</li>
          <li>선형기반의 모델을 사용할 때 필요</li>
          <li>연속형 변수를 처리에 활용</li>
        </ul>
      </li>
      <li>Scaling의 종류
        <ul>
          <li>Scale 변경
            <ul>
              <li><strong>Min Max Scaling</strong>
                <ul>
                  <li>Minimum 값을 빼고, Max값과 Min 값의 차이로 나눔</li>
                </ul>
              </li>
              <li><strong>Standard Scaling</strong>
                <ul>
                  <li>평균 값을 빼고, 표준 편차로 나눔</li>
                </ul>
              </li>
              <li><strong>Robust Scaling</strong>
                <ul>
                  <li>중위 값을 빼고 IQR(상위 75%에 해당하는 값 - 상위 25%에 해당하는 값)으로 나눔</li>
                  <li>보통 이상치의 영향을 덜 받음</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Scale, Distribution(분포) 변경
            <ul>
              <li>분포 변환의 장점
                <ul>
                  <li>Feature와 Target의 관계를 더욱 직접적인 관계를 갖도록 함</li>
                  <li>특정 Feature가 선형 모델에 성능을 올릴 수 있음</li>
                </ul>
              </li>
              <li><strong>Log Transformation</strong>
                <ul>
                  <li>변수의 분포가 치우쳐 있는 경우, 정규 분포 같은 분포로 변환</li>
                </ul>
              </li>
              <li><strong>Quantile Transformation</strong>
                <ul>
                  <li>값을 균일하게 변화시키거나 정규 분포로 변환</li>
                  <li>Log Transformation과 차이점은 어떤 분포던 변환 가능</li>
                </ul>
              </li>
            </ul>
          </li>
          <li><strong>Binning</strong>
            <ul>
              <li>연속형 변수를 범주형 변수로 변형하는 방법</li>
              <li>Overfitting이 발생하는 경우를 방지
                <ul>
                  <li>Overfitting: 구간을 나눌 수 있는 데이터에서 중간중간 유의미한 정보가 있는 경우</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>범주형 데이터 전처리
    <ul>
      <li><strong>One Hot Encoding</strong>
        <ul>
          <li>컬럼에 변수를 두고 Boolean과 같이 1과 0으로 나누는 방법</li>
          <li>장점: 변수의 의미가 명확</li>
          <li>단점: 변수의 종류가 많아지면 분석이 복잡해짐 (차원의 저주)
            <ul>
              <li>차원의 저주(Curse of dimensionality): 차원이 높아질수록 발생하는 다양한 현상들</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>Label Encoding</strong>
        <ul>
          <li>컬럼의 수는 1개로 유지하고 값에 의미를 부여
            <ul>
              <li>e.g. 1: 개, 2: 고양이, 3: 둘 다</li>
            </ul>
          </li>
          <li>단점: 숫자의 순서에 의미가 부여되어 특징으로 여겨질 수 있음</li>
        </ul>
      </li>
      <li><strong>Frequency Encoding</strong>
        <ul>
          <li>변수의 값이 등장한 빈도를 측정해서 값을 사용</li>
          <li>빈도수를 변수의 Label로 사용</li>
          <li>장점: 값에 의미가 있는 범주형 데이터로 만들 수 있음</li>
          <li>단점: 다른 종류의 변수가 같은 Target 변수값을 가질 수 있음</li>
        </ul>
      </li>
      <li><strong>Target Encoding</strong>
        <ul>
          <li>각각의 변수 종류가 가지는 Target 변수의 평균을 사용</li>
          <li>단점: 다른 변수가 같은 Target 변수 평균을 갖게 될 수 있음</li>
        </ul>
      </li>
      <li>Embedding
        <ul>
          <li>Text 데이터의 관계값을 이용해서 더 낮은 차원으로 변환하는 방법</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="데이터-상-결측치와-이상치-처리-방법">데이터 상 결측치와 이상치 처리 방법</h2>

<ul>
  <li>결측치 처리 방법
    <ul>
      <li>특정 패턴을 갖고 있는 경우
        <ul>
          <li>패턴에 맞춰, 결측치를 채우는 방법</li>
        </ul>
      </li>
      <li>특정 패턴이 없는 경우
        <ul>
          <li>패턴이 없는 경우, 잘못된 방법을 사용 시 상관관계가 무너질 수 있으니 결측치 비율에 따라 주의해서 처리해야 함</li>
          <li>단변량 분석(Univariate)
            <ul>
              <li>제거
                <ul>
                  <li>데이터가 충분히 많아야 가능</li>
                  <li>테스트 데이터에 결측치가 있을 경우 사용하기 어려움</li>
                  <li>결측치 비율이 너무 크다면 포함된 변수 자체를 제거 가능</li>
                </ul>
              </li>
              <li>평균값 삽입</li>
              <li>중위값 삽입</li>
              <li>상수값 삽입</li>
            </ul>
          </li>
          <li>다변량 분석(Multivariate)
            <ul>
              <li>Linear, KNN 등 머신러닝 모델을 활용해 주변 변수들을 기반으로 결측치의 값을 예측하는 방법</li>
              <li>존재하는 데이터 중 결측치를 가진 샘플과 가장 유사한 샘플의 값을 이용하는 방법</li>
              <li>인구, 인원, 강수량, 지명, 온도, 습도, 풍속, 풍향 등의 결측치를 채우는 예시가 있음</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>이상치 처리 방법
    <ul>
      <li>이상치는 모델의 성능에 큰 영향을 끼치기 때문에 조심스럽게 처리해야 함</li>
      <li>이상치 처리 관점
        <ul>
          <li>정성적인 측면
            <ul>
              <li>이상치 발생 이유와 이상치의 의미를 고려해야 함
                <ul>
                  <li>과정을 통해 처리 방법을 선택</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>성능적인 측면
            <ul>
              <li>Train Test Distribution
                <ul>
                  <li>트레이닝 데이터와 테스트 데이터에 같은 이상치가 있는데, 트레이닝 데이터에서 이상치를 제거한 경우, 모델의 예측력이 떨어질 수 있다는 것을 고려해야 함</li>
                  <li>트레이닝 데이터에만 있는 이상치를 제거해야 함</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>이상치 탐색 방법
        <ul>
          <li>Z-Score</li>
          <li>IQR</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="머신러닝-기본-개념-소개">머신러닝 기본 개념 소개</h1>

<h2 id="underfitting과-overfitting">Underfitting과 Overfitting</h2>

<ul>
  <li>본 적이 없는 데이터를 잘 표현하지 못하는 상황임</li>
  <li>Underfitting
    <ul>
      <li>데이터를 잘 설명하지 못하는 상황</li>
    </ul>
  </li>
  <li>Overfitting
    <ul>
      <li>데이터를 과도하게 설명하는 상황</li>
      <li>제어하고 방지하기 위한 방법
        <ul>
          <li>Regularization(정형화)
            <ul>
              <li>Early Stopping
                <ul>
                  <li>Traning 데이터를 다시 한번 Train과 Validation Set으로 나누어 학습과 관찰을 하는 방법</li>
                  <li>Validation Error가 지속적으로 증가하는 지점에 학습을 중단</li>
                </ul>
              </li>
              <li>Parameter Norm Penalty
                <ul>
                  <li>데이터에 패널티를 부여하는 파라미터 <a href="https://steadiness-193.tistory.com/262">L1, L2</a>를 설정하는 방법</li>
                  <li>L1(Lasso, least absolute shrinkage and selection operator): 가중치, 기울기
                    <ul>
                      <li>일부 가중치가 0에 수렴하고, 이로 인해 feature의 수가 감소하는 효과</li>
                    </ul>
                  </li>
                  <li>L2(Ridge): 모델의 복잡도 조정
                    <ul>
                      <li>가중치를 0의 방향으로 잡아당기는 효과</li>
                    </ul>
                  </li>
                  <li>정형 데이터도 적용 가능</li>
                </ul>
              </li>
              <li>Data Augmentation
                <ul>
                  <li>데이터 변형을 통해 데이터 개수를 늘려서 다양한 데이터로 학습할 수 있게 하는 방법</li>
                  <li>이미지 데이터를 다룰 때 회전, 반전, 확대, 축소 등의 방법으로 많이 사용</li>
                  <li>정형 데이터도 적용 가능</li>
                </ul>
              </li>
              <li>SMOTE
                <ul>
                  <li>불균형한 데이터에서 소수 데이터를 활용해서 사이사이에 데이터를 생성하는 방법</li>
                  <li>정형데이터에서 Data Augmentation와 같은 효과를 내는 방법으로 많이 사용</li>
                </ul>
              </li>
              <li>Dropout
                <ul>
                  <li>일부의 Feature와 Node만 사용하여 학습하는 방법 (가지치기)</li>
                </ul>
              </li>
              <li>Column sample by tree
                <ul>
                  <li>Tree 모델을 만들 때, 렌덤하게 샘플링해서 일부 데이터만 사용</li>
                  <li>정형데이터에서 Dropout과 같은 효과를 내는 방법으로도 사용</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="검증-전략">검증 전략</h2>

<ul>
  <li>데이터셋의 구성
    <ul>
      <li>종류
        <ul>
          <li>Train
            <ul>
              <li>모델을 훈련하는 데이터셋</li>
              <li>Validation, Test를 제외한 나머지 데이터셋으로 품질에 따라 Noise 데이터를 포함할 지 여부를 고려해야 함</li>
            </ul>
          </li>
          <li>Validation
            <ul>
              <li>모델의 성능을 파악하기 위한 데이터셋</li>
              <li>Test Set을 제외한 전체 데이터를 대표할 수 있도록 구성</li>
            </ul>
          </li>
          <li>Test
            <ul>
              <li>모델을 테스트하기 위한 데이터셋</li>
              <li>최대한 전체 데이터를 대표할 수 있도록 구성</li>
              <li>테스트 데이터를 바꾸는 것은 프로젝트 진행에 매우 위험하기 때문에 정해놓고 Validation Set을 바꾸면서 다루어야 함.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>데이터셋을 선정하는 방법
        <ul>
          <li>Hold-out Validation
            <ul>
              <li>하나의 Train Set, Validation Set으로 고정해서 사용하는 방법</li>
              <li>불균형한 데이터가 특정 Set에 몰릴 수 있기 때문에 각 클래스 비율을 고려해야 함</li>
              <li>Random sampling
                <ul>
                  <li>무작위로 선택해서 나누는 방법</li>
                  <li>대표성이 유지되고 간편</li>
                  <li>데이터 사이즈가 작다면 전체 데이터를 대표하기에 어려울 수 있기 때문에 주의</li>
                </ul>
              </li>
              <li>Stratified Split
                <ul>
                  <li>클래스 비율에 따라 Train, Validation Set도 같은 비율로 나누는 방법</li>
                  <li>각 클래스의 분포를 유지할 수 있음</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Cross Validation
            <ul>
              <li>여러개의 Train Set, Validation Set으로 구성해서 사용</li>
              <li>K-Fold
                <ul>
                  <li>각 상황별로 모델을 학습시킨 후, 최종적으로 각자 학습된 모델들을 모두 사용해서 예측하는 방식</li>
                </ul>
              </li>
              <li>Stratified K-Fold
                <ul>
                  <li>데이터셋의 비율을 유지시키면서 상황별 모델 학습시키는 방식</li>
                  <li>데이터셋의 비율을 유지시켜 주는게 성능에 좋음</li>
                  <li>보통 8:2 비율을 유지</li>
                </ul>
              </li>
              <li>Group K-Fold
                <ul>
                  <li>데이터셋을 그룹으로 만들어 상황별 모델 학습시키는 방식</li>
                  <li>동일 Group이 같은 Fold에 들어가지 않도록 구성</li>
                  <li>Group은 항상 Fold 개수보다 커야 함</li>
                </ul>
              </li>
              <li>Time series split
                <ul>
                  <li>이전 데이터를 이용해서 다음 데이터를 예측하는 방식</li>
                  <li>학습 시, 미래 데이터로 과거 데이터를 예측하지 않도록 하기 위함</li>
                  <li>앞쪽 Fold일수록 Train 데이터가 적을 수 있다는 것을 유의해야 함</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="재현율">재현율</h2>

<ul>
  <li>학습된 모델로 예측할 때마다 샘플링이 다를 수 있고, 성능도 다를 수 있음</li>
  <li>이런 랜덤을 기반으로 실행되는 결과를 고정시켜주기 위해 <code class="language-plaintext highlighter-rouge">Seed</code>를 고정해서 사용</li>
</ul>

<p><br /></p>

<h2 id="머신-러닝-workflow">머신 러닝 Workflow</h2>

<ol>
  <li>Raw Data에서 데이터 추출</li>
  <li>데이터 전처리를 진행</li>
  <li>Feature Engineering, Scaling, Selection을 수행</li>
  <li>머신 러닝 알고리즘으로 모델링 및 학습을 진행</li>
  <li>Test Set으로 성능 평가를 진행</li>
  <li>필요에 따라 2 ~ 3을 반복</li>
</ol>

<p><br /></p>

<h1 id="트리-모델-소개">트리 모델 소개</h1>

<h2 id="tree-model">Tree Model</h2>

<ul>
  <li>Feature 값을 특정 기준으로 분류해 트리 모양으로 구성되며, 목적에 맞는 의사결정을 만드는 모델</li>
  <li>가장 기본이 되는 모델은 의사결정트리(Decision Tree)가 있음</li>
  <li>그 외에 Random Forest, AdaBoost, GBM, XGBoost/LightGBM/CatBoost 등이 있음 (트리의 발전 순)</li>
</ul>

<h2 id="bagging--boosting">Bagging &amp; Boosting</h2>

<ul>
  <li>Bagging
    <ul>
      <li>데이터셋을 랜덤하게 샘플해서 트리를 생성하고 생성한 트리의 의사 결정들을 취합하여 하나의 의사결정으로 구성하는 방식</li>
      <li>대표적으로 Random Forest가 있음</li>
      <li>구성 알고리즘
        <ul>
          <li>Bootstrap: Data를 여러 번 Sampling</li>
          <li>Aggregation: 종합(Ensemble)</li>
          <li>Bagging = Bootstrap + Aggregation</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Boosting
    <ul>
      <li>초기에 랜덤하게 선택된 데이터셋을 이용해서 틀을 만들고 , 맞지 않는 데이터들에 Weight를 부여하여 다음 트리 생성에 반영하는 방식</li>
      <li>대표적으로 LightGBM, XGBoost, CatBoost가 있음</li>
    </ul>
  </li>
  <li>Bagging과 Boosting 차이
    <ul>
      <li>가장 큰 차이는 Train 데이터를 어떻게 다루냐의 차이</li>
      <li>Tree 생성 방법
        <ul>
          <li>Bagging은 병렬 모델로 트리를 생성 (각 모델은 연관 없음)</li>
          <li>Boosting은 순차적 모델로 트리를 생성 (이전 Tree 오류를 기반으로 생성)</li>
        </ul>
      </li>
      <li>특징
        <ul>
          <li>Bagging은 다양한 Tree 생성</li>
          <li>Boosting은 정밀한 Tree 생성</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="lightgbm-xgboost-catboost">LightGBM, XGBoost, CatBoost</h2>

<ul>
  <li>Tree가 성장하는 방식에 따라 구분됨 (제한하지 않는다면 크게 다르지 않을 수 있음)</li>
  <li>균형적 구조
    <ul>
      <li>XGBoost</li>
      <li>CatBoost</li>
    </ul>
  </li>
  <li>비 균형적 구조
    <ul>
      <li>LightGBM</li>
    </ul>
  </li>
  <li>Category 변수 다루기
    <ul>
      <li>LightGBM, CatBoost는 pandas의 category 데이터 타입 가능
        <ul>
          <li>category 데이터에 대해 우수한 모델 성능</li>
        </ul>
      </li>
      <li>XGBoost는 numeric 데이터 타입만 가능 (전처리 필요)</li>
    </ul>
  </li>
</ul>

<h2 id="hyper-parameter-살펴보기">Hyper-parameter 살펴보기</h2>

<ul>
  <li>Learning Rate (학습률)
    <ul>
      <li>모델이 제대로 학습하기 위한 파라미터로, 작을수록 수렴 속도가 느려지고 클수록 발산하게 됨</li>
      <li>Gradient Descent의 Learning Rate와 같은 개념</li>
    </ul>
  </li>
  <li>Tree Depth &amp; Leaves
    <ul>
      <li>트리의 깊이(Depth)와 잎사귀(Leaves)를 설정</li>
      <li>값을 너무 크게 주거나 제한하지 않으면 Overfitting의 위험이 있음</li>
    </ul>
  </li>
  <li>Column &amp; Row Sampling Ratio
    <ul>
      <li>컬럼(Feature) 또는 로우(Instance) 중 랜덤으로 일부만 사용해서 Tree를 만듦</li>
      <li>Overfitting이 발생할 확률이 비교적 낮음</li>
      <li>다양한 조합으로 여러가지 트리를 만들 수 있음</li>
    </ul>
  </li>
</ul>

<table>
  <thead>
    <tr>
      <th>Parameter</th>
      <th>XGBoost</th>
      <th>CatBoost</th>
      <th>LightGBM</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Learning rate</td>
      <td>learning_rate</td>
      <td>learning_rate</td>
      <td>learning_rate</td>
    </tr>
    <tr>
      <td>Tree depth</td>
      <td>max_depth</td>
      <td>depth</td>
      <td>max_depth</td>
    </tr>
    <tr>
      <td>Number of leaves</td>
      <td>max_leaves</td>
      <td>max_leaves</td>
      <td>num_leaves</td>
    </tr>
    <tr>
      <td>Number of tree</td>
      <td>n_estimators</td>
      <td>n_estimators</td>
      <td>n_estimators</td>
    </tr>
    <tr>
      <td>Early stop</td>
      <td>early_stopping_rounds</td>
      <td>od_wait</td>
      <td>early_stopping_rounds</td>
    </tr>
    <tr>
      <td>Row sampling ratio</td>
      <td>subsample</td>
      <td>subsample</td>
      <td>bagging_freq</td>
    </tr>
    <tr>
      <td>Column sampling ratio</td>
      <td>colsample_bytree</td>
      <td>rsm</td>
      <td>colsample_bytree</td>
    </tr>
    <tr>
      <td>L1/L2 norm penalty</td>
      <td>alpha/lambda</td>
      <td>l2_leaf_reg</td>
      <td>lambda_l1/lambda_l2</td>
    </tr>
  </tbody>
</table>

<h1 id="reference">Reference</h1>

<ul>
  <li><a href="https://m.post.naver.com/viewer/postView.naver?volumeNo=35664080&amp;memberNo=34635212">제대로 된 인공지능 스터디를 찾고 있다면? AI 심화 스터디</a></li>
  <li><a href="https://www.boostcourse.org/study-ai111-2023">[코칭스터디 10기] Beyond AI Basic 2023 스터디 전용강좌</a></li>
</ul>

      <div class="c-article__footer u-clearfix">
        <div class="c-article__tag">
          
        </div>
        <div class="c-article__share">
          <a href="https://twitter.com/intent/tweet?text=%EC%BD%94%EC%B9%AD%EC%8A%A4%ED%84%B0%EB%94%94%20Beyond%20AI%20Basic%202023%20-%201%EC%A3%BC%EC%B0%A8%20%ED%95%99%EC%8A%B5&url=https://dong-jun-shin.github.io/2023/05/08/Beyond_AI_Basic_2023_Week_1/" title="Share
          on Twitter" rel="nofollow" target="_blank"><div data-icon='ei-sc-twitter' data-size='s'></div></a>
          <a href="https://facebook.com/sharer.php?u=https://dong-jun-shin.github.io/2023/05/08/Beyond_AI_Basic_2023_Week_1/" title="Share on Facebook" rel="nofollow" target="_blank"><div data-icon='ei-sc-facebook' data-size='s'></div></a>
          <a href="https://plus.google.com/share?url=https://dong-jun-shin.github.io/2023/05/08/Beyond_AI_Basic_2023_Week_1/" title="Share on Google+" rel="nofollow" target="_blank"><div data-icon='ei-sc-google-plus' data-size='s'></div></a>
        </div>
      </div>
      <div class="c-newsletter">
  <div class="c-newsletter__header">
    <h4 class="c-newsletter__title">Newsletter</h4>
    <div class="c-newsletter__subtitle">Subscribe to this blog and receive notifications of new posts by email.</div>
  </div>
  <form class="c-newsletter-form validate" action="#" method="POST" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" target="_blank" novalidate>
    <div class="c-newsletter-form__group">
      <label class="u-screen-reader-text" for="mce-EMAIL">Email address</label>
      <input class="c-newsletter__email required email" id="mce-EMAIL" type="email" name="EMAIL" placeholder="Your email address" autocomplete="on">
      <input class="c-newsletter__button" id="mc-embedded-subscribe" type="submit" name="subscribe" value="Subscribe">
    </div>
  </form>
</div> <!-- /.c-newsletter -->
      <div class="c-recent-post">
        <h4 class="c-recent__title">You might also enjoy</h4>
        <div class="c-recent__box">
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2025/01/10/permutation_and_combination_implements/" style="background-image: url( /images/CS_Algorithm/2025/01/permutation_and_combination_implements/thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2025/01/10/permutation_and_combination_implements/">순열과 조합 - 2, 경우의 수 뿐만 아니라 경우를 직접 구해보자</a></h4>
              <div class="c-recent__date">
                <time datetime="2025-01-10T17:45:03+09:00">January 10, 2025</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2025/01/10/permutation_and_combination_theory/" style="background-image: url( /images/CS_Algorithm/2025/01/permutation_and_combination_theory/thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2025/01/10/permutation_and_combination_theory/">순열과 조합 - 1, 어떤 원리로 경우의 수를 계산할 수 있는걸까?</a></h4>
              <div class="c-recent__date">
                <time datetime="2025-01-10T17:45:02+09:00">January 10, 2025</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2024/08/21/2_years_of_experience_from_2022/" style="background-image: url( /images/Life/2024/08/2_years_of_experience_from_2022/thumbnail_retrospective-journey.jpg)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2024/08/21/2_years_of_experience_from_2022/">퇴사 회고(라 쓰고, 2022년 ~ 2024년 정리)</a></h4>
              <div class="c-recent__date">
                <time datetime="2024-08-21T23:47:38+09:00">August 21, 2024</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2024/05/21/Aws_Summit_Seoul_2024/" style="background-image: url( /images/IT_Tech/2024/05/Aws_Summit_Seoul_2024/thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2024/05/21/Aws_Summit_Seoul_2024/">AWS Summit Seoul 2024 방문기</a></h4>
              <div class="c-recent__date">
                <time datetime="2024-05-21T21:55:48+09:00">May 21, 2024</time>
              </div>
            </div>
          </div>
        
        
        </div>
      </div> <!-- /.c-recent-post -->
      
        <div class="c-comments">
  <div id="disqus_thread" class="article-comments"></div>
  <script>
    (function () {
      var d = document, s = d.createElement('script');
      s.src = '//dong-jun-shin-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
</div> <!-- /.c-comments -->
      
    </div> <!-- /.c-wrap-content -->
  </div> <!-- /.c-article__content -->
</article> <!-- /.c-article-page -->

</main> <!-- /.c-content -->
  </div> <!-- /.o-wrapper -->
  <div class="c-top" data-icon='ei-chevron-up' data-size='s' title="Scroll To Top"></div> <!-- /.c-top -->
  <script src="/js/jquery-3.3.1.min.js"></script>
<script src="/js/evil-icons.min.js"></script>
<script src="/js/jquery.fitvids.js"></script>
<script src="/js/simple-jekyll-search.min.js"></script>
<script src="/js/main.js"></script>
<!-- /javascripts -->
</body>
</html>